titulo;url;regiao;descricao
Engenheiro de Dados Etl;https://www.catho.com.br/vagas/engenheiro-de-dados-etl/18646877/?origem_apply=busca-de-vagas&entrada_apply=direto;Brasilia - DF (1);Buscamos profissionais para atuação: Criação, versionamento e manutenção de workflows para consumo, carregamento e processamento de dados. Criação de scripts de ETL de dados ,Deploy de modelos preditivos e criação de estrutura para acompanhamento de métricas e testes A/B de modelos. Criação e manutenção de base de dados para análises e relatórios. Coletar, limpar, combinar e tratar dados de diferentes fontes. Criar e implementar processos automatizados de Data Quality. Integração com ferramentas de governança e gerenciamento de dados. Contribuir na definição da arquitetura de dados da organização. Apoiar na criação e manutenção em ambiente de big data utilizando práticas devops e dataops. Disseminação de boas práticas para o time de engenharia. Realizar reviews de código para garantir a qualidade de código e dos dados. Realizar estimativas e análises técnicas de estórias. Formação em Ciências da Computação, Engenharia da Computação, Sistemas de Informação, Análise e Desenvolvimento de Sistemas ou áreas correlatas Conhecimento avançado em Python ou e/ou Scala e/ou Java. Conhecimentos básicos em Linux. Experiência imprescindível na ferramenta: Spark. Desejável Experiência em outras ferramentas como Databricks. Conhecimentos básicos em AWS ou Azure. Conhecimento avançado em SQL. Conhecimento em banco de dados relacionais e não relacionais. Experiência com processamento de dados (Streaming e batch). Experiência com CDC - Change Data. Capture. Raciocínio lógico e pensamento analítico Noções de kubernetes e docker. Bons conhecimentos em arquitetura de big data Conhecimentos em construção de API. Conhecimentos em Git. Conhecimentos em web scrap.
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18656987/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Você trabalhará em estreita colaboração com nossa equipe de desenvolvimento, bem como com outras áreas da empresa, para melhorar e apoiar nossa tomada de decisão de dados.  - Coleta, análise e interpretação dos dados  - Criar comparações estatísticas  - Geração de Relatórios e documentação do projeto/produto  - Busca/Pesquisa de novas ferramentas e/ou tecnologias do mercado  - Tratamento/extração e análise de dados para ingestão em clusters de Big Data e afins  - Executar apresentações para explorar e expor resultados obtidos  - Criar pipelines confiáveis Requisitos:  - Experiência com Bancos de dados SQL, relacionais (Postgres / RDS)  - Experiência com banco de dados não relacionais (MongoDB)  - Conhecimento em Ferramentas ETL e pipelines de dados  - Conhecimento em Ferramentas de visualização (Metabase, entre outras)  - Experiência em Limpeza e avaliação de dados.    Perfil profissional:  - Hands On, disposto a fazer diversas atividades da área  - Profissional multi skills e com a mente aberta para aprender novas tecnologias e ferramentas  - Profissionais proativos, dinâmicos(as), com disposição para aprender algo novo todos os dias  - Motivados(as) em fazer parte de um time que busca entregar resultados de forma simples, eficiente e sustentável  - Capacidade de gerenciar seu próprio tempo  - Iniciativa e capacidade de trabalhar de forma independente e em equipe  Idioma:  Inglês - Intermediário
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18447908/?origem_apply=busca-de-vagas&entrada_apply=direto;São Caetano do Sul - SP (1);Responsável por gerenciar, otimizar, supervisionar e monitorar a recuperação, armazenamento e distribuição de dados em toda a organização. Engenheiros de dados são membros vitais de qualquer equipe corporativa de análise de dados.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18632099/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Bacharelado em MIS, CIS, Estatística, Negócios ou área relacionada. - Experiência profissional relevante. - Experiência trabalhando com a Hadoop ou outra plataforma de Grandes Dados e construindo soluções que agregam valor através da alavancagem de dados como um ativo. - Proficiência em AWS, Drone e GitHub. - Experiência na construção de dutos de dados em lote e streaming usando sqoop, Kafka, Spark. - Conhecimento básico de Hive e Neo4j. - Capacidade demonstrada para definir conceitos e padrões arquitetônicos e sua utilização criando capacidades de acesso a dados escaláveis e sustentáveis. - Experiência trabalhando em SQL Queries/Views e paradigmas NoSQL para estruturas de dados e gráficos. - Forte experiência em trabalhar e projetar CI/CD e sua automação. - Capacidade de pensar além dos frameworks EDW e ESB quando se trata de dados. - Experiência demonstrada trabalhando com desenvolvimento de software de ponta a ponta utilizando metodologia ágil/scrum. - Motivado pelo aprendizado e experimentação, especialmente com um grupo pequeno e ágil de colegas. - Conhecimento sobre como os dados podem criar valor para os negócios/domínio (através do ciclo de vida) e apetite para construir esta habilidade ao longo do tempo. - Fortes habilidades interpessoais, capacidade demonstrada para construir confiança e fortes relacionamentos. - Fortes habilidades de comunicação e apresentação. - Orientação para os resultados e capacidade de trabalhar em situações ambíguas onde as exigências não são claras, especificações não em detalhes, etc. - Forte força conceitual, pensamento estratégico, resolução de problemas, habilidades técnicas e analíticas. - Aplicação demonstrada de forte consciência do mercado e foco no cliente. - Capacidade de usar uma abordagem empreendedora para resolver problemas comerciais. - Capacidade de fazer perguntas de próximo nível, antecipando consultas comerciais e realizando análise de causa raiz.
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18658870/?origem_apply=busca-de-vagas&entrada_apply=direto;Jaguariuna - SP (1);Tratamento de dados, BI, Data Service. Necessário experiência na função/área. Ensino Superior na função.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18658128/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Projetar, modelar, documentar e implementar Data Warehouses com banco de dados Oracle Projetar, modelar, documentar e implementar um Data Lake Realizar ingestão de dados em batch, em streaming, carga de dados de diferentes fontes, organização e segurança dos dados e integração com outros repositórios de dados Auxiliar Cientistas e Analistas de Dados a analisar Big Data e oferecer soluções analíticas Criar Pipelines completo de análise de dados Participar da análise de demandas e levantamento de escopo assim como da execução de projetos Definir as atividades necessárias para a realização de projetos, analisando os impactos em sistemas e processos através do entendimento da necessidade, conhecimento técnico e arquitetônico dos sistemas Prestar consultoria e apoiar as áreas clientes e demais áreas de TI, proporcionando o esclarecimento de dúvidas relacionados ao projeto, contribuindo para uma melhor análise de impactos de processos e sistemas sob sua responsabilidade Participar e liderar as reuniões de planejamento e acompanhamento dos projetos Quando necessário executar atividades de desenvolvimento, execução e testes necessários para garantir a qualidade e performance da entrega Participar das atividades de planejamento para a liberação do produto para homologação e produção, por meio da validação de testes de aceite, assim como documentação de não conformidades avaliando e planejando a execução das correções reportadas. Experiência com Desenho e Implantação de soluções de BI e Analytics Experiência com ferramentas de ETL e integração de dados Experiência com Big Data e ecossistema Hadoop (Spark, Sqoop, MapReduce, etc). Experiência em métodos ágeis: Scrum e Kanban Experiência em liderança de projetos de Data Warehouses: Design e Implementação Experiência em integração de dados tradicional (ETL): IBM Data Stage 8.5 e 11.3 Experiência técnica Oracle 12g (modelagem e manipulação de dados) Experiência em Data Lakes: Kafka, SQOOP, Spark streaming, Hadoop Experiência desejada em Analytics, Visualização, Relatórios e Tomada de Decisões com BIG Data: Power BI ou Tableau.
ENGENHEIRO DE DADOS;https://www.catho.com.br/vagas/engenheiro-de-dados/18325080/?origem_apply=busca-de-vagas&entrada_apply=direto;Maringa - PR (1);Gosta de desafios ?A Gerando Falcões está inaugurando uma nova posição de ENGENHEIRO DE DADOS.Se você está pronto para colocar a mão na massa, e fazer acontecer, então essa vaga é perfeita para você!Vem com a gente, vem ser Falcão! Ensino Superior Completo em: Ciência da Computação, Engenharia da Computação ou áreas relacionadasInglês: BásicoDomínio em linguagem SQL e PythonDomínio em banco de dados: SQL Server, Oracle, MySQL e NoSQLDomínio em ingestão, integração. processamento e armazenamento de dadosConhecimento em ferramentas de ETL como Pentaho, SSIS, Data FactoryConhecimento em uso e desenvolvimento de API'SConhecimento em ferramentas de report e visualização de inteligência de dados (Power BI, DataStudio, Tableau).
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18651257/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Criar pipelines de leitura, transformação, carga e processamento de dados de fontes diversas (Oracle, SQL, text files, API&#39s JSON e XML) organizando os dados em data lake e ambiente data warehouse. Bancos de dados SQL, Comunicação web por Webservices e Web API&#39s, organização de Data Lakes e plataformas de big data Azure Data Lake, Python, Apache Airflow e Apache Spark.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18650367/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Desenvolvimento de soluções com grandes volumes de dados, seja offline ou real time. Ajudar na expansão da Plataforma Analítica, com foco em Self Service Analytics e ferramental Big Data. Garantir a preparação dos dados. Criação de modelos e indicadores. Parear com times de negócios Construção e otimização de ETL. Conhecimentos avançados em SQL. Experiência com modelagem dimensional de dados reporting e dashsboards como: Power BI Elevantamento de requisitos. Experiência em pipelines streaming e batch. Linguagens de programação, como: Java, Python ou Scala. Conhecimentos em otimização de performance em processos Spar. Experiência com tecnologias como: Apache Airflow , Spark , Kafka, AWS Redshift , EMR, S3, Glue , Hive e Athena) Ferramentas de automação e provisionamento.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18624463/?origem_apply=busca-de-vagas&entrada_apply=direto;Rio de Janeiro - RJ (1);Somos uma empresa do grupo América Móvil, com mais de 30 anos de experiência no mercado de soluções digitais e serviços de TI na América Latina e Estados Unidos. Desde 2010, nossas conquistas têm crescido e para sustentá-las, contamos com aproximadamente 3.000 profissionais engajados no desenvolvimento consistente do nosso negócio no País. Apostamos em talentos, no trabalho em equipe, na diversidade e em um ambiente inclusivo. Acreditamos no desenvolvimento de pessoas, no empoderamento como meio de superação de limites e promoção de resultados. Temos a bordo profissionais, programas jovem aprendiz, estágio e trainee. Apoiamos boas práticas e a sustentabilidade. Requisitos necessários: * Superior completo em Tecnologia da Informação, Engenharia da Computação, Ciência da Computação ou áreas correlata * Linguagens de Programação: Java, Python e SQL * Bancos de Dados NoSQL: Graph DB, Document DB (HBase ou Bigtable) * Google Cloud Plataform * Pub/sub, bigquery, dataflow Requisitos desejáveis: * Kubernetes e Janusgraph Princpais atribuições: * Construir, gerenciar e evoluir o pipeline * Definir arquitetura e soluções técnicas dos projetos * Coleta, combinação e disponibilização de dados * Configurar/desenvolver a ingestão de dados * Garantir a disponibilidade e performance da plataforma de dados * Implementar/gerir métodos de confidencialidade de dados * Disponibilização e integração de dados * Desenvolver estrutura de informações e dados Importante: Todas as nossas vagas são elegíveis para profissionais com deficiência, equidade de gênero e raça/ etnia.
Engenheiro de Dados (Inovação);https://www.catho.com.br/vagas/engenheiro-de-dados-inovacao/18383134/?origem_apply=busca-de-vagas&entrada_apply=direto;Porto Alegre - RS (1);Atuar no design, programação e testes de soluções críticas e escaláveis. Projetar, evoluir e manter pipelines de dados envolvendo as fases de ingestão, saneamento, processamento, entrega e visualização. Desenvolver e manter rotinas de captura, tratamento e enriquecimento de dados. Apoiar na análise dos dados processados pelas soluções e na preparação dos dados para exploração em ambiente analítico. Atuar na resolução de incidentes e defeitos, propondo melhorias para aplicações e processos. Apoiar na elaboração e revisão de especificações técnicas, funcionais e não funcionais. Trabalhar de forma colaborativa, apoiando o time e disseminando conhecimento. Conheça os conhecimentos que procuramos: Experiência prévia em desenvolvimento de sistemas corporativos e especificação de sistemas. Experiência prévia no desenvolvimento de pipelines de dados envolvendo as fases de ingestão, processamento, entrega e visualização. Computação em nuvem (preferencialmente Microsoft Azure) incluindo Storage, App Services, Serverless/Functions. Conhecimento em Ferramentas de Exploração e Análise de Dados, principais SGBDs de mercado, SQL, NoSQL, Spark, Python, etc. Boas práticas e metodologias de desenvolvimento de software. Perfil analítico e visão sistêmica. Iniciativa e pró-atividade para identificar, diagnosticar e propor soluções. Empatia e bom relacionamento para trabalho em equipe. Disposição e vontade para ensinar e aprender. Qualificações e Habilidades desejadas: Experiência em governança de dados incluindo saneamento, tratamento e classificação. Excel avançado para manipulação de dados. Ferramentas analíticas tais como Power BI, Microstrategy, Tableau, etc. Experiência com tecnologias envolvendo inteligência artificial e machine learning. Conhecimentos em HTML, XML, CSS, Maven/Ant, Log4j/Logback, JUnit/TestNG, WebServices SOAP/REST, JSF, Spring Boot, JPA com Hibernate, Angular 5, Javacript, TypeScript, Go Language. Formação Requerida: Superior completo na área de Tecnologia da Informação ou cursos afins.
Engenheiro de Dados Pleno;https://www.catho.com.br/vagas/engenheiro-de-dados-pleno/18383159/?origem_apply=busca-de-vagas&entrada_apply=direto;Porto Alegre - RS (1);Pesquisar, definir e desenvolver as soluções de processamento, armazenamento e disponibilização de grandes volumes de dados que compõem as plataformas Big Data, de dados e analítica, utilizadas pelos produtos da Neogrid. Construir e manter o pipeline de ingestão, processamento e transformação de dados em insights para os produtos dentro dos padrões de qualidade e performance, em cumprimento ao planejamento estabelecido. Experiência em desenvolvimento de sistemas corporativos, orientação a objetos, padrões de projetos e testes unitários. Experiência na tecnologia Scala ou Java, banco de dados relacional e NoSQL, gerenciamento de dependências (maven, sbt, gradle) e sistema operacional Linux. Conhecimento em arquitetura Big Data e experiencia nas tecnologias para processamento distribuído (Spark, MapReduce) Conhecimento em Hadoop e seu ecossistema (Hbase, HDFS, YARN, Zookeeper, Solr), e/ou conhecimento em processamento massivo de dados em cloud (Azure, AWS).Conhecimento em Business Intelligence (Datawarehouse, Datamining) Superior completo em Sistemas de Informação, Ciência da Computação, Engenharia da Computação, Análise de Sistemas ou área relacionada.
Engenheiro de Dados Pleno;https://www.catho.com.br/vagas/engenheiro-de-dados-pleno/18615333/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Nesta vaga de Eng. de Dados você irá trabalhar diretamente na construção e em melhorias de toda nossa infraestrutura de Dados, tanto para nossos times de BI quanto para nossos times de Engenharia de Dados. Será responsável por melhorias de processos e de ferramentas, construção e melhora de ETL&#39s, ferramentas de extração de dados, anonimização, padronização de dados. O QUE ESPERAMOS DE VOCÊ: Experiência comprovada na execução de pipeline de dados para Ciência de dados e Machine Learning. Ter a filosofia de que simplicidade é a maior das sofisticações. Trabalhe com software livre e seja um multiplicador deste conhecimento. Entender sobre arquitetura de dados moderna, ETL&#39s usando AIRFLOW ou correlatos. PONTOS EXTRAS PARA: Conhecimento em AWS, Amazon Web Service. Conhecimento em linguagens como Python e/ou Ruby. Ter implementado arquiteturas de extração e manipulação de dados usando Airflow+S3. BENEFÍCIOS DE UM NEXEER: Fazer parte do time que constitui a maior Fintech de Marketplace Lending da América Latina. Ambiente dinâmico, colaborativo e inovador: para conseguir acompanhar o mercado e continuar inovando, nosso ritmo é acelerado e nossa curva de aprendizado é muito alta. Além disso, valorizamos um ambiente informal com contato direto e constante com os sócios e o CEO. Honestidade e desenvolvimento: Aqui, você encontrará um ambiente que valoriza feedbacks 360° e 1:1. Acreditamos que a honestidade é a fórmula do desenvolvimento individual e do trabalho em equipe. Localização acessível: atualmente nosso escritório se encontra ao lado do metrô Faria Lima, com fácil acesso através de transporte público. Achamos essencial nosso escritório ser acessível e próximo a um dos maiores polos de comércio e finanças do país. Gympass: plataforma que te dá benefícios em mais de 18 mil academias no Brasil. Nas academias conveniadas são oferecidas mais de 700 modalidades esportivas, incluindo aulas de dança, artes marciais, musculação, yoga, aulas aquáticas, pilates e até massagem! POSHER Benefícios In-Company : plataforma que oferece uma diversidade de serviços online para aumentar o seu nível de bem-estar e ajudar você a relaxar! Você terá acesso a aulas online de yoga, pilates, mindfulness, consultas com nutricionistas e psicólogos, aulas de inglês, espanhol e muito mais. Tudo isso sem perder tempo com deslocamento! Plano de Saúde Unimed em parceria com a Vitta! Dando direito ao nosso colaborador ao PrimeCare: uma Equipe de Saúde 24/7, com tecnologia proprietária e time próprio, que pode ser acessada via WhatsApp ou pelo App. Ao ser atendido pelo médicos de plantão você terá direito de até 90% de subsídio no medicamento e reembolso de até R$220,00 por consulta Auxílio creche Cartão de Crédito Caju! Não quer gastar com comida!? Que tal usar seu VR para ir ao cinema ou à academia? O Cartão Caju dá a liberdade para o colaborador fazer o que quiser com o seu Vale Refeição. Vale Transporte
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18611945/?origem_apply=busca-de-vagas&entrada_apply=direto;Curitiba - PR (1);Desenhar e modelar novas soluções de arquitetura de dados seguras, confiáveis, disponíveis e escaláveis. Criar e definir modelagens de repositórios de dados de clientes tais como (Data Lakes, DataWareHouses, Bases relacionais e não relacionais). Desenvolver estratégias de aquisição de dados (históricos e online), recuperação de informação, implementação de pipelines de processamentos de dados e armazenamento de dados. Manter repositórios de dados seguros e pipelines de integração confiáveis e escaláveis. Planejar e modelar estruturas de comunicação de dados entre sistemas legados e repositórios de dados. Construir e sustentar a infraestrutura que suporta o treinamento e a operação de modelos de machine learning. Entendimento de necessidade de clientes junto à equipes de negócio. REQUISITOS E QUALIFICAÇÕES: Forte skill de engenharia de software Proficiência em alguma linguagem de programação. Preferência por Python ou Java Proficiência em linguagem SQL Conhecimento em big data, data warehousing, business intelligence Experiência em arquitetura e processos de cargas para DataLake Experiência em extrações de Dados via API&#39s Experiência com ferramentas de ETL Experiência com ferramentas de orquestração de fluxo de dados Conhecimento em DataOps e esteiras de CI/CD Experiência com cloud computing, preferencialmente GCP, AWS ou Azure. Diferenciais: Conhecimento em engenharia de machine learning Conhecimento em catálogo de dados.
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18427584/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Irá atuar ativamente no desenvolvimento da plataforma de inteligência de dados de forma geral, desenvolver, evoluir e manter, como parte do escopo dos projetos. A plataforma está baseada em um ambiente AWS. Desenvolvimento e implementação de componentes AWS - EMR, Cloud Formation, Glue, Athena, APIs, Integration Services Administração de bucket S3 e instâncias AWS EC2 para execução de componentes da plataforma de Analytics quando requerido. Migração de dados a partir de fontes como SAP ECC e 4Hana, Sales Force, sistemas legados c/ bd no SQL Server, dados não estruturados como planilhas/imagens/etc e plataformas digitais (redes sociais, sites de e-commerce internos e externos, dados de apps entre outros) para nosso DataLake na AWS. Desenvolvimento de Lambda Functions, armazenamento em nosso DW, datamarts e cluster Big Data. Integração de dados utilizando como destino banco de dados SQL e NoSQL (Azure SQL DW, Aurora, MariaDb, Redshift, DynamoDb, MongoDb entre outros). Criação e manutenção de scripts em Python e SQL (conhecimentos em R e NodeJs desejáveis conhecimentos em Kafka e Kinesis serão considerados diferenciais). Experiência com modelagem de dados e especificação de arquitetura de soluções de BI & Analytics seguindo melhores práticas e/ou design patterns recomendados internamente ou por fornecedores.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18616080/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Desenvolver soluções de engenharia de dados em nuvem utilizando os produtos Azure Databricks / Data Factory / Storage e Azure SQL Server Coletar requerimentos de usuários em relação as soluções de BI e Dados Construir modelagem que descrevam os dados e seus relacionamentos de modo consistente para suportar os objetivos de negócios tecnológicos Desenhar relatórios e dashboards que facilitem as atividades operacionais dos usuários de negócios e extrair insights avançados Definir e criar a camada semântica de dados Treinar e apoiar usuários na exploração autônoma dos dados usando as ferramentas apropriadas Definir processos que forneçam conjuntos de dados para análises, aumentando a velocidade das entregas Limpar e preparar dados para uso futuro (principalmente BigData) Simplificar o acesso e colaboração por meio de componentes reutilizáveis (APIs, Views, DataSet etc). Requisitos Necessários Conhecimentos em Azure Data Bricks / Azure Data Factory / Azure Storage / Azure SQL Arquitetura de ambientes de Dados utilizando Databricks / Data Factory / Storage e Azure SQL Server Análise de requisitos de dados e BI Modelagem e relacionamento de dados Desenhar e desenvolver relatórios e Dashboards Análise semântica de dados Executar o processo ETL Conhecimento de integração com fontes de dados Criação de processos para governança de dados. Requisitos Desejáveis Programação na Linguagem Python.
Desenvolvedor Sênior (Engenheiro de Dados);https://www.catho.com.br/vagas/desenvolvedor-senior-engenheiro-de-dados/18383001/?origem_apply=busca-de-vagas&entrada_apply=direto;Porto Alegre - RS (1);Atuar no design, programação e testes de soluções críticas e escaláveis. Projetar, evoluir e manter pipelines de dados envolvendo as fases de ingestão, saneamento, processamento, entrega e visualização. Desenvolver e manter rotinas de captura, tratamento e enriquecimento de dados. Apoiar na análise dos dados processados pelas soluções e na preparação dos dados para exploração em ambiente analítico. Atuar na resolução de incidentes e defeitos, propondo melhorias para aplicações e processos. Apoiar na elaboração e revisão de especificações técnicas, funcionais e não funcionais. Trabalhar de forma colaborativa, apoiando o time e disseminando conhecimento. Experiência prévia em desenvolvimento de sistemas corporativos e especificação de sistemas. Experiência prévia no desenvolvimento de pipelines de dados envolvendo as fases de ingestão, processamento, entrega e visualização. Computação em nuvem (preferencialmente Microsoft Azure) incluindo Storage, App Services, Serverless/Functions. Conhecimento em Ferramentas de Exploração e Análise de Dados, principais SGBDs de mercado, SQL, NoSQL, Spark, Python, etc. Boas práticas e metodologias de desenvolvimento de software. Perfil analítico e visão sistêmica. Iniciativa e pró-atividade para identificar, diagnosticar e propor soluções. Empatia e bom relacionamento para trabalho em equipe. Disposição e vontade para ensinar e aprender. Experiência em governança de dados incluindo saneamento, tratamento e classificação. Excel avançado para manipulação de dados. Ferramentas analíticas tais como Power BI, Microstrategy, Tableau, etc. Experiência com tecnologias envolvendo inteligência artificial e machine learning. Conhecimentos em HTML, XML, CSS, Maven/Ant, Log4j/Logback, JUnit/TestNG, WebServices SOAP/REST, JSF, Spring Boot, JPA com Hibernate, Angular 5, Javacript, TypeScript, Go Language.
Engenheiro de dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18429370/?origem_apply=busca-de-vagas&entrada_apply=direto;Rio de Janeiro - RJ (5);Estamos contratando Engenheiro de Dados para a execução de projetos de transformação digital, desenvolvendo ferramentas inovadoras para entregar a melhor experiência para os usuários da plataforma de uma grande empresa.    Entendemos que para essa evolução, é necessário o conhecimento nas tecnologias:      ?	Python  ?	BigData  ?	Metodologia Agil    Se você tem conhecimento ou experiência em metodologia ágil e ferramentas de ETL para desenvolvimento será uma grande diferencial para a oportunidade e com certeza não hesitaremos em te contratar.    Os bancos de dados principais:  ?	SQL Server  ?	Oracle  ?	TeraData  Essa transformação envolve diversas áreas, por isso é um projeto com prazo indeterminado na qual você fara parte da equipe desde o início para que possamos ter o melhor resultado e uma equipe de longa experiência para evolução das plataformas em uma grande empresa de telecomunicação.    Atuação 100% remota.    Tem interesse?    Candidate-se a nossa vaga que teremos o grande prazer de dividir essa experiência com você.    ?Grandes coisas em termos de negócios nunca são feitas por uma pessoa. São feitas por uma equipe de pessoas?  Idioma:  Inglês - Intermediário
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18539014/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Propor, executar, validar, apresentar e implantar o uso de tecnologias e soluções para questões técnicas e também de negócios, através de ferramentas e arquiteturas projetadas para processamento de grande volume de dados, com foco em inovação, melhora na qualidade de dados e provendo insumos para novos produtos na empresa. Experiência em engenharia de dados. Experiência em SIEM. Experiência em QRADAR.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18575950/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Profissional que gerencia, otimiza, supervisona e monitora a recuperação. responsável pelos armazenamento e distribuir os dados. Em linhas gerais, é o profissional responsável por gerenciar, otimizar, supervisionar e monitorar a recuperação, armazenamento e distribuição de dados em toda a organização. Engenheiros de dados são membros vitais de qualquer equipe corporativa de análise de dados. Fundamentos de Big Data, Hadoop, Hive, SQL, StreamSets Conhecimento de Spark Conhecimentos de Python Conhecimento em Modelagem de Dados Conhecimento em NoSQL Conhecimento com Linux Experiência com ingestão, integração, processamento e armazenamento de grandes volumes de dados.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18564354/?origem_apply=busca-de-vagas&entrada_apply=direto;Florianópolis - SC (1);O Engenheiro de Dados projeta e implementa o gerenciamento, monitoramento, segurança e privacidade de dados utilizando as soluções que atendam às necessidades de negócios. Concluído ou Cursando superior em Informática, matemática, engenharia ou áreas afins. Docker. Apache Spark. Apache Airflow. Apache Hive.Apache ZooKeeper. Apache Hadoop YARN. Apache Kafka.Apache Sentry. Conhecimento do ecossistema Cloudera. onhecimento nas seguintes linguagens: SQL, Python. Conhecimento em Orientação a Objeto e/ou Funcional. Diferenciais:C#.Redis.Jupyter Notebook .DevOpsData Driven. Conhecimento em Ciência de Dados.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18522596/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (6);Extrair dados de diversas plataformas e trabalhar com terabytes de dados. Garantir por meio de monitoramento e métricas que todo o processo de ETL esteja funcionando. Propor melhorias e soluções relacionadas a engenharia de dados. Experiência em processos ETL (Extract Transform and Load). Experiência com grandes conjuntos de dados com ferramentas de BigData como Spark, Presto, Kafka, Kinesis ,etc. Experiência em um ambiente data-driven. Experiência com tecnologias como Spark, Kafka, Presto e Airflow e se sente confiante para criar datasets agregados. Conhecimento em práticas para construção de De Data Lakes e Data Warehouses em cloud. Experiência com AWS, Azure ou GCP. Experiência na função.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18554544/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);O Engenheiro de Dados tem o desafio de desenvolver pipelines de dados, praticar governança e disseminar a melhor fonte de dados para cada necessidade, modelos estatísticos ou inteligência do negócio (BI, MIS, etc). Procuramos alguém dinâmico, capaz de buscar as melhores soluções para cada desafio proposto. Atividades: Desenvolvimento de ingestões de dados utilizando Azure Data Factory. Desenvolvimento de pipelines de dados utilizando Spark. Desenvolvimento em Python, manipulação de dados, criação de datamarts e tabelas unificadas para melhor atender os requisitos de negócio. Realizar as entregas em todos ambientes (inclusive em produção). Automatizar integrações de bases com o Data Lake Experiência em soluções de dados. Conhecimento em Python ou outra linguagem voltada a manipulação de dados. Conhecimento dos conceitos de ETL. Experiência em modelagem de dados. Conhecimentos avançados em SQL. Diferenciais: Experiência com arquitetura cloud para dados. Preferencialmente em Azure (Ex.: Azure Data Factory, Azure Databricks, Azure Data Lake Storage, Azure Synapse Analytics). Análise de fontes de dados conforme pedido das áreas de negócio (banco de dados, arquivos, não estruturados, etc). Conhecimento de alguma ferramenta de ETL (Ex.: IBM Datastage, ODI, Informatica PowerCenter). Experiencia em análise e extração de dados estruturados e não estruturados. Familiaridade com ambiente cloud (Azure, Google ou AWS) Levantamento de necessidades e definições de formato de integração de dados. Conhecimento em ferramentas de dashboards (Power BI ou Tableau).
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18448997/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Experiência em projetar, desenvolver, testar, instalar / implementar, modificar e manter soluções de Business Intelligence e Data Warehousing. Experiência de Processo: Consultoria de Dados e Análise Modelagem de dados: modelagem de banco de dados multidimensional e relacional Traduzir desafios e requisitos de negócios em percepções. Experiência em escrever e desenvolver processos ETL ad-hoc e de nível de produção Proficiente em SQL (PL-SQL, T-SQL) Experiência prática com pipelines de dados em Python (ETL, preparação de dados, engenharia de recursos) Conhecimento prático de scripts de shell Plataformas orientadas para estatísticas (SAS, SSPS) Plataformas ETL (Data Stage, PowerCenter) Paradigmas de modelagem de dados não relacionais (gráfico, documento, valor-chave, coluna) Proficiente em pelo menos uma plataforma de Big Data e Cloud (Azure, AWS, GCP) Inglês Avançado, Espanhol intermediário.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18609304/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Quem somos: // Nascemos em 1998, fruto da paixão pela tecnologia e do impulso empreendedor de nossos fundadores. Com a sabedoria que só quem é a página inicial da internet no Brasil pode ter, acreditamos que todos podem se desenvolver. Por isso, oferecemos um portfólio completo de serviços de internet, atendimento especializado e muito conteúdo. Mais de 280 mil clientes e 15 mil desenvolvedores parceiros estão com a gente. Somos uma empresa que possui diferentes unidades de negócio, cada qual com um conjunto de soluções específicas: serviços de internet, e-commerce, marketing de relacionamento digital e projetos corporativos, mas com algo em comum: paixão por desenvolver. Porque, aqui na Locaweb, desenvolver vai muito além da tecnologia. :) E para tirar de letra, você precisa de: * Fundamentos de Big Data, Hadoop, Hive, SQL, StreamSets * Conhecimento de Spark * Conhecimentos de Python * Conhecimento em Modelagem de Dados * Conhecimento em NoSQL * Conhecimento com Linux * Experiência com ingestão, integração, processamento e armazenamento de grandes volumes de dados. Só quem é Locaweber tem: ? Convênio Médico ? Convênio Odontológico ? Vale-Transporte ou Estacionamento gratuito ? Serviço gratuito de vans do terminal João Dias para a Locaweb ? Vale Refeição: ? Seguro de Vida ? Máquinas de café a vontade ? Massagem e ginástica laboral in company ? Sala de Relax com TV, mesa de bilhar, carteado, tênis de mesa, vídeo games e puffs ? Salão de beleza in company (cabeleireiro, depilação, manicure, estética corporal) ? Gympass ? Day off ? Programa de Qualidade de Vida e bem-estar ? Parceiras com diversos estabelecimentos na área de saúde, lazer e entretenimento entre outros ? Oferta de cortesias dos produtos LOCAWEB. Onde estamos: Ficamos num lugar incrível com muita natureza e pertinho do metrô Giovanni Gronchi e Terminal João Dias (Rua Itapaiúna, 2434 ? São Paulo/SP.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18609251/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Arquitetura e Ingestão de Dados Hadoop Bigdata NoSQL Databases SQL PL/SQL Apache Spark Scala e Pyspark ETL (Extração, transformação e carregamento) Gerenciamento de serviços de TI Experiência em Data Preparation, com habilidades para coletar, limpar, normalizar, combinar, estruturar e organizar dados para análises. Tecnologias utilizadas: Hortonworks on premise ? Linux - Spark Hadoop - HIVE - SQOOP ? PHOENIX - HBASE - ORACLE - Shell-Script , Elasticsearch, com Desenvolvimento em Apache SCALA. Tecnologias e Cloud: GCP ? BigQuery ? Dataproc Scala ? STORAGE Buckets ? Cloud Pub/Sub e Python.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18588594/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar no apoio de desenvolvimento da área de BI, desenhando melhores soluções para o negócio, realizar o desenvolvimento de processos, com foco  em performance de qualidade de dados e modelagem. Necessário experiência em modelagem de dados em arquitetura DW
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18582588/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Contribuir com o projeto de Data Lake e preparação de dados, implementando um design sólido, robusto e extensível que suporte os principais fluxos de negócios  Criar a infraestrutura necessária para extração, transformação e carregamento otimizados de dados de uma ampla variedade de fontes de dados usando as tecnologias de SQL, AWS e outras  Fornecer excelência operacional por meio da análise de causa raiz e melhoria contínua para tecnologias e processos de Big Data  Contribuir para inovações e insights de dados que impulsionam a visão da empresa  Trabalhar em um ambiente colaborativo, interagindo com vários grupos diariamente. Bacharel em Ciência da Computação ou disciplina técnica relacionada  Experiência de trabalho com projetos/ infraestrutura do Hadoop  Experiência com as práticas de DW no espaço Big Data  Experiência com pelo menos uma linguagem de script (Shell, Python, Perl, etc.)  Experiência com uma linguagem de programação: Python  Proficiente em projetar fluxos de trabalho de ETL  Inglês avançado  Capacidade de escrever, analisar e depurar consultas SQL.    Soft Skills  Flexibilidade  Resiliente  Proativo  Comunicação eficaz
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18581042/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Projetar e desenvolver sistemas de Machine Learning e Deep Learning. Executar testes e experimentos de aprendizado de máquina. Pesquisar e implementar algoritmos de Machine Learning apropriados. Selecionar conjuntos de dados apropriados e métodos de representação de dados. Realizar análise estatística e ajustes nos modelos usando resultados de teste. Treinar e ajustar os sistemas quando necessário. Estender bibliotecas e estruturas de Machine Learning existentes. Ensino Superior completo. Experiência com Machine Learning. Compreensão de estruturas de dados, modelagem de dados e arquitetura de software. Conhecimento em matemática, probabilidade, estatística e algoritmos. Capacidade de escrever código robusto em Python, Java ou R. Conhecimento em estruturas de aprendizado de máquina (como Keras ou PyTorch) e bibliotecas (como scikit-learn). Habilidades de comunicação. Vivência com a cultura DevOps. Experiência com Linux. Experiência com Docker. Conhecimento avançado em Git. Experiência com automação de desenvolvimento de software (Jenkins ou similar).  Idioma:  Inglês - Fluente
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18568333/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Buscamos um profissional com grande capacidade técnica para abraçar novos desafios e desenvolver as seguintes tarefas   - Desenvolver, construir, testar e manter arquiteturas de dados  - Alinhar arquiteturas com requisitos de negócios  - Cuidar da aquisição dos dados  - Desenvolver processos de conjunto de dados  - Usar linguagem de programação e ferramentas  - Identificar maneiras de melhorar a confiabilidade, a eficiência e a qualidade dos dados  - Usar grandes conjuntos de dados para resolver problemas de negócios  - Implantar programas analíticos sofisticados, Machine Learning e métodos estatísticos  - Preparar dados para modelagem preditiva e prescritiva  - Encontrar padrões ocultos usando dados  - Usar dados para descobrir tarefas que podem ser automatizadas  - Entregar atualizações para as partes interessadas com base em análises. O candidato deve ter terceiro grau em Ciência da Computação, Engenharia, Matemática Aplicada ou curso correlato  ?	Conhecimento do design do banco de dados SQL  ?	Conhecimento em linguagens de programação: Python, Java ....  ?	Cursos e/ou Certificações na área são um diferencial:   Mestrado ou pós-graduação em Análise de Dados   Cloudera Certified Professional (CCP): Data Engineer   Google Cloud Certified Professional Data EngineerCertificate in Engineering Excellence Big Data Analytics Optimization (CPEE)  IBM Certified Data Engineer ? Big Data  ?	Fluência em inglês  ?	Ter boa comunicação   ?	Ser organizado  Idioma:  Inglês - Fluente
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18547400/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar na área de de Data & Analytics, sendo responsável pela modelagem de dados, clusterização, segmentação de dados dos projetos e da indústria para auxílio na tomada de decisão. Além disso, vai realizar a avaliação da estruturação de dados atual e futura, proposição e desenvolvimento de uma estrutura de dados futuros e melhorias de código para a base de dados e vai operar todo o processo para gestão das informações do Projeto e Produto de Marketplace no setor de saúde. Profissional com aptidão para desenho e desenvolvimento de soluções Big (batch) e Fast Data, capazes de superar desafios importantes de segurança, performance e resiliência em aplicações de missão crítica e com altíssimo volume de consumo. Conhecimento em modelagem de dados / Azure ADLSGen2 / ComosDB Cassandra/MongoDB. Conhecimento de plataformas de extensão de data lake em clouds públicas. Conhecimento de produtos em Cloud Pública Azure, Spark, Databricks, Event Hub, ADLSGen2, HDInsight. Experiência em frameworks e produtos de processamento Big e Fast Data (ex.: Spark, SparkStreaming, Java/Scala , Hive, Impala). Experiência na utilização de produtos utilizados na construção do soluções Big e Fast Data (ex.: Kafka, Yarn, Schema Registry). Experiência na utilização de produtos para extensão de data lake em Cloud Pública Azure, Spark, Databricks, Event Hub, ADLSGen2, HDInsight. Metodologia de desenvolvimento ágil.
Engenheiro de Dados NRT;https://www.catho.com.br/vagas/engenheiro-de-dados-nrt/18559885/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Sustentação microserviços fluxo NRT.                  Preparação de dados com Spark Streaming.                         Entendimento dos requisitos de negocio.                  Desenvolvimento dos pipelines.                   Teste Unitário.                  Desenvolvimento plano de implantação.                    Acompanhamento Implantação.                      Validação dos dados.                     Homologação com o Gestor.                        Alinhar com a origem a necessidade de replicação.                        Ativar replicações na origem (DEV/Prod).                         Acompanhamento da estabilização do job em Produção.                      Sustentação pós-implantação PySpark / Python / Spark / Shell / HQL / SQL / Git / Kafka / Java / Hbase Intermediário Framework hadoop / Nifi / CDC Básico   Desejável: Jira / Confluence / Bitbucket / Docker / Micro Serviços
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18558036/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuará com Data Factory, Data Lake Storage, desenvolvimento e modelagem de Data Warehouse. Experiência e bons conhecimentos em Python.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18553010/?origem_apply=busca-de-vagas&entrada_apply=direto;Porto Alegre - RS (1);Propor e desenvolver soluções para DataOps em cloud. Construir scripts de transformação de dados transacionais e analíticos. Criar mecânicas para gerencia do ciclo de vida dos dados. Trabalhar com processamento de volumes massivos de dados em streaming e batch Explorar novas tecnologias e propor formas inovadoras de disponibilizar os dados nas melhores condições para Cientistas e Analistas Participar e colaborar com os Squads Ágeis em seus rituais. Participar da definição das soluções e ser propositivo e apresentar as suas ideias ou críticas. Conhecimento em configuração, desenvolvimento e deploy de soluções em cloud (AWS, Azure, GCP ou Huawei). Proficiência com Python ou Scala. Conhecimento de Orientação a Objetos. Domínio de SQL e PLSQL. Experiência na construção de pipelines de ETL (com qualquer ferramenta). Desejável: Experiência com bibliotecas Python para manipulação de dados (Pandas, Numpy, etc.) Experiência com Apache Spark. Experiência em soluções que utilizam arquivos Parquet, Avro, ORC ou Carbon. Conhecimento em Docker. Entendimento de modelagem dimensional. Diferencial: Possuir certificação técnica em AWS, Azure, GCP, Huawei ou Databricks. Experiência com Apache Kafka.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18509552/?origem_apply=busca-de-vagas&entrada_apply=direto;Barueri - SP (1);Levantar e entender as necessidades do cliente Identificar oportunidades Propor soluções em consonância com orientações do cientista - chefe Apoiar o desenvolvimento, implantação e operacionalização do projeto, garantindo a aderência às necessidades do cliente Avaliar e propor melhorias para as soluções adotadas. Experiência com projetos Big Data e engenharia de dados. Arquitetura Batch, Streaming, Lambda e Kappa. Conhecimento em pelo menos Java ou Scala. Conhecimento em plataformas Cloud. Experiência em Big Data. Ingestão e processamento de dados em DataLake e Data Warehouse. Construção de dashboards para análise (Grafana, Kibana, Power BI, Tableau). Conhecimentos sólidos em Linux. Sólidos conhecimentos em containers Docker (construção e publicação). Proficiência: SQL. Shell Script. Apache Spark. Hadoop. Java ou Scala. Modelagem de dados em RDB e colunar. ELK (Elasticsearch, Logstash, Kibana). ETL (Ex.: Nifi, StreamSets, Logstash). GCP ou AWS. Formação Acadêmica Curso superior completo em TI.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18528038/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar com Governança de Dados, Uso de ferramentas MS Office, atuando em projetos centrados em Dados. Conhecimento sobre Governança de Dados INTERMEDIÁRIO Conhecimento sobre Qualidade de Dados DESEJÁVEL Conhecimento de ao menos uma das seguintes tecnologias: Teradata, SAS, Hive/Hadoop Power BI, Microstrategy, Tableau  INTERMEDIÁRIO Uso de ferramentas MS Office (Power Point, Word, Excel e Project)- INTERMEDIÁRIO Experiência atuando em projetos centrados em Dados (ex: Desenvolvimento de sistemas baseados em SGBDs, soluções de BI ou Analytics  INTERMEDIÁRIO Conhecimento de conceitos de Big Data, ferramentas Opens Source, Data Catalog, Data Lineage, Data Virtualization - BASICO Experiências e qualificações: Conhecimento de Métodos Ágeis para desenvolvimento de projetos - DESEJÁVEL Conhecimento nas ferramentas Informática Axon e EDC - DESEJÁVEL Conhecimento nas ferramentas Informática BDM e BDQ - DESEJÁVEL.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18509441/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Construção de processos de ingestão de dados. Desenvolvimento de códigos utilizando-se das linguagens / tools citados abaixo: SQL Ferramenta de ETL Banco de dados (Oracle ou SQL Server ou Teradata) Ferramentas de BigData (Hadoop, Hive, Impala, HDFS) Metodologia Ágil Python Spark / Scala Shell Script. Ensino superior completo  Experiência com ELT  Experiência com desenvolvimento em SQL  Metodologia ágil
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18508624/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Desenvolvimento de códigos utilizando-se das linguagens / tools citados abaixo: SQL. Ferramenta de ETL. Banco de dados (Oracle ou SQL Server ou Teradata). Ferramentas de BigData (Hadoop, Hive, Impala, HDFS). Metodologia Ágil. Python. Spark / Scala. Shell Script. Outros detalhes do trabalho: 1 - Analytics Solution Architecture (P1 - Beginner) | 2 - Big Data Analytics (P1 - Beginner). Primary Skill. Others (Please note the Skill at the beginning of Job Description). Construção de processos de ingestão de dados. Ensino Superior Completo
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18468637/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Responsável por criar novas ingestões usando componentes Google Cloud Plataform. Responsável por manutenções em ingestões e processos usando componentes Hadoop (Hortonworks). Deverá desenvolver novas ingestões, transformações de dados com a automação do pipeline de implantação, monitoramento e testes de seu desenvolvimento. Ficará alocado em squad ágil e seguirá o backlog de atividades dado pelo Porduct Owner da equpe. Vivência/experiência com modelo ágil de desenvolvimento de produto/software (ex: SCRUM, KANBAN, etc). Experiência relevante em pelo menos um dos abaixo: O Java, Python, Spark, Scala. Conhecimento em linguagem SQL. Conhecimento em banco de dados relacional (ex: Oracle). Conhecimento em criação de processos de carga de dados batch e streaming (origem e destino). Conhecimento em bancos de dados NOSQL (ex: HBase, Elastic Search, MongoDB, Hive). Experiência comprovada com cloud Google. Experiência com criação de pipelines de ingestão de dados usando Google Cloud. Desejável conhecimento de arquitetura de dados Big Data (Hadoop ou Google Cloud Platform). Desejável conhecimento na construção de Data Lakes e/ou Data Warehouses. Desejável conhecimento na construção de Dashboards. Desejável conhecimento em modelagem multidimensional . Inglês avançado/ técnico.  Idioma:  Inglês - Intermediário
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18472613/?origem_apply=busca-de-vagas&entrada_apply=direto;Avaré - SP (1);Propor, executar, validar, apresentar e implantar o uso de tecnologias e soluções para questões técnicas e também de negócios, através de ferramentas e arquiteturas projetadas para processamento de grande volume de dados, com foco em inovação, melhora na qualidade de dados e provendo insumos para novos produtos na empresa.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18451185/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Experiência em Hortonworks Nifi, com conhecimentos em Java. Experiência em AWS Glue com Python e PySpark, rodando em EMR Cluster. Experiência em Java/Python (desejável para backend) Experiência com metodologia Ágil. Inglês Avançado. Experiência com ferramentas de integração como: Matillion / Informática Cloud. Experiência com bancos de dados cloud como: Snowflake / AWS Redshift. Experiência com tecnologias como: AWS S3, Google Cloud Storage, Azure Data Lake Storage. Conhecimentos avançados em SQL. Construção e otimização de ETL. Experiência em pipelines streaming e batch Experiência com levantamento de requisitos.  Idioma:  Inglês - Fluente
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18246328/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar dentro do time de dados, traduzindo as demandas externas em produtos de dados Criar processos de ETL para alimentar o Data Lake e Data Warehouse Identificar e implementar a coleta de novas fontes internas e externas de dados Auxiliar a criação, manutenção e monitoramento do pipeline de dados Manutenção e evolução da modelagem de dados. Conhecimento em Cloud ( AWS ou GCP ) Experiência com SQL Experiência com bancos de dados Experiência com modelagem de dados Experiência com desenvolvimento em Python ou Java Vivência em implementação utilizando Big Data e Analytics Spark Conhecimento em metodologias ágeis Git Requisitos diferenciais: Sistemas de mensageria (Kafka/ Pub Sub / Kinesis) Experiência com Docker Conhecimento em ferramentas de orquestração (Airflow/Step Functions/Nifi) Experiência com sistemas distribuídos
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18467379/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);- Processamento e gestão de dados  - Inspeção de dados  - Limpeza de dados  - Trasnformação de dados  - Modelagem de dados  - Adequação dos dados para atender as regras de negócios  - Criação de Data Marts para as diversas áreas da empresa (BI, Financeiro, Comercial, Operacional)  - Automatização do envio de dados para os clientes - Banco de dados SQL (relacional)  - Banco de dados NoSQL (NÃO relacional)  - MongoDB  - Data Mart  - Modelagem Dimensional  - Modelagem Transacional  - ETL  - TypeScript  - Node.js
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18451033/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (4);Experiência com Python, AZURE, SAS Guide, Programação SAS avançada, aplicações do ecossistema Hadoop como (Hive, MapReduce, Storm, Flume, etc.) e Java Vivência em gerenciadores de Banco de Dados Oracle, SQL Experiência em Squads e Metodologia Ágil Atuação remota durante a pandemia, após este período, atuação híbrida em São Paulo (região da Faria Lima).
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18462627/?origem_apply=busca-de-vagas&entrada_apply=direto;Rio de Janeiro - RJ (1);Criação dos bancos de dados, migração de bases de dados e efetuar processos de ingestão. Conhecer Apache Beam ou Spark, linguagem Scala. Tecnologias: SQL Server, Redis, NiFi e Kafka (legado - Ghawk), Google Cloud SQL (MYSQL), Google bigQuery Google DataFlow, Google Pub/Sub e ElasticSearch.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18451071/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (2);Experiência em análise e desenho de processos Experiência em AZURE, SAS Guide, Programação SAS avançada, aplicações do ecossistema Hadoop como (Hive, MapReduce, Storm, Flume), Python e Java Vivência em gerenciadores de Banco de Dados Oracle, SQL Experiência em Squads e Metodologia Ágil Vivência com banco de dados relacionais e linguagem SQL (SQL Server e Oracle) Conhecimento em soluções de exploração de dados (Power BI, Tableau, SAS VA, outros) Noções de Analytics Experiência no segmento de varejo / e-commerce Conhecimento de soluções de exploração de dados (Power BI, Tableu, SAS VA, outros) Noções de analytics. Planejamento e alinhamento dos requisitos funcionais e artefatos a serem entregues a cada solicitação de demanda. Interagir com os clientes desde o levantamento de requisitos até a apresentação do relatório final. Habilidades de gestão técnica do time. Planejar, priorizar, orientar e acompanhar.
Engenheiro(a) de dados;https://www.catho.com.br/vagas/engenheiroa-de-dados/18461858/?origem_apply=busca-de-vagas&entrada_apply=direto;Jaguariuna - SP (1);DESCRIÇÃO DA VAGA Nós acreditamos que a tecnologia revoluciona verdadeiramente quando ela é capaz de mudar hábitos, facilitando a vida das pessoas.  Você vai trabalhar com um time multidisciplinar, com diferentes skills com o mesmo objetivo: Entregar a melhor experiência para seus usuários e clientes.    Você fará parte de um time, com interesse único de entregar tudo o que está por trás do negócio, sua escalabilidade e seu crescimento contínuo.  RESPONSABILIDADES E ATRIBUIÇÕES Você vai trabalhar com um time multidisciplinar, com diferentes skills com o mesmo objetivo: Entregar a melhor experiência para seus usuários.    Você fará parte de um time, com interesse único de entregar tudo o que está por trás do negócio, sua escalabilidade e seu crescimento contínuo. Se você tem paixão por trabalhar com dados que terá impacto na vida dos clientes, então você achou a sua oportunidade perfeita!    -Construção/consolidação e automação de dados  -Construção de dashboards em Power Bi REQUISITOS E QUALIFICAÇÕES Python Paixão por engenharia de alta qualidade SQL / NoSQL databases Automação de dados RPA Azure Graduação em Computer Science/Engineering Data modeling
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18462792/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar na arquitetura de dados assim como em Hadoop, HDFS, Hive, Python, Scala, Shell script e SQL. Desejável vivência em ambientes cloud e metodologias ágeis.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18462780/?origem_apply=busca-de-vagas&entrada_apply=direto;Recife - PE (1);Atuar na arquitetura de dados assim como em Hadoop, HDFS, Hive, Python, Scala, Shell script e SQL. Desejável vivência em ambientes cloud e metodologias ágeis.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18455383/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Analisar, descrever, especificar, desenvolver, alterar, validar, implantar e manter os fluxos de dados, serviços e micro serviços, visando a ampla utilização da informação para integração de sistemas. Trabalhar junto aos arquitetos de dados e analistas de sistemas dentro de uma metodologia ágil, provendo o pipeline para extração, transformação de carga de dados estruturados com fontes diversas e heterogêneas, realizando tratamentos automatizados para garantir a qualidade e veracidade da informação. Vivência em liderança de SQUAD. Banco de Dados (SQL-Server, PostgreSQL, MongoDB), ETL (SSIS) e Modelagem Dados (SQL, SSAS, NoSQL), Foco em Java e ETL de SQL, não precisa Big Data (Hadoop, Spark...) nem IA/Ciência de Dados (Python, R, Machine Learning...)   Idioma:  Inglês - Intermediário
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18429162/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Implementação de infraestrutura e arquitetura de dados necessária para que o Cientista de Dados e a empresa possa fazer o uso adequado dos seus dados e transformando-os em informação, novos negócios e receita. Experiência em atuar de mãos dadas com o Cientista de Dados, sempre alinhados e com apoio das demais equipes da empresa. Responsável por planejar e desenvolver a arquitetura de dados, mantê-la atualizada e torná- la escalável. Ensino Superior completo em Ciências da Computação, Análise de Sistemas e Sistemas de Informação ou cursos correlatos Inglês. Conhecimentos avançados e práticos com bancos de dados SQL, PostgreSQL, TimescaleDB@PostgreSQL e MongoDB Conhecimentos avançados e práticos com API - Request/Response e em plataforma Microsoft Azure (Cloud) Databricks, DataFactory e Synapse Experiência em desenvolver, construir, testar e manter a arquitetura de dados Alinhar arquitetura de dados com requisitos de negócios Utilizar linguagem de programação e ferramentas adequadas para ingestão de dados e modelagem de dados Identificar maneiras de melhorar a confiabilidade, a eficiência e a qualidade dos dados Preparar dados para modelagem preditiva e prescritiva Entregar atualizações dos dados ao Cientista de Dados para que possibilite realizar as análises necessárias Conhecimentos básicos sobre Arquitetura de Soluções, intermediário sobre Arquitetura de Sistemas Distribuídos.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18432774/?origem_apply=busca-de-vagas&entrada_apply=direto;Jaguariuna - SP (1);Construção/consolidação e automação de dados.  Construção de dashboards em Power BI. Python, Paixão por engenharia de alta qualidade, SQL / NoSQL databases, Automação de dados RPA, Azure, Graduação em Computer Science/Engineering, Data modeling.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18413963/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (2);Atuar com Mining e Big Data (Extração de dados, expertise em job SQL Server e automatizações de processos), procedures e functions em SQL, criação de dashboards usando Tableau, Power BI ou ferramentas similares. Implementação em ambiente cloud (Azure, AWS, etc), desenvolvimento de algoritmos para aplicação em larga escala, desenvolvimento de modelos de ML/ Modelagem Preditiva, dados não estruturados. PHD ou Mestrado em Ciências de Dados, Computação, matemática, física, estatística ou afins. Conhecimentos em Python ou R. Capacidade de comunicação e apresentação verbal e escrita, capacidade de transmitir conceitos matemáticos a não-peritos, conhecimentos em arquitetura de dados (experiencia como DBA).
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18413051/?origem_apply=busca-de-vagas&entrada_apply=direto;Barueri - SP (1);Implementar soluções de extração de dados.  Monitoramento do ambiente mantendo a infraestrutura de execução  Liderar novas propostas tecnológicas para evolução da plataforma e melhoria dos processos.  Gerenciar o volume, variedade, velocidade e veracidade dos dados no Data Lake  Monitorar e assegurar a execução dos pipelines de extração de dados  Acompanhar a resolução dos problemas quando encontrados.  Trabalhar em conjunto com equipes de: negócios, governança  Garantir que as soluções sejam escaláveis, com baixa latência e resiliência. Conhecimento em ETL, Unix  Conhecimento em processamento de dados em larga escala, processamento paralelo e distribuído  Linguagens de programação Python, Java ou Scala  Conhecimento em banco de dados NoSQL, SQL e Chave-valor  Computação em nuvem como Azure/Google Clouds  Datafactory, Databricks, Datalake, Utilização de serviços serverless  Processamento de dados em Batch e Streaming  Práticas de DevOps e infraestrutura como código  Conhecimento para desenvolver e gerenciar a Plataforma de Dados garantindo a sua aderência às necessidades tecnológicas e de negócios  Conhecimento em tecnologias de Big Data incluindo Hadoop, Spark, NiFi, Flume, Sqoop, Airflow, Kafka e hbase.
Engenheiro de Dados;https://www.catho.com.br/vagas/engenheiro-de-dados/18413277/?origem_apply=busca-de-vagas&entrada_apply=direto;Belo Horizonte - MG (1);Criação dos bancos de dados, migração de bases de dados e efetuar processos de ingestão. Ensino Superior. Experiência na linguagem NodeJs, experiência nas ferramentas de Dados da AWS, experiência em trabalhar com ETLs, experiência em tecnologias Datalake / Datawarehouse / Datamarts, experiência em tecnologias de streaming de dados (Kinesis / Kafka) Experiência em SQL. Será um diferencial se você tiver: Experiência avançada na linguagem NodeJs, experiência em trabalhar com CDC (Change Data Capture).  Idioma:  Inglês - Intermediário
Engenheiro de Dados Azure;https://www.catho.com.br/vagas/engenheiro-de-dados-azure/18595881/?origem_apply=busca-de-vagas&entrada_apply=direto;Brasilia - DF (1);4 anos de experiência como engenheiro de dados Experiência com o banco de dados Azure Com certificação em DP-200 e DP-201 OU DP-203. ?Experiência de 04 anos como engenheiro de dados ?Experiência com o banco de dados Azure ?Com certificação em DP-200 e DP-201 OU DP-203 Faixa Salarial ? Remuneração: 13.000,00 PJ ou CLT (+ Benefícios) Interessados encaminhar currículo para: rh5.vagastecnologia@gmail.com com o título: Engenheiro de Dados Azure
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18512760/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);O profissional estará encarregado de contribuir para o projeto de implementação de Sistemas escaláveis de ETL e processamento de dados para entrar em nosso ecossistema de Big Data. Construir e escalar a plataforma de análise interna, relatórios e decisões internas. Juntamente com o arquiteto de engenharia e infraestrutura, desenvolver melhorias na estratégia de dados, qualidade e governança. Colaborar com os arquitetos, proprietários de produtos, cientistas de dados e engenheiros de teste para ajudar a trazer projetos de R&D de Ciência de Dados para a produção. Gerenciar a infraestrutura de dados, para crescer e apoiar a equipe de Ciência e Engenharia de Dados, em relação à construção de produtos de dados performantes. Estabelecer a direção técnica para a equipe, impulsionando as mudanças necessárias e fazendo escolhas tecnológicas adequadas. Requisitos: AWS Python Terraform, Docker e Kubernetes Data Warehouse/Data Lake e ETL Spark, Spark Streaming, Hive, Storm, Sqoop, Kafka, Hbase e/ou HDFS SQL/NoSQL Métodos ágeis Disponibilidade para viagens, pois irá atuar com o time técnico de São Francisco e Singapura e eventualmente será necessário viajar para outras unidades Inglês avançado/fluente, diferencial para espanhol Curso superior na área de tecnologia/ exatas. Experiência com: Engenharia de Dados com serviços AWS Codificação de nível de produção em Python Projetos de arquiteturas de Data Warehouse/Data Lake e ETL com tecnologias de Big data como Spark, Spark Streaming, Hive, Storm, Sqoop, Kafka, Hbase e HDFS. SQL/NoSQL como MongoDB, Cassandra, Solr, Elasticsearch, Redshift, DynamoDB Processos Ágeis e Scrum.
Engenheiro de Dados - Scala;https://www.catho.com.br/vagas/engenheiro-de-dados-scala/18595882/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (2);Isso mesmo estamos com a vaga que você tanto procurava Engenheiro de Dados - Scala. 100% Remoto com Auxílio Home Office. R$ 10.000,00 CLT + Benefícios (VA, VT, Plano de Saúde, Gympass). Requisitos -Experiência Linguagem Scala -Framework de processamento distribuído Scala - Spark Hadoop -Big Data -Conhecimento básico em Java. Desejável -Conhecimento em Cloud Azure.
Engenheiro de Dados Azure;https://www.catho.com.br/vagas/engenheiro-de-dados-azure/18249333/?origem_apply=busca-de-vagas&entrada_apply=direto;Campinas - SP (1);Suas principais responsabilidades serão: Engenheiro de Dados Sênior com experiência em processos de ingestão de dados, para atuar em processo de ingestão de dados baseado em PySpark (Databricks) e Azure Data Factory como orquestrador dos pipelines. Será o responsável pelo desenvolvimento e manutenção do fluxo da carga e garantia da qualidade dos dados. O que buscamos: Databricks Pyspark Azure Data Factory Azure Data Lakes (Storage Account Gen2). Processos ETL em Data Lake Conceitos das camadas bronze, silver e gold de um Data Lake. Inglês Fluente. Conhecimentos desejáveis: Já ter atuado em projetos com times globais.  Idioma:  Inglês - Fluente
Engenheiro de Dados Pleno;https://www.catho.com.br/vagas/engenheiro-de-dados-pleno/18607930/?origem_apply=busca-de-vagas&entrada_apply=direto;Osasco - SP (1);Construir e customizar pipeline de dados batch e realtime. Programar e dar manutenção em códigos escritos em R, Python e/ou Java. Definir e construir banco de dados relacionais com arquitetura distribuída para processamento de Big Data. Extrair, transformar e carregar (ETL) dados de um banco de dados para outro. Analisar requerimentos dos usuários. Pesquisar, desenhar e desenvolver novos programas de software. Testar novos programas e procurar por falhas. Experiência (quando aplicável no projeto) em Cloud (AWS, Azure, IBM) - provisionamento de ambiente, conectividade, desenvolvimento e consumo de APIs. Experiência comprovada em Engenharia de dados. Experiência e/ou conhecimento com as seguintes tecnologias: Hadoop, MapReduce, Spark, HBase, Hive, Teradata, Kafka. Preferencialmente com familiaridade nas distribuições Horton / Cloudera. Proficiência em Linux incluindo construção de shell script. Experiência na arquitetura da plataforma SAS, Teradata, Greenplum e ecossistema Hadoop. Conhecimento e experiência avançada com SQL. Conhecimento e experiência com produtos e serviços das áreas de negócios de instituições financeiras.
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18578338/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar como Engenheiro de Dados Generalista em atividades relacionadas à ciência de dados e data analytics. Colaborador com o desenvolvimento do processo para adequações ao LGPD. Atuar na construção de um sistema robusto. Trabalhar na atualização constante de melhores práticas com relação a segurança da informação. Ser alguém que deseja ser protagonistas de sua carreira e que tenha vontade de gerar impactos e transformações positivas em seu redor Conhecimento na língua inglesa. Atuamos em times e projetos globais, por isso este conhecimento é fundamental em seu dia a dia Graduação completa em Engenharias, Ciências da Computação, Matemática e áreas correlatas. Experiência em BI / Big Data, modelagem de dados, construção de pipelines usando sistemas distribuídos, como Hadoop e/ou Spark Experiência no processo de Mineração de Dados. Experiência prática com ingestão, integração, processamento e armazenamento de grandes volumes de dados. Conhecimento na Lei de Proteção à Dados (LGPD). Conhecimento Programação em linguagens como: Python, R, Scala ou Java Experiência com bancos de dados relacionais como: SQL Server, Oracle e MySQL. Experiência com bancos de dados NoSQL. Experiência na utilização dos conceitos de classificação e previsão de dados para construção de modelos de machine learning. Experiência no processo de preparação de dados. Limpeza, Enriquecimento, codificação e feature engineering. Conhecimento em engenharia de atributos.
Engenheiro de Dados - Oncologia;https://www.catho.com.br/vagas/engenheiro-de-dados-oncologia/18479047/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Quais serão suas principais atividades? Desenvolver e cuidar do Data Lake, do funcionamento e do correto uso dos dados da Oncologia por parte de outras áreas Desenvolver rotinas ETL Construir integrações com novas APIs e sistemas de mensageria que deem suporte ao crescimento contínuo em volume e complexidade de dados Implementar processos e sistemas para monitorar a qualidade dos dados, garantindo que as informações disponíveis para tomadas de decisão estejam acuradas com os dados de produção Desenvolver e manter datawarehouses modernos e datamarts da companhia, possibilitando a tomada de decisão de diversas áreas de negócio Trabalhar próximo aos demais engenheiros de backend , cientistas de dados, analistas de dados, product owners e analistas de qualidade Implantar programas analíticos sofisticados, Machine Learning e métodos estatísticos Preparar dados para modelagem preditiva e prescritiva Encontrar padrões ocultos usando dados. O que você precisa para se inscrever? Superior Completo em Ciências da Computação, Engenharia da Computação, Sistemas de Informação, Análise e Desenvolvimento de Sistemas ou áreas correlatas) Experiência com ferramentas de processamento de dados distribuídos (Hadoop, Hive, Spark, Flink, Beam, Storm, Samza) e em prototipação e desenvolvimento de ETL Conhecimento de ferramentas Cloud (AWS e/ou GCP), Linux e em desenvolvimentos de APIs Rest Experiência com banco de dados relacionais e não relacionais (NoSQL) Prática em linguagem Python, Scala ou Java Conhecimento avançado em SQL Experiência de trabalho em times ágeis utilizando metodologia Scrum ou Kanb. O que oferecemos? Ticket Refeição. Ticket Alimentação. Plano de Saúde (após os 90 dias de experiência). Plano Odontológico (após os 90 dias de experiência). PLR. Além dos benefícios citados acima, temos descontos em estabelecimentos credenciados, auxílio educacional, programas de qualidade de vida e um programa de apoio psicológico, financeiro, jurídico e social. Você trabalhará na unidade Corporativa, na Avenida Paulista, de segunda à sexta-feira em horário comercial.
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18625795/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);A empresa multinacional especializada em Management Consulting, Business Intelligence, Big Data, Web Performance, e-Commerce, Omni Channel e soluções ERP-CRM. Desenvolvimento técnico das tarefas combinadas usando as tecnologias propostas. Capacidade de análise de soluções apropriadas e criá-las tecnicamente, com a qualidade apropriada (testes em QA, criação de massas de testes, etc).  Participação ativa nos ritos do Scrum como integrante do time, como daily meetings, plannings (poker), apresentação de resultados em review. Perfil desejado: Shellscript. Python. Tecnologias hadoop (hive, phoenix, spark, yarn e seus conceitos inerentes à computação em cluster). Criação de queries analíticas em SQL/Spark SQL. Conhecimentos de programação funcional usando Scala. Ótimos conhecimentos de GCP "nativo" (cloud functions, dataproc, cloud build, etc..). Perfil comportamental: Trabalho em equipe, boa comunicação, boa organização, comprometimento e pró-atividade,
Engenheiro (a) de Dados (SAP);https://www.catho.com.br/vagas/engenheiro-a-de-dados-sap/18605989/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Experiência e bons conhecimentos em Data Factory  Experiência e bons conhecimentos em Data Lake Storage  Experiência em desenvolvimento e modelagem de Data Warehouse  Experiência com Origens de dados SAP Data Services, SAP Hana, SAP ECC, SAP BW  Azure. Requerido  Experiência e bons conhecimentos em Data Factory  Experiência e bons conhecimentos em Data Lake Storage  Experiência em desenvolvimento e modelagem de Data Warehouse  Experiência com Origens de dados SAP Data Services, SAP Hana, SAP ECC, SAP BW  Azure.
Engenheiro (a) de Dados (Python);https://www.catho.com.br/vagas/engenheiro-a-de-dados-python/18606006/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Experiência e bons conhecimentos em Data Factory  Experiência e bons conhecimentos em Data Lake Storage  Experiência em desenvolvimento e modelagem de Data Warehouse  Experiência e bons conhecimentos em Python  Azure. Experiência e bons conhecimentos em Data Factory  Experiência e bons conhecimentos em Data Lake Storage  Experiência em desenvolvimento e modelagem de Data Warehouse  Experiência e bons conhecimentos em Python  Azure.
Engenheiro de Dados - Splunk;https://www.catho.com.br/vagas/engenheiro-de-dados-splunk/18607876/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Splunk Enterprise, criação de painéis, otimização de consultas e melhorias de performance, criação de comandos em python. Experiência Splunk Enterprise. Experiência em ingestões. Experiência em criação de painéis, otimização de consultas e melhorias de performance. Experiência em criação de comandos em python. Experiência ambiente BigData (HDFS, Hive, Spark, HBase), Linux / Shell Script, Python, SQL.
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18609143/?origem_apply=busca-de-vagas&entrada_apply=direto;Belo Horizonte - MG (1);Atividades relacionadas a ciência de dados e data analytics. Experiência na área de BI / Big Data, modelagem de dados, construção de pipelines usando sistemas distribuídos, como Hadoop e/ou Spark Conhecimento Programação em linguagens como: Python, R, Scala ou Java Experiência com bancos de dados relacionais como: SQL Server, Oracle e MySql Experiência com bancos de dados NoSQL. Experiência na utilização dos conceitos de classificação e previsão de dados para construção de modelos de machine learning. Experiência no processo de preparação de dados. Limpeza, Enriquecimento, codificação e feature engineering. Conhecimento em engenharia de atributos. Experiência no processo de Mineração de Dados. Experiência prática com ingestão, integração, processamento e armazenamento de grandes volumes de dados Conhecimento na Lei de Proteção à Dados (LGPD)
Engenheiro de dados Pleno;https://www.catho.com.br/vagas/engenheiro-de-dados-pleno/18598792/?origem_apply=busca-de-vagas&entrada_apply=direto;Rio de Janeiro - RJ (1);Extração de dados (APIs, DB relacionais e não relacionais e web scraping)  Estruturar, desenvolver e monitorar fluxos ETL  Fazer a manutenção e monitoramento de sistemas legados  Colaborar com o time de Dados, Editorial e Produtos para novos produtos e novos processos  Desenvolver Data Lake e otimizar a disponibilização de dados para toda a empresa Conhecimento sólido em Python e Sql  Experiência no funcionamento e manutenção de banco de dados, principalmente PostgreSQL  Conhecimento em soluções em nuvem  Experiência em PowerBI, Metabase, Redash ou similares  Desejáveis:  Experiência com mercado financeiro/capitais  Conhecimento em Java e Groovy  Experiência com programação em R  Iniciativa  Idioma:  Inglês - Fluente
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18600660/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Entendimento funcional do requisito de negócio e traduzir para fluxo de dados. Modelagem de dados em Hive/HBase. Implementação de fluxos de dados (pipelines) utilizando principalmente com Spark para distribuição e processamento paralelo. O destino de dados pode ser arquivos, API, ElasticSearch ou SFTP. Linguagem de programação com Scala. Implementação de fluxos de dados com arquitetura orientada a eventos (Apache Kafka), utilização de padronização de tipo de mensagem Avro/protobuf/json. Ensino Superior completo.
Engenheiro de Dados Pleno;https://www.catho.com.br/vagas/engenheiro-de-dados-pleno/18585541/?origem_apply=busca-de-vagas&entrada_apply=direto;Florianópolis - SC (1);Análise desenho de soluções de arquitetura de dados na busca das melhores soluções para cada problema, desenvolver,?manter?e monitorar?pipelines de ingestão de dados, monitorar a performance e propor melhorias na infraestrutura?cloud, criar e manter a estrutura de dados data?lake?+ data warehouse, criar e monitorar?testes e?métricas?para?qualidade de dados.  Criar e monitorar?testes e?métricas?para?segurança dos dados.
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18559226/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Irá atuar com soluções de dados. Ferramentas para manipulação de dados (R, Python...) Conhecimento em extração e análise de dados Conhecimento em modelagem de dados Levantamento de necessidades e definições de formato de integração de dados Automatizar integrações de bases com o Data Lake
Engenheiro de Dados - Pleno;https://www.catho.com.br/vagas/engenheiro-de-dados-pleno/18567734/?origem_apply=busca-de-vagas&entrada_apply=direto;Fortaleza - CE (1);Projeto, modelagem, desenvolvimento e manutenção de data Warehouses e data marts/feature stores para atender às diversas necessidades do negócio. Projeto e o desenvolvimento de pipelines de transferência e transformação de dados (ETL) para a integração e consolidação de diferentes bases de dados. Projeto e desenvolvimento de arquiteturas de sistemas de dados eficientes e escaláveis que atendam às demandas de uso de grandes quantidades de dados em projetos de ciência de dados. Manutenção e otimização de sistemas existentes de gerenciamento de bancos de dados e de coleta de informações. Criação de pipelines para integrar e automatizar todo o fluxo da solução, desde a coleta até a disponibilização dos resultados. Ensino Superior completo Ciência da Computação, Engenharia de Software, Sistemas de Informação e afins. Conhecimento e/ou experiência nos fundamentos e conceitos de data warehousing. Experiência com a Linguagem SQL. Conhecimentos em linguagem Python e Scala. Conhecimentos e/ou experiência com sistemas de gerenciamento de bancos dados relacionais (RDBMS) diversos, incluindo MySQL, Postgres. Conhecimentos e/ou experiência em ferramentas para criar, agendar e monitorar workflows relacionados a ETL e aprendizado de máquina (e.g. Apache Airflow, Luigi). Compreensão da arquitetura de sistemas distribuídos de armazenamento, gerenciamento e processamento de dados (sistemas "Big Data") como os componentes do ecossistema Spark e/ou Hadoop. Desejáveis: Conhecimento com sistemas NoSQL (Cassandra) será um diferencial. Conhecimento e/ou experiência em desenvolvimento e arquitetura de software. Conhecimento e/ou experiência com sistemas de monitoramento e supervisão. Conhecimento em ferramentas e/ou bibliotecas de Data Science (e.g. Sklearn Tensorflow, Keras, Pytorch). Experiência em frameworks de processamento de stream de dados (Apache Kafka, Apache Flink, Spark Stream ...). Inglês intermediário para conversação, reuniões com Stakeholders e time de business, envios de emails e leitura e produção de documentação.
Engenheiro de Dados ESP;https://www.catho.com.br/vagas/engenheiro-de-dados-esp/18554611/?origem_apply=busca-de-vagas&entrada_apply=direto;Brasilia - DF (1);Desenvolvimento de microserviços e APIs. Algoritmos de Machine Learning. Conhecimento das distribuições Big Data (Cloudera, Hortonworks, etc.). Conhecimentos de técnicas de testes (unitários, integrados, etc.). Experiência em times ágeis e/ou distribuídos globalmente. Experiência com bancos NoSQL (Hbase, MongoDB, etc.). Experiência na criação de rotinas de preparação de dados para análises (ETL). Experiência com a linguagem de programação Scala com Apache Spark. Experiência com ferramentas de DevOps (Jenkins, Kubernetes, Docker, etc.). Experiência com desenvolvimento na stack ELK (ElasticSearch) Experiência com desenvolvimento Neo4j. Desejável: - Fluência em Inglês (leitura, escrita, conversação, técnico). Experiência com desenvolvimento em ambiente Cloud (AWS, Azure, GCP). Experiência com a linguagem de programação Python (Pandas, Numpy, Boto, Airflow, etc). Experiência em desenvolvimento de microserviços e APIs. Conhecimentos de algoritmos de Machine Learning.
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18521157/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Analisar demandas, definir soluções e desenvolver com autonomia. Definir e acompanhar monitorações de integrações. Desenvolver e acompanhar todo o processo de implantação em produção. Arquitetar sistemas distribuídos. Criar pipelines confiáveis. Combinar fontes de dados. Colaborar com a equipe de Dados e construir as soluções certas para essas equipes. Bacharelado em Tecnologia e Sistemas. Inglês avançado - comunicação e escrita. Ter vivência com metodologia ágil (Scrum e Kanban). Conhecimentos avançados em Java e frameworks Spring, linguagens Javascript, Groovy, Python, DevOps, Docker e Kubernets, Cloud, SOA, modelagem e/ou desenvolvimentos de interfaces REST, Angular, Banco de dados Oracle e Bigdata. Atuação no desenvolvimento de microsserviços e APIs. Conhecimento em Cloud (GCP, AZURE). Seria interessante também ter: MBA em Projetos de Sistemas  Idioma:  Inglês - Fluente
Engenheiro de Dados Corporativo;https://www.catho.com.br/vagas/engenheiro-de-dados-corporativo/18507374/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Construir, avaliar e executar scripts de atualização de dados de forma performática. Criar modelagem e persistência de dados, com as melhores práticas. Criação de modelagem de dados relacional e não relacional. Criação de pipelines no jenkins e infraestrutura na AWS para a estrutura de dados. Produzir análises detalhadas sobre comportamento de usuários, modelos estatísticos, fontes de dados, etc. Descobrir e avaliar a relevância de novas fonte de dados. Conhecimento no desenvolvimento com a linguagem Python. Conhecimento nos serviços da AWS (SQS, S3 e EC2). Criação de pipelines no Jenkins. Domínio do Jypiter Notebooks. Experiência com bancos de dados e tecnologias relacionadas (SQL, noSQL). Experiência em trabalhar com ferramentas e linguagens voltadas à análise de dados.
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18494995/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar com técnicas de captura, tratamento e estruturação de dados em arquitetura de processamento de dados com escalonamento horizontal (big data, cloud computing PaaS etc). Operar sistemas operacionais Linux (centos, RHEL), Shell comandos básicos e intermediários, edição de arquivos com VIM, Python, Scala com Spark, conceitos de MPP, Kubernetes, criar VMs, GCP DataProc, Cloud Storage,  Airflow, Devops (git, jenkins, pipeline de deploy, Jira, Confluence). Boa comunicação e proatividade, aberto a conhecer novas tecnologias no cliente. Certificações Cloud (GCP preferencialmente).  Idioma:  Inglês - Intermediário
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18481914/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Analisar demandas, definir soluções e desenvolver com autonomia. Definir e acompanhar monitorações de integrações. Desenvolver e acompanhar todo o processo de implantação em produção. Arquitetar sistemas distribuídos. Criar pipelines confiáveis. Combinar fontes de dados. Colaborar com a equipe de Dados e construir as soluções certas para essas equipes. Bacharelado em Tecnologia e Sistemas. Inglês avançado ? comunicação e escrita. Ter vivência com metodologia ágil (Scrum e Kanban). Conhecimentos avançados em Java e frameworks Spring, linguagens Javascript, Groovy, Python, DevOps, Docker e Kubernets, Cloud, SOA, modelagem e/ou desenvolvimentos de interfaces REST, Angular, Banco de dados Oracle e Bigdata. Atuação no desenvolvimento de microsserviços e APIs. Conhecimento em Cloud (GCP, AZURE). MBA em Projetos de Sistemas.
Engenheiro de Dados - SAP;https://www.catho.com.br/vagas/engenheiro-de-dados-sap/18468456/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Identificar e implementar a coleta de novas fontes internas e externas de dados. Auxiliar a criação, manutenção e monitoramento do pipeline de dados. Experiência e bons conhecimentos em Data Factory. Experiência e bons conhecimentos em Data Lake Storage. Experiência em desenvolvimento e modelagem de Data Warehouse. Experiência com Origens de dados SAP Data Services, SAP Hana, SAP ECC, SAP BW.
Engenheiro de Dados - Python;https://www.catho.com.br/vagas/engenheiro-de-dados-python/18468331/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Requisitos: Experiência e bons conhecimentos em Data Factory. Experiência e bons conhecimentos em Data Lake Storage. Experiência em desenvolvimento e modelagem de Data Warehouse. Experiência e bons conhecimentos em Python. Contratante: Importante empresa do segmento de consultoria voltada para  BI e Big Data.
Engenheiro de Dados - Python;https://www.catho.com.br/vagas/engenheiro-de-dados-python/18468492/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Experiência e bons conhecimentos em Data Factory. Experiência e bons conhecimentos em Data Lake Storage. Experiência em desenvolvimento e modelagem de Data Warehouse. Experiência e bons conhecimentos em Python.
Engenheiro de Dados - Microstrategy;https://www.catho.com.br/vagas/engenheiro-de-dados-microstrategy/18475196/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atua com processos de desenvolvimento estruturado que se estende do conceito ao projeto dos sistemas Microstrategy e Cognos. Ter experiência na função. O nível de utilização destas tecnologias no projeto é 90% Microstrategy e 10% Cognos.
Engenheiro de Dados - BI;https://www.catho.com.br/vagas/engenheiro-de-dados-bi/18431769/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Responsável por capturar, gerir e garantir a qualidade dos dados através de diversas ferramentas das áreas. Desenvolver todo processo de ETL construindo, testando e mantendo a solução, onde todos os dados são extraídos, limpos, organizados, integrados e disponibilizados. Responsável pela implementação e melhoria contínua da plataforma de dados. Utilizará ferramentas para avaliar, integrar e disponibilizar os dados da forma mais adequada e performática possível Elaborar relatórios/Dashboards em Power BI utilizando modelos e visões avançadas, automatizando as entregas e garantindo a qualidade das informações. Criar métricas, KPI&#39s, extrair, tratar e comparar dados através das bases das ferramentas das áreas, bases de mercado e concorrência. Manter as atividades com controle de progresso e quando necessário com o follow-up adequado internamente. Atender e realizar atividades profissionais correlatas e inerentes ao cargo, conforme orientação e solicitação do superior imediato.
Engenheiro de Dados (AWS);https://www.catho.com.br/vagas/engenheiro-de-dados-aws/18462887/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuação com linguagens SQL, Python, Scala e Java, modelagem e manipulação de grandes volumes de dados. Domínio em plataforma AWS (AWS Bucket S3, AWS Redshift). Modelagem de Dados (SQL e NoSQL). Experiência com ferramentas de data quality (AWS Deequ, GreatExpectations). Experiência em criação de pipeline. Experiência em ferramentas de versionamento (Git). Conhecimento em arquitetura de dados e governança. Estar ambientado em projetos com metodologias e frameworks Ágeis.
Engenheiro de Dados Pleno;https://www.catho.com.br/vagas/engenheiro-de-dados-pleno/18455398/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Desenvolver, construir, testar e manter a solução (Plataforma de Dados), onde todos os dados são extraídos, limpos, organizados, integrados e disponibilizados com Gestão e Governança. Conhecer os processos e interage com outras áreas de Datos & Tecnologia, assim como de Negócio. Saber traduzir necessidades de usuários de negócio em requisitos técnicos para criação de novas features para a plataforma de dados. Responsável pela implementação e melhoria contínua da Plataforma de Dados, utilizará ferramentas para avaliar, integrar e disponibilizar os dados da forma mais adequada e performática possível, apresentando os trade-offs adequados para cada contexto. Requisitos mandatórios: Agile (Scrum/Kanban), DevOps (CI/CD), PowerBI, Control-M, RDBMS, NoSQL, Impala, Hive e Spark. Cloud - Experiência em pelo menos uma das três principais plataformas (AWS, Azure e GCP). Hadoop Ecosystem (on premises e gerenciado em nuvem, EMR/HDInsights). SQL / NoSQL (databases, paradigmas e modelagem). Data Warehousing & Data Lakes. Python, Scala e/ou Java (core e Spark batch/streaming). Mensageria/Real time (Kafka, Flume e SQS ). APIs e Microsserviços. Testes e DevOps (CI/CD).   Idioma:  Inglês - Intermediário
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18455435/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Microsserviços. Arquitetura Lambda, Kappa e orientada a eventos MLFlow. Vivência no mercado financeiro. web scrap. Git Construção de API Formação em Ciências da Computação, Engenharia da Computação, Sistemas de Informação, Análise e Desenvolvimento de Sistemas ou áreas correlatas. Conhecimento avançado em Python, Scala ou Java. Conhecimentos básicos em Linux. Conhecimentos básicos em AWS ou Azure. Conhecimento avançado em SQL. Conhecimento em banco de dados relacionais e não relacionais. Experiência com processamento de dados (Streaming e Batch). Experiência com CDC - Change Data Capture. Raciocínio lógico e pensamento analítico. Experiência ferramentas como Hadoop, Spark, Hive, Kafka, Airflow, Databricks. Noções de kubernetes e docker.   Idioma:  Inglês - Intermediário
Engenheiro de Dados-Conrado;https://www.catho.com.br/vagas/engenheiro-de-dados-conrado/18453863/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Profissional que gerencia, otimiza, supervisiona e monitora a recuperação. responsável pelos armazenamento e distribuir os dados. Atuar com sql e postgree.
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18428802/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Analisar demandas, definir soluções e desenvolver com autonomia. Definir e acompanhar monitorações de integrações Desenvolver e acompanhar todo o processo de implantação em produção. Arquitetar sistemas distribuídos. Criar pipelines confiáveis. Combinar fontes de dados. Colaborar com a equipe de Dados e construir as soluções certas para essas equipes. Ensino Superior em Tecnologia e Sistemas. Inglês avançado. Comunicação e escrita. Vivência com metodologia ágil (Scrum e Kanban). Conhecimentos avançados em Java e frameworks Spring, linguagens Javascript, Groovy, Python, DevOps, Docker e Kubernets, Cloud, SOA, modelagem e/ou desenvolvimentos de interfaces REST, Angular, Banco de dados Oracle e Bigdata. Atuação no desenvolvimento de microsserviços e APIs Conhecimento em Cloud (GCP, AZURE).   MBA em Projetos de Sistemas.
Engenheiro de Dados de Qualidade;https://www.catho.com.br/vagas/engenheiro-de-dados-de-qualidade/18418595/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Conhecimento das ferramentas Informática DEQ e EDC Conhecimento da ferramenta Informática Data Engineering Quality (DEQ 10.4.1): Profile, Score Cards, Parsing Data, Standardizing Data, Mapplets Conhecimento da ferramenta Informática Enterprise Data Catalog (10.4.1): Integração com DEQ, Assets (Business Glossary, Tabular, Rule, Scorecard, Column and Field, Data Domain), Lineage, Impact View, Relationships View, Discover, Profiling, Import catalog/metadados. Configuração de Advanced Scanner Desejável: certificação nas ferramentas mencionadas.
Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-senior/18384191/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Desenvolvimento e implementação de componentes AWS - EMR, Cloud Formation, Glue, Athena, APIs, Integration Services Administração de bucket S3 e instâncias AWS EC2 para execução de componentes da plataforma de Analytics quando requerido. Migração de dados a partir de fontes como SAP ECC e 4Hana, Sales Force, sistemas legados c/ bd no SQL Server, dados não estruturados como planilhas/imagens/etc e plataformas digitais (redes sociais, sites de e-commerce internos e externos, dados de apps entre outros) para nosso DataLake na AWS. Desenvolvimento de Lambda Functions, armazenamento em nosso DW, datamarts e cluster Big Data. Integração de dados utilizando como destino banco de dados SQL e NoSQL (Azure SQL DW, Aurora, MariaDb, Redshift, DynamoDb, MongoDb entre outros). Criação e manutenção de scripts em Python e SQL (conhecimentos em R e NodeJs desejáveis conhecimentos em Kafka e Kinesis serão considerados diferenciais). Experiência com modelagem de dados e especificação de arquitetura de soluções de BI & Analytics seguindo melhores práticas e/ou design patterns recomendados internamente ou por fornecedores. Experiência atuando em projetos de médio/grande porte, relacionados a BI & Analytics. Experiência com implementação de soluções de BI tradicionais, EDW, e Big Data. Experiência de trabalho utilizando metodologias ágeis (Scrum, Lean, Kanban).
Engenheiro de Dados - Big Data;https://www.catho.com.br/vagas/engenheiro-de-dados-big-data/18593799/?origem_apply=busca-de-vagas&entrada_apply=direto;Brasilia - DF (1);Atuar com engenharia de dados - Big Data. Requisitos: Experiência em Linguagem Scala - Framework de processamento distribuído Scala - Spark Hadoop e Big Data, Conhecimento básico em Java. Desejável -Conhecimento em Cloud Azure.
Engenheiro de Dados Azure Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-azure-senior/18249326/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Suas principais responsabilidades serão:    Engenheiro de Dados Senior responsável pelo fluxo de ingestão de dados:    Construir pipelines de extração de dados de diversas fontes e armazenar em um Azure Data Lake, utilizando Python.  Suportar e monitorar a plataforma de dados do cliente.  Experiência com bancos de dados e tecnologias relacionadas tais como SQL Server, Oracle, Hadoop entre outros. O que buscamos:    Python  Databricks  Pyspark  Azure Data Factory  Azure Data Lakes (Storage Account Gen2)  Bancos de dados e tecnologias relacionadas tais como SQL Server, Oracle, Hadoop, entre outros.  Conhecimentos desejáveis:    Metodologia ágil Scrum/Kanban  Git (Azure DevOps)  Inglês Avançado  Idioma:  Inglês - Fluente
Engenheiro de Dados - Semantix Lab;https://www.catho.com.br/vagas/engenheiro-de-dados-semantix-lab/18559797/?origem_apply=busca-de-vagas&entrada_apply=direto;Campinas - SP (1);Procuramos engenheiro de dados com background de desenvolvedor para atuação com ingestão de dados e construção de aplicações analíticas para área da saúde.  Estratégias de ingestão (incrementall e full), conhecimento em particionamento Shell Script e ambiente Linux Linguagem Python e versionamento Git Conhecimento em sistema Tasy será um diferencial
Engenheiro de Dados/Sênior/Remoto;https://www.catho.com.br/vagas/engenheiro-de-dados-senior-remoto/18555006/?origem_apply=busca-de-vagas&entrada_apply=direto;Rio de Janeiro - RJ (1);Arquitetar, desenvolver e otimizar os sistemas de backend da startup Trabalhar em conjunto com o time de desenvolvimento de software e de produto para o desenvolvimento de sistemas de recomendação, análises em tempo real, e interação entre usuários Dividir projetos em subprojetos que possam ser delegados Ser mentor técnico do seu time. Humildade e paciência são importantes  Questionar sobre qualquer informação que é apresentada Desejável experiência relevante em desenvolvimento de grande complexidade Experiência em engenharia de dados Experiência substancial em revisão de códigos, documentação, Unit e integration testing experiência em engenharia de software, principalmente em python Conhecimento em desenvolvimento e consumo de APIs (Django e/ou NodeJS)   Experiência robusta com bases SQL e NoSQl (Postgres, Cassandra, DynamoDB) Mestrado ou maior grau em ciência da computação   Conhecimento de mercado financeiro  Idioma:  Inglês - Intermediário
Engenheiro de Dados - Sênior | Hadoop;https://www.catho.com.br/vagas/engenheiro-de-dados-senior-hadoop/18438373/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);No dia-a-dia o profissional atuará como PO com visão de Negócios para ajudar os times nas discussões para tomadas de decisão. Deverá ter entendimento de Arquitetura de Dados FastData, NearRealtime, Realtime, Batch e Modelagem de Dados, além de atuar como engenheiro de Dados, para construção de ingestão com base em requisitos das áreas de negócios, transformações de dados, construção de ETL batch, construção de ETL, Análise e Validação de Bases SQL e NoSQL, construção de Serviço para consumo de API. Ambiente Linux, Elasticsearch, Git e GitFLow, Hadoop (HDFS, Partionamento), Hbase, Hive, Jenkis, Python, Scala, Spark, SQL, SQL em Hive e Impala. Desejável: BIGTABLE BIGQUERY FIRESTORE STORAGE PUB/SUB PYTHON CLOUD FUNCTION.
Engenheiro de Dados Cloud - Pleno;https://www.catho.com.br/vagas/engenheiro-de-dados-cloud-pleno/18559946/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Engenheiro de dados, será responsável por criar novas ingestões usando componentes Google Cloud Plataform. Responsável por manutenções em ingestões e processos usando componentes Hadoop (Hortonworks).  Deverá desenvolver novas ingestões, transformações de dados com a automação do pipeline de implementação, monitoramento e testes de seu desenvolvimento.  Ficará alocado em squad ágil e seguirá o backlog de atividades dado pelo Product Owner da equpe. Hadoop (HDFS, Partionamento), Metodologia Ágil.                                                                       Vivência/experiência com modelo ágil de desenvolvimento de produto/software (ex: SCRUM, KANBAN, etc?)                                                                    Experiência relevante em pelo menos um dos abaixo: O Java, Python, Spark, Scala                                                                  Conhecimento em linguagem SQL Conhecimento em banco de dados relacional (ex: Oracle)                                                                     Conhecimento em criação de processos de carga de dados batch e streaming (origem e destino)                                                                      Conhecimento em bancos de dados NOSQL (ex: HBase, Elastic Search, MongoDB, Hive)                                                                         Experiência comprovada com cloud Google                                                                  Experiência com criação de pipelines de ingestão de dados usando Google Cloud                                                                    Desejável conhecimento de arquitetura de dados Big Data (Hadoop ou Google Cloud Platform) Desejável conhecimento na construção de Data Lakes e/ou Data Warehouses                                                                        Desejável conhecimento na construção de Dashboards                                                                       Desejável conhecimento em modelagem multidimensional                                                                     Inglês avançado/ técnico                                                                         Capacidade analítica                                                                     Visão Sistêmica                                                                  Postura de dono
Engenheiro de Dados Sr - Python;https://www.catho.com.br/vagas/engenheiro-de-dados-sr-python/18607954/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Resolução de problemas, boa compreensão da capacidade de sistemas, gargalos, noções básicas de memória, CPU, OS, armazenamento e redes. Compreensão de elementos de infraestrutura de maneira geral, como Rede, SO, Armazenamento, entre outros Python (diferenciais: Spark, Java, Scala, desenvolvimento de software, API, Apache Kafka, SDK e micro serviços) Manipular bases de dados tipo-SQL (diferenciais: HBase, Cassandra, Parquet, Avro) Desenvolvimento de ETL com Apache Beam. Excelente conhecimento em bancos de dados relacionais e não-relacionais. Bons conhecimentos em soluções de integração de dados (APIs, softwares, técnicas). Habilidade para entendimento do negócio do cliente, de forma a identificar relevância ou não nos dados manipulados. Habilidades de resolução de problemas, boa compreensão da capacidade de sistemas, gargalos, noções básicas de memória, CPU, OS, armazenamento e redes. Conhecimento em Linux..
Engenheiro de Dados Pl Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-pl-senior/18595657/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Banco de Dados (SQL, Postgre, MongoDB) e linguagem SQL, Python. Conhecimento avançado em SSIS, Dataflow, CloudStorage e PubSub, uso e desenvolvimento de API?s, análise e solução de problemas e transitar muito bem entre tecnologia e negócios. Superior completo em TI. Conhecimento em Modelagem de Dados e Integração de Dados. Desejável conhecimento com Progress.
Engenheiro de Dados Spark Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-spark-senior/18559841/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Realizar ingestão de Dados em Data Lake Hadoop através do Pyspark.                                                                                    Estruturar queries na origem (SQL) e no Data Lake.                                                                                       Realizar consumo em filas Kafka.                                                                                         Estruturar estratégia de ingestão, com o objetivo de viabilizar que o dado seja consumido da forma mais adequada pelo cliente, considerando data format, camadas no HDFS, processo para gravação no HDFS.                                                                                        Estruturar queries no Impala para que dados sejam consumidos em Dashboards que serão criados no PowerBI (Dashboards serão responsabilidade de outro time). Fundamentos de Big Data, Hadoop (HDFS, Partionamento), Hive, Impala, Kafka, Python, Shell Script, Spark, SQL, SQL em Hive e Impala. Vivência com Streaming será um diferencial.
Engenheiro de Dados Teradata Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-teradata-senior/18559868/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Desenvolvimento de rotinas nas linguagens atreladas a cada ambiente (Python, Spark, etc).                                                                      Desenvolvimento de Automações para Batimento, validações, etc, gerando alertas e insumos para ações de gestão de Recursos (Espaço, CPU, licença, etc), identificação de desvios, etc.                                                                    Desenvolvimento de monitorações/alertas para garantir a execução dos processos conforme schedule definido (Execução dentro do schedule e ANS esperado).                                                                          Analise, Definição, implantação e controle de Regras de Segurança (Permissionamento, etc).                                                                       Geração dos insumos (Bases, Logs, etc) para construção dos Painéis de Monitoração.                                                                       Otimização na passagem dos processos Produtivos para gestão do time de Sustentação.                                                                      Construção do Pareto dos Incidentes e Plano de Ação para correção em causa raiz dos Ofensores mapeados.                                                                          Construção de Base de Conhecimento para Incidentes, Erros conhecidos, Procedimentos Operacionais, etc.                                                                  Desenvolvimento técnico/Treinamento dos recursos internos. Teradata, Hadoop (HDFS, Partionamento), Hive, Python, Shell Script, Spark, SQL, SQL em Hive e Impala, Tableau.
Engenheiro de Dados Python - Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-python-senior/18560008/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Hive Python Spark Desejável - Streamsets - Rundeck (orquestrador de processos)
Engenheiro de Dados Azure Pleno;https://www.catho.com.br/vagas/engenheiro-de-dados-azure-pleno/18559914/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar em uma das squads do projeto, cujo objetivo é implementação do ambiente cloud e data analytics. SQL Datafactory Conhecimento principal: SQL e que saiba lidar com cloud da Azure Databriks Plus, se tiver será ótimo: sinapse
Engenheiro de Dados Sênior - Alteryx;https://www.catho.com.br/vagas/engenheiro-de-dados-senior-alteryx/18515670/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Traduzir necessidades de negócios em requisitos técnicos. Projetar, desenvolver, implantar e oferecer suporte ao negócio através de desenvolvimento de soluções técnicas. Executar tarefas de manipulação/preparação de dados usando Alteryx, além de conhecimentos em consultas SQL/HQL. Compartilhar conhecimento e disseminar boas práticas para key-users e end-users. Ótima comunicação Autonomia Senso de urgência. Foco. Capacidade de sintetizar informações técnicas e de negócios para as partes interessadas individuais técnicas e não técnicas. Serão considerados Diferenciais: Certificações Alteryx.
Engenheiro de Dados (Big Data);https://www.catho.com.br/vagas/engenheiro-de-dados-big-data/18478149/?origem_apply=busca-de-vagas&entrada_apply=direto;João Pessoa - PB (1);Criar processos automatizados em Big Data, preparar e monitorar rotinas para reportes periódicos, garantir a ingestão e disponibilização de dados nos ambientes de BI, desenvolver políticas e procedimentos para a coleta e análise de dados, revisar e validar dados disponibilizados para o time de BI, interagindo com equipes multidisciplinares. Conhecimentos com: Big Data (SQL, Spark, Python, PySpark), Hadoop, Vivência em áreas de Analytics e Dados, Vivência na criação de indicadores de eficiência operacional e gestão de portfólio.
Engenheiro de Dados - Big Data;https://www.catho.com.br/vagas/engenheiro-de-dados-big-data/18478161/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar com Splunk Enterprise, ingestões, criação de painéis, otimização de consultas, melhorias de performance, criação de comandos em python. Vivencia ambiente BigData (HDFS, Hive, Spark, HBase), Linux / Shell Script, Python, SQL. Diferencial: Certificação Splunk.
Desenvolvedor Engenheiro de Dados Sênior;https://www.catho.com.br/vagas/desenvolvedor-engenheiro-de-dados-senior/18474318/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Desenvolvimento alavancando framework Spark (ecossistema BigData).Desenvolvimento Java, Python e Scala em pipelines de integração de dados. Conhecimento de ambientes Cloud ? Azure preferencialmente. Experiência com pipeline DevOps ? Jenkins, SonarQube, Fortify.  Idioma:  Inglês - Fluente, Espanhol - Fluente
Engenheiro de Dados Bigdata Azure;https://www.catho.com.br/vagas/engenheiro-de-dados-bigdata-azure/18462859/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);O que procuramos? Um profissional que seja apaixonado em transformar dados em informação e que atue com ingestão, integração e processamento de dados em Bigdata, em Databricks, Datafactory e Azure. O que você deve ter? Experiência em criação de pipeline Ingestão de dados. Atuação em implementação e evolução dos processos de ingestão e integração de dados. Experiência (Python, PySpark, Databricks, Datafactory, Azure)Experiência em HadoopExperiência em modelagem de dados.  O que mais seria interessante você saber? Conhecimento em metodologias ágeis Desejável conhecimento em criação de Dashboards em Power BI.
Engenheiro de Dados - Sênior | AWS;https://www.catho.com.br/vagas/engenheiro-de-dados-senior-aws/18167809/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Irá apoiar o time do cliente para otimizar os processos de ingestão atuais bem como desenvolver novos processos. Ambiente Linux AWS Git e GitFLow Python SQL.
Engenheiro de Dados - Sênior | GCP;https://www.catho.com.br/vagas/engenheiro-de-dados-senior-gcp/18438407/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);O profissional atuará no desenvolvimento de app para programa de pontos e de fidelidade de um cliente varejista de grande porte. Entender as necessidades dos clientes, Desenvolver aplicações resilientes a falhas, Construções de documentações Técnicas (ex: Metadados e Catálogos de Dados), Arquitetar sistemas distribuídos, Criar pipelines de dados confiáveis, Combinar fontes de dados, Criar a arquitetura de soluções, Colaborar com a equipe de Data Science e construir as soluções certas para essas equipes. Fundamentos de Big Data, GCP, Hbase, NoSQL, Python, Scala, Spark, SQL. Desejável: Conhecimento de arquitetura de dados Big Data (Hadoop ou Google Cloud Platform) Conhecimento na construção de Data Lakes e/ou Data Warehouses Conhecimento em aplicação FRONT de Business Intelligence (ex: Tableau ou Power BI) Conhecimento na construção de Dashboards Conhecimento em modelagem multidimensional
Engenheiro de Dados - Sênior | Docker;https://www.catho.com.br/vagas/engenheiro-de-dados-senior-docker/18438391/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Será responsável por construir processos de ingestão utilizando PySpark e processos de ETL utilizando SQL. Ambiente Linux, Docker, Git e GitFLow, Python, Shell Script, Spark, SQL, SQL em Hive e Impala. Desejável conhecimento de access.
Engenheiro de Dados ETL Pleno;https://www.catho.com.br/vagas/engenheiro-de-dados-etl-pleno/18418666/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Requisitos Obrigatórios: Desenvolvimento ETL Pentaho Data Integration (PDI) Modelagem Dimensional de BI (Data Warehouse),  MongoDB. Requisitos Desejáveis: Amazon Redshift, Glue AWS Pyton Neo4j.
Engenheiro / Consultor de Dados;https://www.catho.com.br/vagas/engenheiro-consultor-de-dados/18550197/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Duas oportunidades para engenheiro/Consultor de Dados (Pleno e Sênior). Vivência em TI / Dados. Experiência em BIG DATA (Hadoop, ou Cloudera ou Hortonworks). Vivência com Hive. Vivência em HDFS. Vivência em shell Unix. Vivência em desenvolvimento Python ou Scala. Vivência em Spark. Desejável: Map Reuce, Zooeper, Ragner. CLT + Benefícios. Remoto.
Engenheiro - Arquiteto de Dados;https://www.catho.com.br/vagas/engenheiro-arquiteto-de-dados/18540490/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Prestar serviços de soluções tecnológicas. Avançados e prévia relevante com SOA Avançados e com design patterns de API&#39s e Micro serviços Cloud computing (AWS preferencialmente) Modelagem em banco de dados Relacionais e No-SQL Infraestrutura (Redes, Protocolos) CI/CD Kubernetes/Docker Inglês  Java SpringBoot, Flutter, Angular, ReactJS, Kafka.  Idioma:  Inglês - Fluente
Engenheiro de Dados Sênior (Lead Engineer);https://www.catho.com.br/vagas/engenheiro-de-dados-senior-lead-engineer/18456796/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Responsabiliza-se e garante a construção/desenvolvimento/implementação da solução técnica. Entendimento funcional do requisito de negócio e traduzir para fluxo de dados. Modelagem de dados em Hive/HBase. Implementação de fluxos de dados (pipelines) utilizando principalmente com Spark para distribuição e processamento paralelo. O destino de dados pode ser arquivos, API, ElasticSearch ou SFTP. Linguagem de programação com Scala. Implementação de fluxos de dados com arquitetura orientada a eventos (Apache Kafka), utilização de padronização de tipo de mensagem Avro/protobuf/json. Tecnologias: Git Jetbrains IntelliJ. Hadoop: YARN, HIVE. Apache HBase. Apache Spark. Apache Kafka. Protocolo Protobuf. Bash Shell Script.
Engenheiro de Dados PowerCenter + BDM Júnior;https://www.catho.com.br/vagas/engenheiro-de-dados-powercenter-plus-bdm-junior/18493229/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar com processos de ETL e ferramentas de ETL (Power Center e BDM). Engenheiro de Dados com conhecimentos nas ferramentas Power Center e BDM.  Conhecimentos desejáveis: Banco de dados SQL Server e Framework Ágil.
Engenheiro de Dados / Cientista de Dados - Sênior - DataSUS;https://www.catho.com.br/vagas/engenheiro-de-dados-cientista-de-dados-senior-datasus/18270946/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Modelagem em ambiente Cloud levando em conta fonte de dados DataSUS Auxílio em definição de arquitetura de dados Cloud para suportar reports e integrações baseadas em DataSUS Suporte em integração de dados DataSUS com outras fontes de mercado e internas Qualificações Essenciais: Experiência em ramo Farmacêutico ou Saúde Experiência com modelagem de dados Experiência de trabalho com base DataSUS Conhecimento das regras existentes no acesso às informações DataSUS Soft Skills: Comunicativo Ownership Autodidata Hands-on Proatividade Linguagem de Programação (Java ou Python ou Scala) Experiência com Cloud (AWS, Azure ou GCP) Conhecimentos de ETL  Idioma:  Inglês - Fluente
Engenheiro de Dados BI Big Data;https://www.catho.com.br/vagas/engenheiro-de-dados-bi-big-data/18465512/?origem_apply=busca-de-vagas&entrada_apply=direto;Belo Horizonte - MG (3);Atuar em Engenharia de Dados com Projetos de Big Data em Nuvem. Experiência em projetos de Big Data. Conhecimentos em PYSPARK. Experiência com conjunto de ferramentas relacionadas a Big Data na AWS, como: Kafka, EMR, Kinesis, RedShift, S3, Glue, Athena, ElasticSearch. Conhecimentos em ferramentas de provisionamento de Infraestrutura em Cloud via código, tais como: Terraform, CloudFormation. Experiência com Bancos de Dados não Relacionais, como: HBase, DynamoDB, Cassandra ou MongoDB. Experiência prática com ingestão, integração, processamento e armazenamento de grandes volumes de dados. Conhecimento em linguagem Python, Java e/ou Scala. Experiências em ferramentas ETLs. Conhecimentos em modelagem de dados relacionais e dimensionais (Data WareHouse). Compreensão de Bancos de Dados Relacionais, como: SQL Server, PostgreSQL e MySQL. Experiência com tecnologias relacionadas ao ecossistema Hadoop, tais como: Hdfs, HBase, MapReduce, Spark, Hive. Conhecimentos em sistemas baseados no Unix.
Engenheiro de Dados Sênior Big Data;https://www.catho.com.br/vagas/engenheiro-de-dados-senior-big-data/18586279/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Sabemos que grandes resultados só são alcançados com uma grande equipe, por isso procuramos pessoas talentosas e apaixonadas, com desejo de crescer profissionalmente e criar uma trajetória de carreira conosco. Papéis e Responsabilidades: Engenheiro de dados para apoiar cliente com engenharia reversa e validação de dados em ambiente Big Data. Atuará tanto no desenvolvimento dos fluxo de carga, quanto na validação das regras de negócio e qualidade de dados. Qualificações Essenciais: Experiência em processos de ETL e ELT. Experiência com projetos Big Data e engenharia de dados Arquitetura Batch, Streaming, Lambda e Kappa. Conhecimento em plataformas Cloud. Experiência em Big Data. Ingestão e processamento de dados em DataLake e Data Warehouse.  Conhecimentos sólidos em Linux, conhecimentos em containers Docker (construção e publicação). SQL. Shell Script. Apache. Spark. Hadoop. Java ou Scala. Modelagem de dados em RDB e colunar. ELK (Elasticsearch, Logstash, Kibana). ETL (Ex.: Nifi, StreamSets, Logstash). GCP ou AWS. Construção de dashboards para análise (Grafana, Kibana, Power BI, Tableau) Certificação AWS, GCP e/ou Cloudera.
Engenheiro de Dados Sênior (Python + GCP);https://www.catho.com.br/vagas/engenheiro-de-dados-senior-python-plus-gcp/18493262/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar com técnicas de captura, tratamento e estruturação de dados em arquitetura de processamento de dados com escalonamento horizontal (big data, cloud computing PaaS). Experiência atuando como Engenheiro de Dados Python com GCP. Operar sistemas operacionais linux (centos, RHEL):  Shell comandos básicos e intermediários. Edição de arquivos com VIM. Acesso remotto SSH. Outras operações baseadas em unix sem interface gráfica (GUI). Linguagem de programação: Python. Scala com spark. Arquitetura de big data e tecnologias de escalonamento horizontal: Conceitos de MPP. Cluster. Kubernetes. Devops:  git, jenkins, pipeline de deploy, Jira, Confluence. Integração de dados: Criar e manipular comandos DDL e DML. Fazer junções, agregações e ordenação de dados em tabelas utilizando. linquagem SQL ou tecnologias SPARK. Criar funções, classes e/ou métodos para processamento de fluxo de dados. em tecnologias de escalonamento horizontal. Google Cloud: Criar VMs, DataProc, Cloud Storage, Airflow. Conhecimentos desejáveis:  Boa comunicação e proatividade e aberto a conhecer novas tecnologias no cliente.
Engenheiro (a) de Dados | Presencial ou Home Office;https://www.catho.com.br/vagas/engenheiro-a-de-dados-presencial-ou-home-office/18621212/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);A Eleflow nasceu para tornar Big Data Analytics e Machine Learning mais acessíveis para as empresas. Com um time de Desenvolvedores, Engenheiros, Cientistas e Analistas de Dados experientes, motivados e curiosos buscamos ser os diferenciadores nos projetos que atuamos. Requisitos principais:·&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspExperiência em processos de Extração, Padronização e Carga de dados (ETL), utilizando ferramentas ou linguagem de programação.·&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspConhecimentos e experiência nas melhores práticas em automação da carga de dados bem como de governança de dados.·&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspExperiência realizando análise de dados via SQL.·&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspExperiência com SQL, Java/Scala, Python, e Shell Script para automação·&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspLógica de programação e boas práticas de desenvolvimento·&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspExperiência em pelo menos um ambiente de Cloud: AWS, Azure, GCP ou IBM Cloud.·&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspExperiência com serviços Cloud (Azure ou similares): Azure Data Lake, Data Factory, Databricks.Requisitos Diferenciais: ·&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspExperiência/Conhecimento em projetos de MDM ou criação de visão única de clientes. Conhecimentos em LGPD·&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspAzure Data Lake, Data Factory, Databricks.·&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspStory telling, organizado(a), senso de urgência e priorização de demandas.
Engenheiro de Dados Data Lake Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-data-lake-senior/18560343/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Hadoop (HDFS, Partionamento), Metodologia Ágil.                                                                       Vivência/experiência com modelo ágil de desenvolvimento de produto/software (ex: SCRUM, KANBAN, etc?)                                                                    Experiência relevante em pelo menos um dos abaixo: O Java, Python, Spark, Scala                                                                  Conhecimento em linguagem SQL Conhecimento em banco de dados relacional (ex: Oracle)                                                                     Conhecimento em criação de processos de carga de dados batch e streaming (origem e destino)                                                                      Conhecimento em bancos de dados NOSQL (ex: HBase, Elastic Search, MongoDB, Hive)                                                                         Experiência comprovada com cloud Google                                                                  Experiência com criação de pipelines de ingestão de dados usando Google Cloud                                                                    Desejável conhecimento de arquitetura de dados Big Data (Hadoop ou Google Cloud Platform) Desejável conhecimento na construção de Data Lakes e/ou Data Warehouses                                                                        Desejável conhecimento na construção de Dashboards                                                                       Desejável conhecimento em modelagem multidimensional                                                                     Inglês avançado/ técnico                                                                         Capacidade analítica                                                                     Visão Sistêmica                                                                  Postura de dono Teradata, Hadoop (HDFS, Partionamento), Hive, Python, Shell Script, Spark, SQL, SQL em Hive e Impala, Tableau.  ?Senso de urgência, Comunicação, Comprometimento.
Engenheiro de Dados Sênior - Power Center;https://www.catho.com.br/vagas/engenheiro-de-dados-senior-power-center/18249274/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Suas principais responsabilidades serão: Atuar na sustentação de sistemas utilizando a ferramenta Power Center. O que buscamos: Desenvolvimento e manutenção de mapas e workflows no Power center (Mapping Designer, Workflow Manager, Monitor). Conhecimentos em CTRL-M. Conhecimento em migração de objetos do Power center entre ambientes (Repository Manager). Conhecimento de queries em SQL (Oracle). Conhecimento básico de Shell Script. Conhecimentos desejáveis: Banco de dados Oracle, BDM e Framework Ágil/Scrum. Comportamentos Esperados: Bom relacionamento interpessoal. Organização e disciplina para o trabalho. Dinamismo e proatividade. Facilidade para o trabalho em equipe. Solução de problemas (busca de soluções).
Engenheiro de Dados Informática Cloud Sênior;https://www.catho.com.br/vagas/engenheiro-de-dados-informatica-cloud-senior/18493188/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Responsável pelo desenvolvimento de pipeline de dados utilizando a ferramenta Informatica Cloud com experiência em trabalhos com grandes volumes, performance tuning de processos ETL, conhecimento de extração de dados de ambiente SAP e Salesforce. Graduação em carreiras de exatas, experiência em construção de Data Lakes, experiência em ambiente Big Data, experiência em trabalhos com grandes volumes de dados, profissional dinâmico, conhecimento de ambiente Cloud Azure, experiência em instalação do Informatica Cloud, conhecimento em ambiente Linux, conhecimento em Azure Synapse, conhecimento em Azure SQL, conhecimento em Databricks, conhecimento em Data Factory. Certificação em Informática Cloud.  Idioma:  Inglês - Fluente
Engenheiro de Dados de Integração (Desenvolvimento de ETL);https://www.catho.com.br/vagas/engenheiro-de-dados-de-integracao-desenvolvimento-de-etl/18418575/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Vamos juntos neste desafio? Precisamos que você saiba... Conhecimento da ferramenta Data Engineering Integration (DEI 10.4.1): Mapping Components, Data Object Operations, Transformations, Expressions / Functions, Mapplets, Segmentes, Mapping Parameters, Hierachical Data Processing. Conhecimento de ferramentas Google Cloud Plataform (GCP) Pubsub e GCP Dataflow para processamento em Streaming. Conhecimento das soluções GCP Dataproc (processamento spark, sqoop, spark streaming). Experiência com Troubleshotting de GCP Dataproc e Informatica DEI 10.4.1. E seriam pontos fortes: Desejável: certificação nas ferramentas mencionadas. Desejável: conhecimento em IBM DataStage 11.x e Cloudera 5.8.x (sqoop, beeline, hive e hue). Desejável: conhecimento em criptografia/mascaramento de dados, LGPD, conceitos de camada de dados bruto, confiável e refinado.
Engenheiro de Dados Big Data Python AWS;https://www.catho.com.br/vagas/engenheiro-de-dados-big-data-python-aws/18493108/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Apoiar cliente com engenharia reversa e validação de dados em ambiente Big Data. Atuará tanto no desenvolvimento dos fluxo de carga, quanto na validação das regras de negócio e qualidade de dados. Experiência em processos de ETL e ELT, experiência em linguagem ANSI-SQL, experiência em ambiente AWS (Glue, Athena, S3, DynamoDB, Elasticsearch, Cloudwatch, Lambda, Nifi, Redshift, Databricks). Experiência em ambiente Azure (Azure Data Lake, Databricks, HDInsights, Data Factory, Synapse, SQL-DW), experiência em GCP (Dataflow, CloudStorage, BigTable, BigQuery), programação Python, Spark Conhecimento em Cloudera. Conhecimento em Scala, Kafka. Conhecimentos desejáveis: Certicações em cloud providers, Inglês fluente para conversação, familiaridade com framework Ágil.  Idioma:  Inglês - Fluente
Engenheiro de Dados Sênior - Informática BDM - DEI;https://www.catho.com.br/vagas/engenheiro-de-dados-senior-informatica-bdm-dei/18515697/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Traduzir necessidades de negócios em requisitos técnicos. Projetar, desenvolver, implantar e oferecer suporte ao negócio através de desenvolvimento de soluções técnicas. Experiência em desenvolvimento com a ferramenta Informatica BDM DEI - Data Engineering Integration (Big Data Management) e PowerCenter Tradicional. Conhecimentos em linguagem SQL ANSI, modelagem de dados e banco de dados Oracle. Comunicação, autonomia, senso de urgência, foco e capacidade de sintetizar informações técnicas e de negócios para as partes interessadas (técnicas e não técnicas). Qualificações Desejáveis:  Conhecimento de Alteryx. Inglês intermediário (leitura e escrita).
Analista de Engenharia de Dados;https://www.catho.com.br/vagas/analista-de-engenharia-de-dados/18581945/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Desenvolvimento de processos de ETL para dados de fontes variadas junto a outras equipes técnicas Manutenção da infraestrutura de dados do Instituto Cordial em bancos de dados postgresql em máquinas virtuais e no Big Query no GCP (DL, ST e DW) Processamento de dados e eventual desenvolvimento de algoritmos para geração de novas variáveis de análise Disponibilização de dados e variáveis para equipes internas e squads de projetos e iniciativas (DMs) Desenvolvimento eventual de soluções computacionais para contribuir com a otimização ou aprimoramento de processos de equipes internas e squads de projetos e iniciativas Acompanhamento no desenvolvimento e manutenção de plataformas desenvolvidas por fornecedores externos. Ensino superior completo em Ciências da Computação, Engenharia da Computação ou áreas correlatas Vivência com Programação em: Bash (Linux, Debian) SQL Python Necessário conhecimento em Google Cloud Platform (SDK e ferramentas administrativas)GCP Big Query, Compute Engine, Data Flow Diferenciais: Experiência com processamento de dados geoespaciais, especialmente em Postgis Experiência com ferramentas de ETL como Pentaho Análise estatística e de redes sociais em R Desenvoltura com outras linguagens de programação, como Java e C++.
Especialista em Engenharia de Dados (AWS);https://www.catho.com.br/vagas/especialista-em-engenharia-de-dados-aws/18495160/?origem_apply=busca-de-vagas&entrada_apply=direto;Barueri - SP (1);Atuar na criação de desenvolvimento de novos produtos usando AWS, será responsável por implementar o LakeHouse, irá dar suporte e apoio nas demandas da área que envolvam Glue e Python Atualizar e evoluir as documentações existentes, bem como apoiar na execução de novos documentos Apoiar o time na construção do pipeline para automação dos processos internos. Requisitos Mandatórios:  SQL e PL/SQL Avançado Procedures Languages Desenvolvimento de scripts com Python e Shell script Experiência no ecossistema AWS ? especialmente Glue Banco de Dados Relacionais (MYSQL e PostgreSQL) Banco de Dados NoSQL/NewSQL (RedShift) Requisitos Desejáveis:  Conhecimento em gestão de mudanças (ITIL) e AGILE (Kanban/Scrum) Experiência em orquestração de containeres  Informações Adicionais
Especialista em Engenharia de Dados -AWS;https://www.catho.com.br/vagas/especialista-em-engenharia-de-dados-aws/18396927/?origem_apply=busca-de-vagas&entrada_apply=direto;Barueri - SP (1);Atuar na criação de desenvolvimento de novos produtos usando AWS, será responsável por implementar o LakeHouse, irá dar suporte e apoio nas demandas da área que envolvam Glue e Python Atualizar e evoluir as documentações existentes, bem como apoiar na execução de novos documentos Apoiar o time na construção do pipeline para automação dos processos internos. SQL e PL/SQL Avançado. Procedures Languages. Desenvolvimento de scripts com Python e Shell script Experiência no ecossistema AWS ? especialmente Glue Banco de Dados Relacionais (MYSQL e PostgreSQL). Banco de Dados NoSQL/NewSQL (RedShift). Conhecimento em gestão de mudanças (ITIL) e AGILE (Kanban/Scrum). Experiência em orquestração de containeres.
Engenheiro de Dados - Informática BDM - DEI - Líder Técnico;https://www.catho.com.br/vagas/engenheiro-de-dados-informatica-bdm-dei-lider-tecnico/18494972/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Liderar equipe técnica e traduzir necessidades de negócios em requisitos técnicos. Projetar, desenvolver, implantar e oferecer suporte ao negócio através de desenvolvimento de soluções técnicas. Formação Superior em TI, de preferência em Ciência da Computação, Engenharia de Sistemas ou áreas equivalentes. Liderança técnica: experiência em gestão de equipes, atividades e demandas com conhecimento em Power Center. Experiência em desenvolvimento com a ferramenta Informatica DEI - Data Engineering Integration (Big Data Management) e PowerCenter Tradicional. Conhecimentos em linguagem SQL ANSI, modelagem de dados e banco de dados Oracle. Ótima comunicação, autonomia, senso de urgência, foco e capacidade de sintetizar informações técnicas e de negócios para as partes interessadas (técnicas e não técnicas). Qualificações desejáveis: Conhecimento de Alteryx. Inglês intermediário (leitura e escrita).  Idioma:  Inglês - Intermediário
Engenheiro de Dados Pl (Hadoop/Spark–Big Data)- Sp;https://www.catho.com.br/vagas/engenheiro-de-dados-pl-hadoop-sparkbig-data-sp/18365333/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Especialização: Big Data usando ferramentas open source com foco em Engenharia de Dados    Este profissional poderá ser alocado para trabalhar com qualquer tecnologia open source mas - prioritariamente - será direcionado para os assuntos da sua especialização.    **Principais tarefas:        ?  Implementar projetos usando tecnologias open source com foco maior nos assuntos da sua especialização      ?  Ministrar curso ? presencial ou online - relacionados a área da sua especialização      ?  Prestar suporte em infraestrutura de Big Data e assuntos correlacionados para os clientes da 4Linux      ?  Suportar a infraestrutura interna da 4Linux nos assuntos da sua especialização      ?  Criar e escrever novos cursos ou atualizar os existentes relacionados aos temas da sua especialização **Obrigatório:        ? Superior completo      ? Disponibilidade para trabalhar na cidade de São Paulo      ? Conhecimentos em Linux      ? Saber programar em Python (nível intermediário)      ? Conhecimento básicos nas plataformas de Big Data como Hadoop e Spark, de modo geral é esperado que este candidato saiba realizar as seguintes tarefas:          ? Instalação e configuração de um cluster Hadoop          ? Criação de pipelines de transformação de dados usando Python com pyspark          ? Conhecimentos básicos em plataformas de Big Data: Hortonworks ou Cloudera          ? Conhecimento básicos em SQL          ? Conhecimentos básicos com algum banco NoSQL          ? Manutenção de Datalake (HDFS ou Google Cloud Storage ou AWS S3) e Data warehouse (Hive ou outro qualquer em nuvem)          ? Criar processos para extração, transformação e carregamento de dados (ETL)          ? Manter a qualidade dos nossos dados e códigos          ? Padrão de troca de dados em JSON          ? Entender requisitos de negócio para modelagem do nosso data lake e data warehouse de acordo com as necessidades.    **Desejável:        ? Já ter trabalhando em empresas de consultoria      ? Já ter ministrado - e gostado -  de dar aulas de T.I.      ? Conhecimentos básicos em Kubernetes      ? Conhecimentos básicos em Kafka e NiFi      ? Conhecimentos de containers utilizando Docker      ? Conhecimentos básicos de ferramentas de Big Data em nuvem: Google Cloud Plataform, Azure ou AWS      ? Noções em algoritmos de Machine Learning e conhecimento em algum framework como Scikit Learn ou Tensorflow ou Keras      ? Noções em algum banco NoSQL: Hbase, MongoDB      ? Criação de fluxo de processamento com Apache Airflow.
Analista Engenharia de Dados Sênior;https://www.catho.com.br/vagas/analista-engenharia-de-dados-senior/18628578/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Desenvolvimento de software backend. Desenvolvimento de pipeline de dados na nuvem. Análise e melhoria de código legado. Entendimento de demanda de diversas áreas da empresa. Análise e configuração de infraestrutura na nuvem. Formação em Desenvolvimento de Sistemas, Ciências da Computação ou áreas correlacionadas. Conhecimentos em desenvolvimento de software. Domínio da linguagem Python. Conhecimentos em banco de dados, com SQL avançado e modelagem multidimensional Experiência em trabalho na nuvem, com nível avançado em ferramentas / ambiente AWS. Fundamentos de Big Data, NoSQL, Pandas, Spark, Hadoop, Hive Experiência em GIT Facilidade em trabalhar com Linux (flavors). Conhecimento da metodologia AGILE. Perfil desejado: facilidade em trabalhar em time, cooperação, automotivação, objetividade, flexibilidade e inovação. Desejável experiência em teste unitário.
Analista de Engenharia de Dados Pl;https://www.catho.com.br/vagas/analista-de-engenharia-de-dados-pl/18468085/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (2);Executar as análises e desenvolvimentos de banco de dados Desenvolvimento e suporte de processos de carga e integração de dados de diversas origens e destinos de dados, tratamento de bases de dados e implementação de produtos Dtm Desenvolvimento de processos de carga e integração de dados, envolvendo diversas origens e destinos de dados para alimentar bases de dados analíticas Desenvolvimento de relatórios analíticos Análise de dados, procurando garantir qualidade e consistência dos mesmos Garantir performance em relatórios e na estrutura de dados desenvolvida para análise Manter documentados os processos e procedimentos de responsabilidade do colaborador Prestar suporte nos produtos e processos desenvolvidos e implementados pela Dtm Desenvolver e prestar suporte em campanhas de Marketing Direto através de ferramenta de Gestão de Campanhas. Formação superior completa Experiência em Ferramentas de ETL Conhecimento em um ou mais sistemas gerenciadores de banco de dados (SQL Server, Oracle, MySQL, etc.), linguagem SQL, modelagem de bases de dados (relacionais e dimensionais) Conhecimento em ferramentas de relatório (Tableau, Power BI, etc.) Será um diferencial conhecimento em projetos de Database Marketing.
Analista de Engenharia de Dados Sr;https://www.catho.com.br/vagas/analista-de-engenharia-de-dados-sr/18468049/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Executar as análises e desenvolvimentos de banco de dados com total autonomia, sendo capaz de definir esforços e estabelecer prazos assertivos Desenvolvimento e suporte de processos de carga e integração de dados de diversas origens e destinos de dados, tratamento de bases de dados e implementação de produtos Dtm Definição de escopo e esforço das atividades Definição e mapeamento de requisitos técnicos Compartilhar conhecimento com a equipe Desenvolvimento de processos de carga e integração de dados, envolvendo diversas origens e destinos de dados para alimentar bases de dados analíticas Desenvolvimento de relatórios analíticos Garantir qualidade, consistência e performance nos dados Manter documentados os processos e procedimentos de responsabilidade do colaborador e fomentar a prática na equipe Prestar suporte em nível avançado nos produtos e processos desenvolvidos e implementados pela Dtm Desenvolver e prestar suporte em nível avançado em campanhas de Marketing Direto através de ferramenta de Gestão de Campanhas Comunicar de forma clara e assertiva andamento das atividades para gestores. Formação superior completa Experiência em Ferramentas de ETL Conhecimento em um ou mais sistemas gerenciadores de banco de dados (SQL Server, Oracle, MySQL, etc.), linguagem SQL, modelagem de bases de dados (relacionais e dimensionais) Conhecimento em ferramentas de relatório (Tableau, Power BI, etc.) Será um diferencial conhecimento em projetos de Database Marketing e tecnologias Big Data (NoSQL, Spark, Hadoop, Hive).
Analista de Engenharia de Dados Sênior;https://www.catho.com.br/vagas/analista-de-engenharia-de-dados-senior/18189434/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Desenvolvimento de software backend. Desenvolvimento de pipeline de dados na nuvem. Análise e melhoria de código legado. Entendimento de demanda de diversas áreas da empresa. Análise e configuração de infraestrutura na nuvem. Formação em Desenvolvimento de Sistemas, Ciências da Computação ou áreas correlacionadas. Sólidos conhecimentos em desenvolvimento de software. Domínio da linguagem Python. Conhecimentos em banco de dados, com SQL avançado e modelagem multidimensional Experiência em trabalho na nuvem, com nível avançado em ferramentas / ambiente AWS. Fundamentos de Big Data, NoSQL, Pandas, Spark, Hadoop, Hive Experiência em GIT Facilidade em trabalhar com Linux (flavors). Conhecimento da metodologia AGILE. Perfil desejado: facilidade em trabalhar em time, cooperação, automotivação, objetividade, flexibilidade e inovação.
Especialista de Dados - Data Engineering;https://www.catho.com.br/vagas/especialista-de-dados-data-engineering/18447958/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (3);Desenvolve, constrói, testa e mantém a solução (Plataforma de Dados), onde todos os dados são extraídos, limpos, organizados, integrados e disponibilizados com Gestão e Governança. Conhece os processos e interage com outras áreas de Datos & Tecnologia, assim como de Negócio. Sabe traduzir necessidades de usuários de negócio em requisitos técnicos para criação de novas features para a plataforma de dados. Responsável pela implementação e melhoria contínua da Plataforma de Dados, utilizará ferramentas para avaliar, integrar e disponibilizar os dados da forma mais adequada e performática possível, apresentando os trade-offs adequados para cada contexto. Agile (Scrum/Kanban), DevOps (CI/CD - desejável), GitFlow, Cloud - Experiência em pelo menos uma das três principais plataformas (AWS, Azure, GCP), Hadoop Ecosystem (on premises e gerenciado em nuvem, EMR/HDInsights), SQL / NoSQL (databases, paradigmas e modelagem). Data Warehousing & Data Lakes, Python, Scala e/ou Java (core e Spark), APIs e Microsserviços e Testes e DevOps (CI/CD).  Idioma:  Inglês - Fluente, Espanhol - Intermediário
Estágio na área de Tecnologia da Informação;https://www.catho.com.br/vagas/estagio-na-area-de-tecnologia-da-informacao/18336701/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Deverá estar cursando: Ensino Superior a partir do terceiro semestre em Tecnologia da Informação, Análise e Desenvolvimento de Sistemas, Ciências da Computação, Sistemas de Informação ou Engenharia de Dados. Limpeza de dados, análise de dados e desenvolvimento de sistemas. Conhecimento em lógica de programação, fundamentos de banco de dados, JAVA e Python.
Arquiteto de Dados / Analista de Base SAS;https://www.catho.com.br/vagas/arquiteto-de-dados-analista-de-base-sas/18658262/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuação em projetos de dados para uso analítico.Participação em projets envolvendo tecnologias mais emergentes de engenharia de dados, envolvendo: Python Spark Ecosys Hadoop Conhecimento de Arquitetura SAS (SAS GRID) SAS E Guide. Características de execução Experiência no desenvolvimento de programas SAS para integração de dados. Conhecimento nas particularidades da linguagem, como por exemplo Data step Macros Includes
Analista de Soluções;https://www.catho.com.br/vagas/analista-de-solucoes/18663893/?origem_apply=busca-de-vagas&entrada_apply=direto;Sorocaba - SP (1);Desenvolvimento de Pipelines em DateFactory, desenvolvimento em ETL em Databricks. Desenvolvimento em modelo em SSAS (Analysis Service). Conhecimento em Power BI. Desenvolver painéis em Power BI. Desenvolver cálculos em DAX. Power BI 365. Power BI Reporting Service. Conhecimento em Engenharia de Dados. Experiência em ambiente nuvem Azure. Experiência em SQL, Python, Pyspark e Spark SQL.
Desenvolvedor Web Sênior;https://www.catho.com.br/vagas/desenvolvedor-web-senior/18664010/?origem_apply=busca-de-vagas&entrada_apply=direto;Rio de Janeiro - RJ (1);Programa, codifica e testa sistemas, sites e portais voltados para o ambiente da internet. Executa a manutenção dos sistemas, fazendo eventuais correções necessárias, visando atender às necessidades dos usuários. Desenvolve trabalhos de montagem, depuração e testes de programas, executando serviços de manutenção nos programas já desenvolvidos. Ensino Superior completo. Experiência em desenvolvimento web e/ou web scraping, python, javascript, Etls, AWS e banco de dados relacional. Vivência em backend e engenharia de dados.
Estatístico;https://www.catho.com.br/vagas/estatistico/18632370/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (3);Missão do Cargo    Fornecer conhecimento, análises e modelos que suportem as tomadas de decisão de crédito, cobrança, fraude e as mais diversas áreas da empresa, de forma autônoma e auxiliando outros analistas.    Responsabilidades    - Identificar oportunidades e viabilidade do uso de dados para auxiliar tomadas de decisão.  - Desenvolver, implementar e monitorar modelos preditivos, bem como documentar todo o processo.  - Escorar modelos e realizar backtests.  - Apresentar e discutir os modelos com as áreas envolvidas nas tomadas de decisão.  - Fazer análises que auxiliem na tomada de decisão.  - Gerenciar projetos relacionados à área de atuação.  - Transmitir conhecimento e apoiar outros analistas em suas entregas. Prévia atuação em:     Áreas de Modelagem, CRM, Políticas de Crédito, Cobrança, Engenharia de dados, Resultados, Finanças, Riscos, Precificação.  Experiência com modelagem preditiva.  Requisitos: Programação em Python, R ou SAS.
Cientista de Dados BI;https://www.catho.com.br/vagas/cientista-de-dados-bi/18650394/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Colaborar com um time de estatísticos, engenheiros em machine learning, economistas e especialistas em linguagem (nlp, nlu, nlg) para resolver problemas usando Data Science. Auxiliar e dar suporte ao time na limpeza do Dataset e em Feature Engineering. Atuar na criação, desenvolvimento e melhoria interativa da base de conhecimento para soluções de aprendizado de máquina que potencialize nosso principal produto de Chatbot. Trabalhar em conjunto com o engenheiro de dados e arquitetos de dados na criação de Datasets, no formato necessário para treinamento de múltiplos modelos. Coletar, limpar, armazenar, organizar, integrar dados e ajudar na criação de pipelines de dados (com a equipe de engenheiros). Realizar análises descritivas e exploratórias, modelagem preditiva, aplicar aprendizado de máquina, realizar simulações, análise de texto e visualização interativa de dados. Auxiliar na expansão do uso da ciência de dados nas frentes de negócios: participar de reuniões com clientes.
Cientista de Dados;https://www.catho.com.br/vagas/cientista-de-dados/18383839/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Criar modelos utilizando estatística, machine learning, otimização e/ou teoria financeira. Comunicar aspectos técnicos e resultados analíticos para clientes (interno e externos) de diferentes backgrounds. Se responsabilizar por projetos (aspectos técnicos) do início ao fim: trabalhar de forma próxima com engenheiros de dados, cientistas de dados e equipes de produto e negócio para entrega de insights de qualidade e com robustez. Buscar proativamente oportunidades de melhorias em processos existentes. Conhecimento em modelagem estatística e técnicas de machine learning. Conhecimento em exploração de dados: criação de hipóteses a partir de um problema de negócios, desenho de experimentação através de dados, interpretação e métricas de sucesso (testes de hipóteses, A|B, comprovação / rejeição de hipótese) Habilidade com apresentações de resultados de projetos de ciência de dados, de forma compreensível pelas áreas de negócios, sem perda de rigor científico. Conhecimento em computação em nuvem (Azure) Conhecimento em linguagem SQL. Conhecimento em Python e suas bibliotecas de ML. Familiaridade com versionamento de código (Git).
Gerente de Marketing;https://www.catho.com.br/vagas/gerente-de-marketing/18621224/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);A Eleflow nasceu para tornar Big Data Analytics e Machine Learning mais acessíveis para as empresas. Com um time de Desenvolvedores, Engenheiros, Cientistas e Analistas de Dados experientes, motivados e curiosos buscamos ser os diferenciadores nos projetos que atuamos. - Graduação completa em Marketing, Comunicação, Publicidade e Propaganda ou áreas similares- Fortes habilidades interpessoais necessárias para se comunicar com uma ampla gama de clientes internos e externos- Vivência na área de tecnologia será considerada um diferencial importante.
Software Engineer Java Sênior;https://www.catho.com.br/vagas/software-engineer-java-senior/18621205/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (2);A Eleflow nasceu para tornar Big Data Analytics e Machine Learning mais acessíveis para as empresas. Com um time de Desenvolvedores, Engenheiros, Cientistas e Analistas de Dados experientes, motivados e curiosos buscamos ser os diferenciadores nos projetos que atuamos. Requisitos obrigatórios: Necessário ter experiência em desenvolvimento utilizando linguagem JAVA e Orientação a objetos Experiência com microserviços e API Rest Gostar de aprender novas tecnologias que resolvam problemas reais. Requisitos Desejáveis:  Experiência com framework reativo - Exemplo: Spring WebFlux. Padrões de Projeto Experiência com Testes Automatizados Experiência em análise de requisitos.
Estágio em Programação Back-end;https://www.catho.com.br/vagas/estagio-em-programacao-back-end/18643710/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (2);Deverá estar cursando: Ensino técnico ou estar cursando graduação Informática, Análise de Sistemas, Sistemas de Informação, Ciências da Computação, Engenharia de Computação ou curso relacionado. Participar em todas as etapas do ciclo de vida de desenvolvimento desde o entendimento das necessidades do usuário, desenho da solução, implementação, testes e deployment em produção Atuar com foco principal em desenvolvimento de software para ambientes web na área de logística e transportes Programação back-end com Java Spring Boot, Spring Data, entre outros Participar na elaboração de documentação, também com o objetivo de melhorar a qualidade e o processos de desenvolvimento. Interesse em práticas de Cloud e CI / CD Conhecimento em GIT, Maven, Jenkins Conhecimento em Metodologias Ágeis Conhecimento nas linguagens: Java, SQL, Javascript Conhecimento sobre fundamentos de engenharia de software, estrutura de dados e algoritmos.
Analista de Dados;https://www.catho.com.br/vagas/analista-de-dados/18621197/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (2);A Eleflow nasceu para tornar Big Data Analytics e Machine Learning mais acessíveis para as empresas. Com um time de Desenvolvedores, Engenheiros, Cientistas e Analistas de Dados experientes, motivados e curiosos buscamos ser os diferenciadores nos projetos que atuamos. Requisitos Principais: Experiência como Analista de Negócios, Analista de dados, ou Analista de TI/Processos. Experiente em interagir com times de negócios e time técnico, construindo relacionamentos em ambos grupos. Experiência na criação de requerimentos e user stories, utilizando técnicas e melhores práticas. Confortável no processo de análise de dados, via SQL ou outro ferramental. Facilidade na compreensão de regras de negócio, documentando e partilhando com o time técnico. Requisitos Desejáveis: Experiência/Conhecimento em projetos de MDM ou criação de visão única de clientes. Conhecimentos em LGPD. Experiência em pelo menos um ambiente de Cloud: AWS, Azure, GCP ou IBM Cloud, Story telling, organizado, senso de urgência e priorização de demandas.
Desenvolvedor iOS;https://www.catho.com.br/vagas/desenvolvedor-ios/18621218/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);A Eleflow nasceu para tornar Big Data Analytics e Machine Learning mais acessíveis para as empresas. Com um time de Desenvolvedores, Engenheiros, Cientistas e Analistas de Dados experientes, motivados e curiosos buscamos ser os diferenciadores nos projetos que atuamos. Requisitos básicos: Programação com linguagem Swift. Conhecimentos básicos XCode. Versionamento git- Storyboards e .xib. Noções básicas de auto layout.- Git. Requisitos Desejáveis: Noções de padrões de arquitetura (MVP, MVVP ou Clean). Ambiente AWS (Lambdas, API Gateway, SNS). Frameworks de injeção de dependência. Clean Code, Testes unitários. Testes de UI (automatizados), Criação de componentes customizados. Noções de Objective-C. Persistência de dados local (Core Data ou Realm). Diferenciais:- Gerenciamento de publicações e versões na Apple Store, Fastlane e SwiftUI.
Analista de Geoprocessamento Júnior;https://www.catho.com.br/vagas/analista-de-geoprocessamento-junior/18643314/?origem_apply=busca-de-vagas&entrada_apply=direto;São José dos Campos - SP (1);Prestar apoio no planejamento executivo dos projetos Interpretar documentos para a especificação técnica (modelagem geográfica e representação temática) de componentes e requisitos de soluções de geoprocessamento Monitorar o desenvolvimento dos processos de geoprocessamento, executando atividades técnicas de geração de imagens, controlando a qualidade dos produtos gerados Executar atividades de geoprocessamento Analisar, interpretar e classificar imagens de satélite de média, alta e de altíssima resolução. Superior cursando em Geografia, Processamento de Dados, Engenharia Cartográfica, Engenharia Florestal, Engenharia Agrícola, Engenharia Ambiental ou áreas afins.  Conhecimento em Geoprocessamento, Sensoriamento Remoto, PDI, ArcGIS PRO ou Desktop Conhecimento em linguagem de programação (lógica de programação) Noções de Cartografia e Agrometeorologia, ArcGIS Online, MS Office Básico, Power BI e Legislação Ambiental.
Analista de Power BI;https://www.catho.com.br/vagas/analista-de-power-bi/18621202/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (5);A Eleflow nasceu para tornar Big Data Analytics e Machine Learning mais acessíveis para as empresas. Com um time de Desenvolvedores, Engenheiros, Cientistas e Analistas de Dados experientes, motivados e curiosos buscamos ser os diferenciadores nos projetos que atuamos. Requisitos Principais:·      Experiência com ferramentas de Data Visualization (Power BI, Looker, Tableau, Qlik, Redash) e DAX·       Experiência em desenvolvimento de Dashboards em Power BI·       Conhecimento avançado em DAX (Data Analysis Expressions)·       Conhecimento básico em SQL, para a construção de consultas em bancos de dados·       Conhecimento em modelagem de dados voltada para BI, com o foco na performance dos relatórios·       Experiência no desenvolvimento de métricas e KPIs que traduzem as necessidades das áreas de negócio·       Facilidade na compreensão de regras de negócio com o objetivo de propor soluções de BI.Requisitos Desejáveis:·       Experiência com ambientes em nuvem de BI sabendo publicar, compartilhar e gerenciar dashboards.·       Story telling, organizado, senso de urgência e priorização de demandas.·       Habilidades e conhecimento de boas práticas relacionadas a UX
Cientista de Dados;https://www.catho.com.br/vagas/cientista-de-dados/18621210/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (2);A Eleflow nasceu para tornar Big Data Analytics e Machine Learning mais acessíveis para as empresas. Com um time de Desenvolvedores, Engenheiros, Cientistas e Analistas de Dados experientes, motivados e curiosos buscamos ser os diferenciadores nos projetos que atuamos. reunir, interpretar e comunicar toda informação relevante contida em toneladas de dados que diariamente as empresas armazenam sobre o comportamento das pessoas, sejam elas seus clientes, prospects, funcionários etc. Experiência em ao menos uma destas linguagens: Python, SQL, R, Scala Experiência em pelo menos um destes Frameworks: Spark, PySpark, Databricks, WatsonStudio, SageMaker, Scikit-learn Experiência em pelo menos um ambiente de Cloud: AWS, Azure, GCP ou IBM Cloud. Conhecimento em estatística (Experiência em análise exploratória de dados e teste de hipóteses. Modelo preditivo e prescritivo e ao menos um destes pacotes de análise de dados e machine learning (como Pandas, NumPy, Matplotlib,) Requisitos Desejáveis:· Experiência prévia como desenvolvedor. Conhecimentos dos modelos Random Forest e XGBoost Conhecimento em versionamento e revisão de código (Git, ?github?, ?gitlab?)· Story telling, organizado(a), senso de urgência e priorização de demandas.
Especialista em BI;https://www.catho.com.br/vagas/especialista-em-bi/18419594/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Venha fazer parte de um Grupo que está em constante mudança e crescimento! Aqui você terá a oportunidade de trabalhar com os processos mais avançados de Gestão de Saúde, da Coordenação do Cuidado à Medicina Diagnóstica e Gestão Hospitalar, oferecendo um pacote integrado de soluções aos nossos clientes. Formação em Tecnologia e/ou Engenharia. Experiência prévia com temas de engenharia de dados. Experiência prévia com o desenho e execução de data lakes em cloud. Experiência com temas de estatística. Experiência com Power BI, Alteryx, MySQL, Hadoop ou DataStage, etc.
Engenheiro de Software;https://www.catho.com.br/vagas/engenheiro-de-software/18559348/?origem_apply=busca-de-vagas&entrada_apply=direto;Belo Horizonte - MG (1);Atuar como Engenheiro de Dados Sênior em projetos de Big Data dentro de uma multinacional. Desejável conhecimentos em DataStage e Python
Analista de Soluções;https://www.catho.com.br/vagas/analista-de-solucoes/18449376/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Análise e mapeamento dos processos, implantação, desenvolvimento de tecnologias e soluções para o negócio. Demais atividades inerentes ao cargo. Ensino Superior completo em Tecnologia da Informação e/ou áreas afins. Conhecimentos: em Power BI, Desenvolver painéis em Power BI, Desenvolver cálculos em DAX. Power BI 365, Power BI Reporting Service, Conhecimento em Engenharia de Dados, Desenvolvimento de Pipelines em DateFactory, Desenvolvimento em ETL em Databricks, Desenvolvimento em modelo em SSAS (Analysis Service), Experiência em ambiente nuvem Azure. Experiência em SQL, Python, Pyspark e Spark SQL.  Idioma:  Inglês - Intermediário
Cientista de Dados Pleno;https://www.catho.com.br/vagas/cientista-de-dados-pleno/18525278/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar com programação, desenvolvimento e codificação. Formação: Superior Completo. - (Mestrado) Tecnologia da informação, ciências da computação ou afins. - (Superior Completo) Ciência da computação ou afins. Idiomas: - Inglês | Nível: Avançado. Experiência como Engenheiro de Dados.
Professor Generalista de Data Science;https://www.catho.com.br/vagas/professor-generalista-de-data-science/18399535/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Venha fazer parte da empresa que está revolucionando o mercado de educação e tecnologia: estamos procurando profissionais do mercado que queiram construir conosco cursos de dados com projeção nacional e internacional. Atualmente, a Digital House oferece dois cursos de dados regularmente: Data Analytics e Data Science. Precisamos de profissionais com conhecimentos amplos em dados, em qualquer contexto (e.g., pesquisa, Business Intelligence, Data Science, Engenharia de dados, Big Data etc), para cuidar da qualidade desses cursos, além de participar da definição, planejamento e criação de novos cursos e treinamentos. Quanto à sua experiência profissional, é imprescindível que você tenha: Atuação profissional em alguma área de dados. Atuação como instrutor ou professor. Quanto aos seus conhecimentos, é imprescindível que você tenha conheça uma ou mais das seguintes áreas: Análise de dados (Business Intelligence, People Analytics, Pesquisa etc). Ciência de dados ou Inteligência Artificial (modelagem e implementação de algoritmos de Machine Learning e API). Engenharia de dados e Big Data (ecossistema Hadoop, bancos de dados, Cloud etc). É importante que você tenha disposição para aprender e desafiar-se continuamente, atuando proativamente para transformar demandas de amplo escopo em soluções de valor para a Digital House e para seus alunos e clientes. Suas principais funções serão: Acompanhar o andamento das turmas regulares de Data Analytics e Data Science e de treinamentos e cursos sob demanda, dando suporte aos professores, orientando-os e ajudando-os a aprimorar seu desempenho docente. Trabalhar com o squad de dados para avaliar criticamente e revisar ementas, materiais e metodologias empregados nos cursos e treinamentos. Desenvolver propostas de cursos e treinamentos sob demanda, presenciais ou online (caso você tenha experiência com cursos EAD ou desenvolvimento de recursos educacionais digitais, isso será um diferencial). Participar de bancas de avaliação de projetos desenvolvidos por alunos. Participar de eventos de promoção dos cursos. Participar de reuniões com clientes. Outras atividades que visem o aprimoramento dos cursos de dados e integração da equipe acadêmica da Digital House. Sua experiência é bem-vinda também em sala de aula: embora não seja o foco desta posição, você poderá atuar como professor em aulas específicas, dependendo da sua área de conhecimento e disponibilidade.
Estágio na área de Vendas;https://www.catho.com.br/vagas/estagio-na-area-de-vendas/18614706/?origem_apply=busca-de-vagas&entrada_apply=direto;Indaiatuba - SP (1);Deverá estar cursando: Estatística, Engenharia de Dados, Ciência de Dados ou Administração. Suporte na manutenção das informações relacionadas aos produtos, catálogo, novos lançamentos, e-commerce, apoio em elaboração de relatórios a partir das bases de dados de frota, informações dos concorrentes, entre outras atividades. Pacote Office. Diferencial Power BI e Dashboard.  Idioma:  Inglês - Intermediário
Analista de Sistemas;https://www.catho.com.br/vagas/analista-de-sistemas/18189583/?origem_apply=busca-de-vagas&entrada_apply=direto;Rio do Sul - SC (1);Especificar software no que se refere a estrutura, engenharia de funcionamento, telas e relatórios, assegurando a sua qualidade e o atendimento das normas aplicáveis ao respectivo setor da Administração Pública. Superior Completo em Ciências da Computação, Engenharia da Computação, Sistemas da Informação ou áreas correlatas. Conhecimento em Banco de Dados Estrutura de Dados Modelagem de Dados Engenharia de Processamento de Dados Linguagens de Programação (PHP ou Java ou Delphi ou Net Express) Normas e Procedimentos de Qualidade Sistemas operacionais SGBD Softwares auxiliares e software de uso interno.
Analista de Sistemas;https://www.catho.com.br/vagas/analista-de-sistemas/18409577/?origem_apply=busca-de-vagas&entrada_apply=direto;Rio do Sul - SC (1);Especificar software no que se refere a estrutura, engenharia de funcionamento, telas e relatórios, assegurando a sua qualidade e o atendimento das normas aplicáveis ao respectivo setor da Administração Pública. Superior Completo em Ciências da Computação, Engenharia da Computação, Sistemas da Informação ou áreas correlatas, conhecimento em Banco de Dados, estrutura de Dados, modelagem de Dados, engenharia de Processamento de Dados, Linguagens de Programação (PHP ou Java ou Delphi ou Net Express), normas e Procedimentos de Qualidade, sistemas operacionais, SGBD, softwares auxiliares e software de uso interno.
Analista de Soluções;https://www.catho.com.br/vagas/analista-de-solucoes/18579201/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Desenvolvimento de Pipelines em DateFactory, desenvolvimento em ETL em Databricks. Desenvolvimento em modelo em SSAS (Analysis Service). Conhecimento em Power BI. Desenvolver painéis em Power BI. Desenvolver cálculos em DAX. Power BI 365. Power BI Reporting Service. Conhecimento em Engenharia de Dados. Experiência em ambiente nuvem Azure. Experiência em SQL, Python, Pyspark e Spark SQL.
Analista de Soluções;https://www.catho.com.br/vagas/analista-de-solucoes/18428809/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Conhecimento em Power BI. Desenvolver painéis em Power BI. Desenvolver cálculos em DAX. Power BI 365. Power BI Reporting Service. Conhecimento em Engenharia de Dados. Desenvolvimento de Pipelines em DateFactory. Desenvolvimento em ETL em Databricks. Desenvolvimento em modelo em SSAS (Analysis Service). Experiência em ambiente nuvem Azure. Experiência em SQL, Python, Pyspark e Spark SQL.
Coordenador de Business Intelligence;https://www.catho.com.br/vagas/coordenador-de-business-intelligence/18027162/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar no planejamento e na condução de temas, nos projetos de desenvolvimento/ sustentação e na melhoria contínua. vivência em Gestão e desenvolvimento de equipe, coordenar o desenvolvimento e entrega dos projetos relacionados a dados, utilizando métodos ágeis, elaboração e gestão do planejamento estratégico e orçamentário, gestão de fornecedores , indicadores e experiência em projetos de Business Intelligence (BI), com foco em Engenharia de Dados.
Analista de Sistemas ERP Sênior;https://www.catho.com.br/vagas/analista-de-sistemas-erp-senior/18414054/?origem_apply=busca-de-vagas&entrada_apply=direto;Carmo da Mata - MG (1);Atuará com administração e suporte sistema ERP Sênior para usuários, entre outros. Experiência com implantação de sistemas, levantamento de processos internos atuando de forma consultiva exclusivamente no sistema Sênior HCM. conhecimento nos processos de todos os subsistemas de RH, Reforma Trabalhista e E- Social. Conhecimento de Excel intermediário. Conhecimento em rede, servidor SQL, de preferência conhecimento com sistema SENIOR porém pode ser também TOTVS ou SAP, criação de usuário, manutenção de máquinas, controle total de servidor e rede, que tenha conhecimento em utilitários como transferência pacote e-mail de outlook parametrização em estação de trabalho, firewall, 365 premium business Microsoft, backup e tenha pró atividade. Ensino Superior cursando ou interrompido. Certificações: Tecnologia da Informação. Conhecimento em Redes, Sistema Operacional Sênior, Sistema SAP ou TOTUS, Gestão em Informativa. Ensino Superior completo em Tecnologia da Informação, Engenheiro de Dados, Análise e Desenvolvimento de Sistemas. Diploma ou certificações: sistema Sênior, servidor SQL, TOTVS ou SAP.
Arquiteto de Dados Big Data;https://www.catho.com.br/vagas/arquiteto-de-dados-big-data/18193556/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Responsável pelo desenho da solução de arquitetura de dados, assim como apoiar tecnicamente ao tempo da Data & Analytics. Experiência em engenharia e arquitetura de dados Experiência em desenvolvimento, projetos e ambientes Big Data Experiência com o universo Hadoop, Python, Spark, Pyspark Experiência com Cloud AWS Graduação completa.
Data Engineer;https://www.catho.com.br/vagas/data-engineer/18627958/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar em engenharia de dados com Projetos de Big Data em Nuvem. Vivência com desenvolvimento de soluções de dados na plataforma Microsoft. Conhecimentos técnicos importantes ao projeto: Arquitetura de soluçõe, Azure, Arquitetura de dados. Banco de dados SQL Server. SQL Server Analysis Services (On-Premises e como serviço no Azure). SQL Server Intregration Services. SQL Server Reporting Services. Azure Data Factory. Microsoft Power BI. Azure Databricks. Certificações: - 70-462 - Administering Microsoft SQL Server 2012 Databases - 70-464 - Developing Microsoft SQL Server Databases - 70-465 - Designing Database Solutions for Microsoft SQL Server.
Estágio na área de Dados (Product Data);https://www.catho.com.br/vagas/estagio-na-area-de-dados-product-data/18531771/?origem_apply=busca-de-vagas&entrada_apply=direto;Belo Horizonte - MG (1);Deverá estar cursando: Você precisa: Estar cursando Ciência da Computação, Sistemas da Informação, Engenharia de Dados, Estatística ou áreas afins. O que você irá realizar com a gente: Auxiliar e compartilhar com a Equipe de Produtos, os dados sobre a utilização e percepção do produto Organizar dados e gerar dashboards, utilizando ferramentas de análise de dados para subsidiar processos de tomadas de decisão Monitorar o fluxo de dados que transitam na plataforma Auxiliar na governança dos dados Atuar na qualidade e confiabilidade dos dados Gerar indicadores de performance das entregas de produto Auxiliar no acompanhamento dos indicadores de desempenho do produto Validar através de dados as hipóteses do ciclo de Discovery Mensurar o valor gerado das entregas do produto Auxiliar no desenvolvimento de dashboards do produto. Ser apaixonado por dados. Será um diferencial se você tiver: Excel avançado Conhecimento em Python Conhecimento em R Conhecimento em SQL.
Estágio em Suporte Técnico;https://www.catho.com.br/vagas/estagio-em-suporte-tecnico/18425365/?origem_apply=busca-de-vagas&entrada_apply=direto;São Caetano do Sul - SP (1);Suporte técnico em software do mercado financeiro. Conhecimento em informática. Administração ou economia ou processamento de dados ou engenharia
Cientista de Dados;https://www.catho.com.br/vagas/cientista-de-dados/18428360/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Apoiar na implementação da área de análise de dados Validar modelos estatísticos atuais e desenvolver novos Responsável por resolver problemas de negócios usando técnicas orientadas por dados Trabalhar com uma variedade de linguagens de programação, incluindo Python e R Imprescindível que entenda de conceitos e tenha na prática atuado com construção de modelos estatísticos, regressão linear, regressão múltipla, álgebra linear e clustering Conhecimentos práticos para coletar e estruturar tecnicamente os dados, consiga tirar informações dos dados e usá-los para inovar e resolver problemas de negócios Atuação de forma comunicativa com diferentes públicos-alvo: negócios, tecnologia, diretoria e com engenheiro de dados, expondo suas necessidades, apresentando seus projetos, argumentando suas ideias e explorando novas oportunidades com as demais áreas de negócio, a fim de agregar valor à empresa. Formação Acadêmica: Ensino superior completo em Ciências da Computação, Engenharia, Física, Estatística, Matemática ou cursos correlatos. Conhecimentos básicos, o suficiente para interlocução com o time de TI em Machine learning, Deep learning, Arquitetura de dados, Arquitetura de - Soluções, Arquitetura de Sistemas Distribuídos, Azure - Databricks, DataFactory e Synapse, Banco de dados SQL, PostgreSQL, TimescaleDB@PostgreSQL, MongoDB e tecnologia de visualização PowerBI. Habilidade de linguagens de programação como Python e R. Atuar em projetos com metodologia ágil Utilização de ferramentas de gestão de projetos (Jira, Trello etc.).  Idioma:  Inglês - Intermediário
Data Engineer;https://www.catho.com.br/vagas/data-engineer/18418568/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Como Data Engineer na Coteminas, você ajudará a melhorar e a manter a qualidade de várias fontes de dados integradas em nosso data lake, data warehouse e data marts, orquestrando os processos apropriados de extração, transformação e carga. Será responsável por monitorar e evoluir a saúde da infraestrutura de dados e os jobs de migração, garantindo o sincronismo e a consistência das informações. Procuramos pessoas apaixonadas e orientadas a resolução de problemas complexos com grandes datasets e que adorem novos desafios e novas tecnologias. Experiência na função de Engenheiro de Dados ou Engenheiro de Software. Ensino superior completo em tecnologia. Competências técnicas: Projeto e operação de sistemas distribuídos de larga escala: Apache Beam/Spark. Experiência com Python e Shell Script para automação. Conhecimento em arquitetura de software e boas práticas de desenvolvimento. Experiência com plataformas de streaming. e.g. Kinesis, Cloud Pub/Sub, Kafka, RabbitMQ. Experiência com dados não estruturados. Experiência com serviços cloud (AWS/GCP ou similares). Desejáveis: Experiência com automação e manutenção de infraestrutura. e.g. Kubernetes. Experiência com serviços AWS: S3, EC2, Kinesis Data Firehose, EMR. Experiência com serviços GCP: BigQuery, Storage, Dataflow, Kubernetes Engine. Experiência com SQLServer e PostgreSQL. Gerenciamento de pipelines de dados com Airflow.
Técnico em Tecnologia da Informação;https://www.catho.com.br/vagas/tecnico-em-tecnologia-da-informacao/18453189/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Gerenciar as informações da organização, criando e distribuindo-as em redes de computadores, além de lidar com processamento de dados, engenharia de software, informática, hardwares e softwares. Ensino Superior ou Ensino Técnico na área de Tecnologia da Informação.
Auxiliar de Campo;https://www.catho.com.br/vagas/auxiliar-de-campo/18614499/?origem_apply=busca-de-vagas&entrada_apply=direto;Madre de Deus - BA (1);Auxilia técnicos e engenheiros com levantamento de dados, relatório e fotos. Apoio a equipes e laboratório. Experiência em pesquisas e cadastros socioeconômicos de famílias. Ensino Médio completo.
Auxiliar de Operação de Campo;https://www.catho.com.br/vagas/auxiliar-de-operacao-de-campo/18381502/?origem_apply=busca-de-vagas&entrada_apply=direto;Esteio - RS (1);Auxilia técnicos e engenheiros com levantamento de dados, relatório e fotos. Apoio a equipes e laboratório.
Arquiteto de Dados Sênior;https://www.catho.com.br/vagas/arquiteto-de-dados-senior/18249414/?origem_apply=busca-de-vagas&entrada_apply=direto;Campinas - SP (1);Suas principais responsabilidades serão: Buscamos candidato com experiência em arquitetura de dados no ambiente Cloud, especialmente na parte de BI e Analytics. Conhecimento de modelagem de dados. Conhecimento de rastreabilidade de dados e fluxo de ETL. Habilidade para entender o fluxo de dados para o negócio e transformar os requisitos identificados em solução. Habilidade para atuar como interface entre área de negócios e time de desenvolvimento (Engenheiros de Dados). Liderança de times. Conhecimento em gestão básica de projetos, a fim de organizar as atividades por prioridade e controlar demandas. Será o responsável pelo fluxo do processo, respondendo pela movimentação dos dados. Inglês fluente para interação com times globais. O que buscamos: Experiência em arquitetura de soluções end-to-end no ambiente Azure, especialmente na parte de BI e Analytics. Experiência em projetos Big Data no ambiente Azure, utilizando recursos Azure como HDInsight, Azure Databricks, Azure Synapse Analytics (antigo SQL DW), dentre outros. Conhecimentos de integração SAP. Conhecimento em arquitetura streaming. Certificação: Microsoft Certified: Azure Data Engineer Associate ou Microsoft Certified: Azure Solutions Architect Expert. Espanhol. Estar com passaporte e com visto americano dentro da validade (possibilidade de viagens para o Exterior). Informações adicionais: Disponibilidade para atuar em modelo remoto flexível.  Idioma:  Inglês - Fluente, Espanhol - Intermediário
Cientista de Dados;https://www.catho.com.br/vagas/cientista-de-dados/18539556/?origem_apply=busca-de-vagas&entrada_apply=direto;Brasilia - DF (1);Propor soluções técnicas para resolução de problemas complexos, fundamentado no estudo de dados. Reunir, analisar, comunicar, correlacionar, interpretar e transformar dados Aplicação de técnicas estatísticas e matemáticas como: Pareto, Histograma, Estudos de Amostras, Análise de padrões, Regressão linear e Logística, Anova, Frequência Absoluta e Relativa, Limites de Controle, distribuições e dispersões entre outras técnicas serão de relevantes.  Apoiar a implementação de novos projetos e produtos, auxiliar no estudo e desenvolvimento de Análises de Viabilidade técnica e de Custos. Atuar como responsável no mapeamento e identificação de disfunções em processos de produção, além de avaliar oportunidades de melhoria. Ensino Superior completo em Ciências da Computação, Engenharia, Engenharia de Dados, Estatística, Física ou Matemática. Pós-graduação Completa ou Cursando em: Big Data, Ciência de dados, Estatística aplicada a Saúde, Processos ou Produção. Proficiência em: Álgebra Linear, Matemática e Estatística aplicada.  Conhecimento no Pacote Office avançado .  Sólidos conhecimentos em: Data Mining, ETL e Estatística Aplicada em Saúde. Desejáveis Conhecimentos em: Banco de Dados, Big Data, Business Analitycs, Business Intelligence, fundamentos de linguagem de programação e construção de algoritmos, Data Lake, Data Warehouse, Deep Learning, Hadoop, Machine Learning, MapReduce e Spark, programação e análises de Dados (R,, Phyton e SQL). Experiência com ferramentas de análise e modelagem dados (Matlab, Minitab, e etc).  Idioma:  Inglês - Intermediário
Consultor Técnico Sênior;https://www.catho.com.br/vagas/consultor-tecnico-senior/18573626/?origem_apply=busca-de-vagas&entrada_apply=direto;Jaguariuna - SP (1);Projetos de implantação e operação de soluções de engenharia de dados com tecnologias Big Data Implantação de automações DevOps para provisionamento de artefatos e self- healing/autorrecuperarão de ambientes (infraestrutura como código) Operação de ferramentas de APM para monitoração de sistemas. Experiência em operações responsáveis por Site Reliability Engineering (SRE), através de disciplinas ITIL (solicitações/tickets, gestão de alertas, incidentes, problemas, configuração, mudanças). Conhecimentos Tecnologias Big Data (Hbase, Hive, ElasticSearch, Storm, Kafka e Zookeeper). Linguagens de programação para automação DevOps (Ansible, Chef, Rundeck, SCCM, Puppet, Satellite, PowerShell ? com Python, Java ou Ruby) Tecnologias de monitoração de sistemas (preferencialmente Dynatrace, mas interesse também por Interscope ou Zabbix) Ambientes de virtualização (ex: VMware, Hypervisor) Plataforma de computação em nuvem (ex: AWS, Google Cloud Platform, MS Azure) Inglês intermediário (leitura e escrita). Conhecimentos Desejáveis: Plataforma de decisões e scoring FICO Atuação em times através de gestão ágil (Ex: Scrum, SaFe). Atuação técnica no time de sustentação (Site Reliability Engineering) da mesa (área) responsável pela infraestrutura de motores das soluções Desenho e implantação de soluções de automação e configuração para mitigar riscos de indisponibilidade ou remediar problemas de infraestrutura e aplicações de diferentes tecnologias Buscar por oportunidades de evolução do ?manual? para o digital, através do AIOPS Instalação e configuração de ferramentas Troubleshooting e solução de problemas Apoio na definição e implantação de modelos de monitoração.
Analista de Dados;https://www.catho.com.br/vagas/analista-de-dados/18538752/?origem_apply=busca-de-vagas&entrada_apply=direto;Londrina - PR (1);Coletar a necessidade do negócio e criará um plano técnico para os desenvolvedores e, eventualmente, poderá participar de alguns desenvolvimentos também. Liderar e participar de sessões de design com administradores de dados corporativos e de hub, equipes de engenharia, cientistas de dados, gerentes de produtos, partes interessadas de negócios e de TI, que resultam em documentação para soluções de processamento, armazenamento e entrega de dados. Compreender as necessidades e processos de capacidade de negócios conforme se relacionam com Soluções de TI por meio de parceria com gerentes de produto e partes interessadas de negócios e funcionais de TI e aplicar esse conhecimento para influenciar as metas de negócios. Ajudar a equipe a estabelecer e melhorar processos e metodologias, como SCRUM ou Kanban, e/ou liderar novos pilotos Implementar soluções de dados de acordo com documentação de design usando uma variedade de ferramentas e linguagens de programação, como Kafka, bancos de dados SQL e não SQL, Scala, Go etc, e seguindo os processos e metodologias estabelecidos pela equipe. Facilitar e participar revisões de código, retrospectivas, testes funcionais e de integração e outros atividades da equipe focadas na melhoria da qualidade da entrega. Fornecer estimativas confiáveis ??para projeto de grande escala. Liderar a colaboração com proprietários de produtos, outros engenheiros e administradores de dados dentro da equipe e entre dados, plataformas técnicas e equipes de produtos no desenvolvimento e alinhamento de roteiros, datas de entrega e esforços de integração. Experiência com comercial e técnica em ferramentas AWS. Experiência com Diagrama de modelo de dados, documentação funcional e plano de teste. Desejável experiência com tecnologias AWS: EC2, Glue, Linux (Lambda), Spark, cNodes, Python e Espanhol
Analista de Dados;https://www.catho.com.br/vagas/analista-de-dados/18538744/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Coletar a necessidade do negócio e criará um plano técnico para os desenvolvedores e, eventualmente, poderá participar de alguns desenvolvimentos também.  Liderar e participar de sessões de design com administradores de dados corporativos e de hub, equipes de engenharia, cientistas de dados, gerentes de produtos, partes interessadas de negócios e de TI, que resultam em documentação para soluções de processamento, armazenamento e entrega de dados.  Compreender as necessidades e processos de capacidade de negócios conforme se relacionam com Soluções de TI por meio de parceria com gerentes de produto e partes interessadas de negócios e funcionais de TI e aplicar esse conhecimento para influenciar as metas de negócios.  Ajudar a equipe a estabelecer e melhorar processos e metodologias, como SCRUM ou Kanban, e/ou liderar novos pilotos  Implementar soluções de dados de acordo com documentação de design usando uma variedade de ferramentas e linguagens de programação, como Kafka, bancos de dados SQL e não SQL, Scala, Go etc, e seguindo os processos e metodologias estabelecidos pela equipe.  Facilitar e participar revisões de código, retrospectivas, testes funcionais e de integração e outros atividades da equipe focadas na melhoria da qualidade da entrega.  Fornecer estimativas confiáveis ??para projeto de grande escala.  Liderar a colaboração com proprietários de produtos, outros engenheiros e administradores de dados dentro da equipe e entre dados, plataformas técnicas e equipes de produtos no desenvolvimento e alinhamento de roteiros, datas de entrega e esforços de integração. Experiência com comercial e técnica em ferramentas AWS. Experiência com Diagrama de modelo de dados, documentação funcional e plano de teste. Desejável experiência com tecnologias AWS: EC2, Glue, Linux (Lambda), Spark, cNodes, Python e Espanhol.  Idioma:  Inglês - Fluente
Consultor de DataScience;https://www.catho.com.br/vagas/consultor-de-datascience/18512208/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Buscamos consultores em diversos níveis para projetos de Analytics e Machine Learning em instituições financeiras e grandes empresas de varejo. Formação em Estatística, Engenharia ou Ciência de de Dados. Experiência em desenvolvimento de modelos preditivos usando R, Python ou SAS.
Gerente de Growth;https://www.catho.com.br/vagas/gerente-de-growth/18474245/?origem_apply=busca-de-vagas&entrada_apply=direto;Barueri - SP (1);Experiência em marketing de Performance e Mobile apps. Definir quais dados e indicadores estratégicos são necessários para tomada de decisão. Definir as ferramentas para organização e análise dos dados. Criar soluções para uma melhor jornada do usuário. Melhorar o resultado em cada uma das etapas do funil de Growth. Construir e executar as melhores estratégias para aquisição e retenção de usuários através de mídia paga ou mesmo orgânico. Gestão de público alvo, criativos, budget e estratégias de leilão para maximizar a eficiência da mídia paga. Otimização de SEO e ASO para maior conversão de usuários. Dirigir decisões baseadas em dados através de contínuas experimentações e otimizações dos processos, inclusive testando novas interfaces. Trabalhar em conjunto com Produto, Engenheiros de software, Analista de dados e Designer para construção de funcionalidades que possibilitem escalabilidade do produto. Buscar e avaliar oportunidades de growth, priorizando os projetos de maior impacto e avaliando com os engenheiros e analista de dados, as dificuldades técnicas para o sucesso do projeto. Experiência com plataforma de atribuição ( Adjust). Habilidade em comunicação e persuasão para trabalhar com a sinergia entre os times disciplinares. Habilidade em análise de dados qualitativos e quantitativos para priorização de roadmap. Conhecimento em banco de dados (Mongo). Experiência com mobile. Inglês intermediário.
Analista de Suporte Técnico;https://www.catho.com.br/vagas/analista-de-suporte-tecnico/18474147/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Prestar suporte técnico presencial ou por telefone (Remoto) ao usuário, resolvendo problemas relativos ao funcionamento dos computadores da empresa. responsável por gerenciar as informações em uma organização, criando e distribuindo-as em redes de computadores, além de lidar com processamento de dados, engenharia de software, informática, hardwares e softwares. Desejável experiência na função. Formação concluída ou cursando, em Tecnologia da informação ou áreas afins!
Arquiteto;https://www.catho.com.br/vagas/arquiteto/18419461/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Desenvolvimento de projetos executivos e complementares Contato com fornecedores. Decisões técnicas Conhecimento em projetos executivos arquitetônico e disciplinas complementares (instalações e engenharias) Compatibilização Gestão de dados e documentos provenientes de tratativas com fornecedores. Desejável vivência com projetos fabril. Habilidade em: AutoCAD Project, Sketchup, Revit, BIM, Pacote Office.
Suporte Técnico;https://www.catho.com.br/vagas/suporte-tecnico/18408285/?origem_apply=busca-de-vagas&entrada_apply=direto;Fortaleza - CE (1);Prestar suporte técnico presencial ou por telefone (Remoto) ao usuário, resolvendo problemas relativos ao funcionamento dos computadores da empresa. responsável por gerenciar as informações em uma organização, criando e distribuindo-as em redes de computadores, além de lidar com processamento de dados, engenharia de software, informática, hardwares e softwares. Desejável experiência na função.  Formação concluída ou cursando, em Tecnologia da informação ou áreas afins!
Estágio em Análise de Dados;https://www.catho.com.br/vagas/estagio-em-analise-de-dados/18544218/?origem_apply=busca-de-vagas&entrada_apply=direto;Belo Horizonte - MG (1);Deverá estar cursando: Ensino Superior cursando em áreas de Tecnologia, Matemática, Estatística, Administrativa, Engenharias ou afins. Extração de dados do sistema. Alimentar e atualizar bases de dados. Atualização de dashboards no Power BI. Criação de tabelas, planilhas. Validação de dados. Operacionalizar estudos de caso. Ajudar em conferências de planilhas de outros departamentos. Conhecimento intermediário ou avançado em Excel (ou Planilha Google). Conhecimento básico de estatística. Conhecimento básico em Power BI.
Analista de Projetos;https://www.catho.com.br/vagas/analista-de-projetos/18534037/?origem_apply=busca-de-vagas&entrada_apply=direto;Nova Lima - MG (1);Editar e inserir informações no SAP, formatar e criar planilhas para carga em massa de informações no SAP, auxiliar as equipes de Manutenção, PCM e Engenharia no cadastro de dados, elaboração de relatórios semanais de acompanhamento. Graduação em Administração ou áreas correlatas Desejável experiência (na área): SAP - PM Conhecimento em Excel e Power Bi.
Tech Talentos RECODE;https://www.catho.com.br/vagas/tech-talentos-recode/18495179/?origem_apply=busca-de-vagas&entrada_apply=direto;Barueri - SP (1);Desenvolvimento de Produtos e Demandas Testes (QA) Infraestrutura e Segurança Engenharia e Ciência de Dados BI Analytics Inovação e Produtos E muito mais!! Com a gente, além de participar das Baratonas (o nosso Hackathon interno) você trabalhará com diversas Tecnologias, entre elas:  C# .Net .Net Core PHP Node.Js React React Native SQLServer PostgreSQL
Data Engineer Tech Lead;https://www.catho.com.br/vagas/data-engineer-tech-lead/18488105/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Responder pela gestão do time de Engenharia Dados Prover análise e migrações de estruturas de dados vindas de diversas fontes Suportar a construção e manutenção do ambiente de Data Lake Conduzir o mapeamento e documentação da informação estratégica em formato tabular, incluindo data sets para modelagem estatística e auxílio no provisionamento de Data Marts. Efetuar manutenções em códigos existentes, desenvolver novas funcionalidades e manter "vivo" o ambiente atual Ser o agente transformador da Cultura DevOps. Experiência de implementação de Banco de dados relacional (SQLServer, Athena, MySQL e PostgreSQL) e soluções Big Data (MongoDB, Spark). Conhecimento em modelagem de dados (relacional e não relacional) Conhecimento em tuning de queries (SQL) Experiência com ferramentas de ETL - extração, transformação e carregamento (AWS DMS, Glue, dbt, Airflow, Stitch, NiFi) Linguagens de programação: Python (bibliotecas Pandas, Arrow, scikit-learn, PySpark) e JavaScript Conhecimento em estratégias e ferramentas de gestão do ciclo de vida dos dados e replicação Provisionamento de dados através da construção de APIs utilizando Python Flask Experiência com ambientes e serviços de Cloud para suporte ao Data Lake. Conhecimentos de AWS e Google Cloud. Principais requisitos: AWS Lambda, ECS (Docker), EC2, VPC, cluster EMR, S3, EFS e SageMaker.   Você terá destaque se:  Tiver conhecimentos de técnicas de Machine Learning Conhecimento de ferramentas de visualização, como Power Bi Experiência prévia com ambientes de Data Warehouse. Liderança de Squad em processo Ágil.    Soft Skills  Forte desejo de auto-desenvolvimento e aprimoramento Abertura para feedback Adora trabalhar em equipe Proatividade, sempre se importar e se comportar como o dono dos entregáveis.
Arquiteto de Dados Sênior;https://www.catho.com.br/vagas/arquiteto-de-dados-senior/18587912/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Experiência com engenharia ou arquitetura de dados. Ter sido parte de uma equipe de desenvolvimento mais ampla, pareando com pessoas desenvolvedoras e, idealmente, analistas de negócios, pessoas engenheiras de infraestrutura e designers. Práticas ágeis como Scrum. Modelagem de dados relacional e multidimensional lógica e física, BI, Analytics e Big Data. Desenvolvimento, projetos e ambientes Big Data. Universo Hadoop, Python, Spark, Pyspark, Microsoft Azure, PowerBI, DAX, Azure Data Lake, Stream Analytics, Governança de dados e arquitetura de dados.
Orçamentista de Máquinas e Equipamentos;https://www.catho.com.br/vagas/orcamentista-de-maquinas-e-equipamentos/18595463/?origem_apply=busca-de-vagas&entrada_apply=direto;Pinhais - PR (1);Responsável por analisar e desenvolver orçamentos de projetos mecânicos e instalações. Desenvolvimento de novos componentes e dimensionamento de estruturas. Propor soluções com objetivo de redução de custos e aumento da taxa de conversão de negócios. Liberação de pedidos, melhorias em projetos. Interagir com a engenharia para levantamento de dados e esclarecimentos. Controlar prazo de documentação e seguir as normas de qualidade. Experiência com projetos mecânicos em AutoCad e Catia. Conhecimento de leitura e interpretação de desenhos técnicos. Conhecimento em pacote Office Boa administração do tempo. Raciocínio lógico e bom relacionamento interpessoal. Ensino Técnico cursando Mecânica ou Mecatrônica.
Técnico Especialista de Manutenção;https://www.catho.com.br/vagas/tecnico-especialista-de-manutencao/18434335/?origem_apply=busca-de-vagas&entrada_apply=direto;Belo Horizonte - MG (1);Garantir se a execução das atividades está sendo realizadas com qualidade Esse profissional terá um olhar matricial vinculado a garantia da qualidade dos processos verificar a necessidade de realização de treinamentos multiplicar conhecimentos garantir que as pessoas que pertençam a área estejam alinhadas aos objetivos da área Mapear processos, identificar oportunidade de melhorias Apoiar o Supervisor de manutenção tecnicamente na condução da equipe durante a realização das atividades, identificando oportunidades de capacitação e treinando a equipe Treinar os executantes de manutenção na consulta de manuais de manutenção, catálogos de peças e softwares de diagnóstico Scania e Mercedes Bens Participar das análises de falha e perfil de perdas junto à Engenharia sendo o responsável por levantar dados para análises de por garantir o cumprimento das ações destas análises Auditar o processo de execução de manutenção quanto ao cumprimento de procedimentos operacionais, planos de manutenção, instruções dos manuais dos fabricantes e quanto a qualidade das informações registradas sobre as manutenções executadas Elaborar instruções técnicas e procedimentos operacionais Desenvolver trabalhos e análises técnicas específicas com relatórios técnicos conforme demandados pelo Coordenador de Manutenção. Técnico em Mecânica completo. Experiência em Manutenção de caminhões de pequeno porte.
Especialista em Marketing Digital;https://www.catho.com.br/vagas/especialista-em-marketing-digital/18119929/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Acompanhar o desempenho das campanhas e acessos do site através das ferramentas de Web Analytics - Analisar constantemente o desempenho das visitas, conversão, vendas e campanhas de marketing - Analisar dados do site e a partir deles ter insights para melhoria constante - Elaborar relatórios de acessos e desempenho - Mensurar cohorts, life time value e payback de cada canal de marketing - Analisar a experiência do usuário no site - Mensurar a verba de marketing por canal, calculando projeção de ROI - Analisar constantemente as metas do site por canal, informando a área de marketing para cumprimento de metas - Criar alertas na ferramenta de Web Analytics para monitoramento de erros no site - Contribuição para análises preditivas e construção de modelos de atribuição. Superior Completo em Administração, Marketing, Engenharia, Gestão de Dados e Informações ou áreas afins - Inglês Avançado - Pacote Office Avançado - Sólido conhecimento em , Google Analytics, Google Tag Manager, Google Ads, Google Sheets e Plataformas de mídia, teste A/B - Certificação Necessária: Google Adwords . Desejáveis: - Conhecimento e experiência em Scrum/Desenvolvimento Ágil - Integrações com Salesforce - Conhecimentos sobre integrações diversas para a utilização de novas mídias e automatizações necessárias
Programador Delphi;https://www.catho.com.br/vagas/programador-delphi/18194617/?origem_apply=busca-de-vagas&entrada_apply=direto;Rio do Sul - SC (1);Desenvolver e executar a manutenção dos programas e softwares. Desenvolver os programas em conformidade com o padrão de interface, navegação e engenharia de processamento estabelecidas para atendimento da qualidade de toda a aplicação Corrigir as inconformidades ou inconsistências dos programas Melhorar as rotinas dos softwares Ensino superior completo em Ciências da Computação, Engenharia da Computação, Sistemas de Informação, ou em áreas correlatas Experiência na função será um diferencial Linguagem de Programação Delphi Lógica de Programação Desejável vivência em Banco de Dados, Sistema Operacional, Softwares Auxiliares, Modelagem de Dados, Engenharia de Processamento de Programas Inglês Técnico.
Técnico em Tecnologia da Informação;https://www.catho.com.br/vagas/tecnico-em-tecnologia-da-informacao/18493346/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);gerenciar as informações em uma organização, criando e distribuindo-as em redes de computadores, além de lidar com processamento de dados, engenharia de software, informática, hardwares e softwares.  instalações ERP pró ativo, interessado dinâmico e ágil
Desenvolvedor Android | Presencial ou Home Office;https://www.catho.com.br/vagas/desenvolvedor-android-presencial-ou-home-office/18621214/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);A Eleflow nasceu para tornar Big Data Analytics e Machine Learning mais acessíveis para as empresas. Com um time de Desenvolvedores, Engenheiros, Cientistas e Analistas de Dados experientes, motivados e curiosos buscamos ser os diferenciadores nos projetos que atuamos. Requisitos básicos:- Android Studio- Java- Kotlin.Requisitos desejáveis:- Graddle- Detekt- Mockito- OpenAPI- Ambiente AWS (Lambdas, API Gateway, SNS)
Técnico Informática;https://www.catho.com.br/vagas/tecnico-informatica/18612685/?origem_apply=busca-de-vagas&entrada_apply=direto;Belo Horizonte - MG (1);Gerenciar as informações em uma organização, criando e distribuindo-as em redes de computadores, além de lidar com processamento de dados, engenharia de software, informática, hardwares e softwares.    Configurações e programações de sistemas informáticos    Montagem e instalação de computadores    Assistência na correção de defeitos ou falhas nas redes ou equipamentos    Responsável pela cotação e compra de suprimentos para o setor. Necessário curso técnico de informática
Programador PHP;https://www.catho.com.br/vagas/programador-php/18395919/?origem_apply=busca-de-vagas&entrada_apply=direto;Rio do Sul - SC (1);Desenvolver os programas em conformidade com o padrão de interface, ergonomia, navegação e engenharia de processamento estabelecidas para atendimento da qualidade de toda a aplicação Corrigir as inconformidades ou inconsistências dos programas Ensino superior completo ou cursando Ciências da Computação, Engenharia da Computação, Sistemas de Informação ou em áreas correlatas. Linguagens de Programação PHP, Lógica de Programação. Desejável vivência em Banco de Dados, Sistema Operacional, Softwares Auxiliares, Modelagem de Dados, Engenharia de Processamento de Programas.
Analista de Dados - Célula de Operações e Logística;https://www.catho.com.br/vagas/analista-de-dados-celula-de-operacoes-e-logistica/18572424/?origem_apply=busca-de-vagas&entrada_apply=direto;Vila Velha - ES (1);Buscamos um profissional para apoiar as áreas de análises de dados e indicadores da célula de inovação e melhoria - Operações e Logística.Se você tem veia de inovação e facilidade com números e atividades lógicas, aqui é o seu lugar!Candidate-se hoje! Ensino Superior Completo em Ciência de Dados, Engenharias ou áreas afins. Conhecimento do Tableau, Power BI ou Excel avançado. Habilidade para lidar com tarefas de controle e análise. Desejável experiência como Analytics ou Cientista de Dados. Conhecimento de Gestão por Processos.
Técnico Especialista em Manutenção;https://www.catho.com.br/vagas/tecnico-especialista-em-manutencao/18568411/?origem_apply=busca-de-vagas&entrada_apply=direto;Congonhas - MG (1);Apoiar o Supervisor de manutenção tecnicamente na condução da equipe durante a realização das atividades, identificando oportunidades de capacitação e treinamento da equipe. Treinar os executantes de manutenção na consulta de manuais de manutenção, catálogos de peças e softwares de diagnóstico Scania e Mercedes Bens Participar das análises de falha e perfil de perdas junto à Engenharia sendo o responsável por levantar dados para análises de por garantir o cumprimento das ações destas análises. Auditar o processo de execução de manutenção quanto ao cumprimento de procedimentos operacionais, planos de manutenção, instruções dos manuais dos fabricantes e quanto a qualidade das informações registradas sobre as manutenções executadas. Elaborar instruções técnicas e procedimentos operacionais. Contribuir para a melhoria contínua através de implementação de Kaizens e participação em grupo de CCQ. Desenvolver trabalhos e análises técnicas específicas com relatórios técnicos conforme demandados pelo Coordenador de Manutenção. Formação Técnica em Mecânica ou Eletromecânica. Experiência sólida em manutenção de equipamentos móveis de mina com conhecimento em manutenção de caminhões Mercedes Benz e Scania Experiência como Técnico de Manutenção. Pacote Office Intermediário (Windows, Word, Excel, Power Point).
Engenheiro Comercial;https://www.catho.com.br/vagas/engenheiro-comercial/18382513/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Estuda e analisa especificações dos clientes para a elaboração de propostas para o desenvolvimento de projetos. Faz negociação com clientes. Avalia as normas e especificações visando adequar o projeto ou aplicar novos conceitos.  Executa seu trabalho em estrita relação com o departamento de engenharia da empresa registrando todos os dados para compor a documentação técnica do projeto.  Mantém contatos com os clientes atualizando-os quanto ao andamento do projeto, esclarecendo dúvidas etc. bem como reúne-se com parceiros e fornecedores visando manter os cronogramas e os padrões de qualidade estabelecidos.   Mantém-se informado sobre novos conceitos, literatura técnica, novos equipamentos, softwares, cursos de treinamento etc. para atualização tecnológica e suporte às demais áreas da empresa. Engenheiro Mecânico, Eletrifico, Eletrônico, Mecatrônica...  experiência em empresas de energia será desejável , necessário  perfil comercial.  Idioma:  Inglês - Intermediário, Espanhol - Intermediário
Projetista Eletricista - Projetos Subestações Elétricas.;https://www.catho.com.br/vagas/projetista-eletricista-projetos-subestacoes-eletricas/18573538/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (2);Projetos de subestações de alta tensão (mínimo 138kV). Conhecimento em projetos de subestações elétricas de alta tensão e projetos de geração elétrica em geral. Realizar levantamento de dados com a engenharia, diagramas unifilares, dimensionamento de equipamentos para SSAA, especificações técnicas de materiais, desenhos de equipamentos. Elaborar projetos envolvendo: planta de arranjo de equipamentos elétricos, layout geral da subestação e todo o projeto de Instalação elétrica. Habilidades em aplicações Microsoft Office (Word, Excel, PowerPoint). Conhecimento de softwares como: AutoCAD.  Idioma:  Espanhol - Intermediário, Inglês - Intermediário
Programador Delphi;https://www.catho.com.br/vagas/programador-delphi/18339824/?origem_apply=busca-de-vagas&entrada_apply=direto;Rio do Sul - SC (1);Desenvolver e executar a manutenção dos programas e softwares. Desenvolver os programas em conformidade com o padrão de interface, navegação e engenharia de processamento estabelecidas para atendimento da qualidade de toda a aplicação. Corrigir as inconformidades ou inconsistências dos programas. Melhorar as rotinas dos softwares. Ensino superior completo em Ciências da Computação, Engenharia da Computação, Sistemas de Informação, ou em áreas correlatas. Experiência na função será um diferencial. Linguagem de Programação Delphi. Lógica de Programação. Desejável vivência em Banco de Dados, Sistema Operacional, Softwares Auxiliares, Modelagem de Dados, Engenharia de Processamento de Programas. Inglês Técnico.
Analista de BI e Data Science Sênior;https://www.catho.com.br/vagas/analista-de-bi-e-data-science-senior/18413160/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Elaborar análises e modelos para suportar o atingimento dos resultados estratégicos do dr.consulta (receita, custos, NPS, otimização da oferta médica, otimização da utilização dos centros médicos) Identificar novas oportunidades de ganhos de eficiência através da análise de dados e algoritmos de predição Transmitir para a alta administração e demais áreas as conclusões e oportunidades levantadas. Implementar na ponta soluções propostas e validar os resultados Suportar o desenvolvimento de indicadores de resultados desdobrados, a partir de modelagem de dados. Propor e desenvolver novos produtos baseados em dados que agreguem valor aos nossos pacientes e médicos. Ensino Superior Completo, podendo ser em Matemática, Estatística, Ciência da Computação, Ciência de Dados, Engenharias ou áreas afins. Conhecimento de ferramentas de BI e Data Science Experiência prévia na área Linguagem de programação (SQL - Básico e R ou Python - Básico) Autodisciplina, pois vai ter muita autonomia Capacidade analítica Foco em Resultado Resiliência.
Analista de Tecnologia de Pagamentos Pleno (Payments Rel. Manager);https://www.catho.com.br/vagas/analista-de-tecnologia-de-pagamentos-pleno-payments-rel-manager/18585501/?origem_apply=busca-de-vagas&entrada_apply=direto;Florianópolis - SC (1);Será responsável pelo processo de processamento e enriquecimento de dados focado nas operações de conciliação e pagamento de comissões, tanto em relação à execução da operação quanto na evolução e automatização do processo. Será ponto de contato com parceiros para o enriquecimento de informações e conciliações de operações contestadas, estará diretamente conectado com o time de conciliação e pagamentos apoiando esses processo através da disponibilização de dados com eficiência e agilidade e identificação de demandas de soluções de tecnologia (dados + automação). Responsável pela disponibilização de dados para relatórios de funil de conversão de venda, gerenciará o time de processamento de dados de pagamento (analista de dados + Engenheiro de Integração) organizando as demandas identificadas.
Data Analytics - Insights - Pleno;https://www.catho.com.br/vagas/data-analytics-insights-pleno/18528745/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Atuar com análise e modelagem de dados modelagem preditiva, previsão de séries temporais e análise de gráficos painel de controle e ferramentas de relatório como PowerBI ou Tableau. Antecedentes em Matemática Aplicada, Estatística, Informática, Comércio, ou Engenharia Experiência com análise e modelagem de dados Experiência em modelagem preditiva, previsão de séries temporais e análise de gráficos Experiência com painel de controle e ferramentas de relatório como PowerBI ou Tableau Capacidade de discutir análises e aspectos técnicos com um público empresarial Histórico de execução bem sucedida em um ambiente de equipe Fortes habilidades de comunicação com capacidade de processar e explicar conceitos técnicos complexos e alinhar a organização às decisões.  Idioma: Inglês Avançado.
Data Architect;https://www.catho.com.br/vagas/data-architect/18488095/?origem_apply=busca-de-vagas&entrada_apply=direto;Campinas - SP (1);Atuar como arquiteto de dados e ser o condutor de desenho de tecnologias de dados e modelos de entidades e ETL para os projetos de desenvolvimento de produtos analíticos e de aplicação para os squads de desenvolvimento, área de ANALYTICS & INTELLIGENCE e usuários de BI Trabalhar em conjunto e alinhamento tático e estratégico aos demais arquitetos e líderes das áreas de TECHNOLOGY & INTELLIGENCE, assim como analisar requerimentos funcionais e não-funcionais da área de PRODUCT Introduzir novas práticas e tecnologias, através de Provas de Conceito e Tecnologia, treinar e disseminar os resultados e conhecimentos para implantação nos projetos Liderar os times na direção de resolução de problemas identificados, pesquisando, e coordenando os recursos necessários para o efetivo troubleshoot e diagnóstico de problemas complexos dos projetos e suas soluções propostas Avaliar novas tecnologias e sua aplicabilidade para o negócio Extrair e traduzir as necessidades e requerimentos em alternativas e soluções para a ingestão, transformação e processamento de vários recursos de dados estruturados e desestruturados, identificando riscos e impactos, e os ajustes sobre planejamento para facilitar a gestão de tomada de decisão Liderar a direção técnica e a evolução da arquitetura de dados através de revisões de arquitetura junto aos squads e produtos envolvidos nos projetos Ativamente monitorar as unidades de negócio e seus sistemas visando a saúde e desenho das soluções e tecnologias de dados, assim como escrever propostas de remediação e causas de tendências negativas na arquitetura Proativamente monitorar os novos desenvolvimentos para a descoberta de necessidades de ajustes ao data lake e data warehouse, ou processamento de dados que deveria evoluir em uma infraestrutura e plataforma aberta de dados, compartilhada e de fácil acesso Proativamente pesquisar, monitorar, aprender e validar avanços da indústria e tecnologia, e continuamente construir alianças para explorar maneiras de alavancar e avançar as oportunidades técnicas. Forte entendimento de linguagens de programação, código, padrões, frameworks de bancos de dados Domínio e conhecimento de linguagens de programação como, Python, Numpy, Pandas, PySpark, assim como SQL, NOSQL, soluções de dados como AWS Glue, S3, Glacier, Redshift, MongoDB, Elasticsearch, Stitch, Airflow, um expert na disciplina de engenharia de dados Expert na pluralidade de tecnologias como, Sistemas de Processamento Paralelo e Distribuído, em Nuvem, Query de dados, Data Mining, linguagens estruturadas e declarativas e computação de alta-performance, escalabilidade e resiliência Conhecimento de UML e ferramentas de modelagem, para desenho de modelos de bancos de dados, tabelas, arquivos, ETC,,armazenamento de dados, em uma arquitetura orientada a serviços, protocolos de integração e comunicação entre sistemas Entendimento de sistemas operacionais como Windows e Linux Fortes habilidades de organização, planejamento de projetos, gestão do tempo e mudanças entre grupos funcionais múltiplos e áreas, assim como delegação envolvendo priorização, re-priorização de projetos de vários tamanhos e complexidades Experiência avançada em resolução de problemas envolvendo times de liderança, identificando, pesquisando e coordenando recursos necessários para efetivamente diagnosticar questões complexas de projeto, sucesso em extrair e traduzir descobertas de alternativas e soluções, identificando riscos e impactos, assim como ajustes de cronogramas para facilitar as tomadas de decisão dos líderes Habilidade avançada de comunicação (verbal e escrita) e serviço ao cliente. Habilidades interpessoais e apresentação para vastas audiências incluindo a liderança e gestores executivos, clientes, etc. Incluindo dicção, terminologia e apresentando informação de forma concisa e efetiva em diferentes meios de comunicação.   Você terá destaque se:  Tem experiência em arquitetar dados estruturados e desestruturados, big data em nuvem Em modelar, documentar e descrever arquiteturas de dados For hands-on e independente ao desenvolver Provas de Conceito e de Tecnologia Ter implementado projetos de infraestrutura de servidores, processamento de dados e serviços de bancos de dados e big data em nuvem Ter prática de arquitetura no modelo ágil.   Soft Skills  Forte desejo de auto-desenvolvimento e aprimoramento Desafia o status-quo de forma construtiva Foco nos aspectos do negócio e visão comercial para a decisões de tecnologia Busca inovar, pensar Lean com foco em entrega de valor contínuo Abertura para feedback Facilidade com trabalho em time.
Analista de Negócios Sênior;https://www.catho.com.br/vagas/analista-de-negocios-senior/18599901/?origem_apply=busca-de-vagas&entrada_apply=direto;Santos - SP (1);Cria as especificações funcionais, com base nas necessidades de negócio, podendo sugerir novas soluções funcionais para as áreas solicitantes. Acompanha o desenvolvimento da solução de acordo com os especificações funcionais. Realiza a validação funcional do sistema desenvolvido, de acordo com o especificações funcional. Assegura o funcionamento dos sistemas desenvolvidos e contratados, mantendo o apoio mutuo entre todas as áreas envolvidas nesse processo, sejam internas ou externas ao departamento, na solução de problemas. Cria e mantém manuais de uso das soluções entregues. Coordena a homologação da solução desenvolvida e garante o aceite por parte do solicitante. Cria planos de testes para as soluções demandadas. Ensino Superior completo em áreas correlatas a função (IT). Desejável Pós Graduação. Experiência anterior em modelagem de dados e engenharia de requisitos. Experiência anterior na função. Pacote Office avançado.  Idioma:  Inglês - Fluente
Analista de Status Pleno (Status Rel. Manager);https://www.catho.com.br/vagas/analista-de-status-pleno-status-rel-manager/18585512/?origem_apply=busca-de-vagas&entrada_apply=direto;Florianópolis - SC (1);Será responsável pelo processo de processamento e enriquecimento de dados de status de solicitações realizadas pela plataforma Franq disponibilizados pelos diferentes parceiro financeiros. Será ponto de contato com parceiros para o enriquecimento de informações e garantia de assiduidade na entrega de informações pelos parceiros, bem como a qualidade destas, apoiará o time de CS no entendimento dos status das solicitações e esclarecimentos de dúvidas, bem como, disponibilização de dados de detalhamento de status de operações. Apoiará o time de comunicação na viabilização de transmissão da informação referente aos status das operações aos PBs. Garantirá a qualidade e enriquecimento das informações pertinentes a status tanto dentro da plataformas Franq quanto àquelas provenientes de parceiros, responsável pela disponibilização de dados para relatórios de funil de conversão de venda. Gerenciará o time de processamento de dados de status (analista de dados + Engenheiro de Integração + Analista de CRO) organizando demandas identificadas juntamente ao time de CS e Marketing.
Analista Digital Pleno;https://www.catho.com.br/vagas/analista-digital-pleno/18451197/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Superior completo nas áreas: Estatística/Engenharia de Produção/Matemática Experiência em áreas de CRM/inteligência de dados/BI Experiência em criação de dashboards direcionados para tomadas de decisão Experiência em projetos de implementação de Data Driven Conhecimento em Excel Avançado, Access Conhecimento em Salesforce Experiência em Framework de processamento de dados (especificar) Experiência com banco de dados e ferramentas de visualização (SQL Server, Pyhton, Looker, Tableau, Power BI) Desenvolver modelos estatísticos preditivos (criação, análise e manutenção) para suporte a tomada de decisão Trabalhar na especificação, desenvolvimento e estruturação de projetos de data Science Atuar em diversas etapas do projeto de data Science: transformação, limpeza de dados, engenharia, modelagem e visualização Implementar melhores práticas, arquiteturas, algoritmos e metodologias orientadas a dados Gerar análises e plano de ação para melhoria de KPIs.
Gerente de Projetos e Operações;https://www.catho.com.br/vagas/gerente-de-projetos-e-operacoes/18482416/?origem_apply=busca-de-vagas&entrada_apply=direto;Recife - PE (1);Experiência com PMO e Governança de TIC. Conhecimento de ferramentas de gerenciamento de projetos. Experiência gerenciando projetos e contratos, áreas internas e equipes multifuncionais (squads). Experiência em tratar demandas, propor, desenhar e acompanhar qualidade de soluções de infraestrutura de TIC com intuito de prover serviços de Front-end para configuração de sistemas móveis e Data Centers em Cloud. Conhecimento em tecnologias de backup, Sistemas operacionais Windows e Linux. Conhecimento em soluções de servidores, storage, backup, sistema operacional, banco de dados e conectividade. Conhecimento em soluções de replicação em ambiente físico e/ou nuvem. Experiência na arquitetura em nuvens públicas. Experiência nas funções de gerenciamento de Projetos/Contratos e/ou de Customer Success Manager. Ensino Superior completo em Análise de Sistemas, Ciências da Computação, Processamento de Dados, Engenharia Eletrônica, ou áreas afins. Desejável vivência prévia em operadoras de comunicação e/ou datacenters nas áreas de projetos e/ou operações. Desejável conhecimentos em Metodologia Ágil, Kanban, Scrum. Diferencial Inglês técnico. Certificações AWS, GCP e/ou Azure.
Suporte e Monitoramento;https://www.catho.com.br/vagas/suporte-e-monitoramento/18490152/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Monitoramento e atendimento de incidências de N1, utilizando o ambiente NOC (Network Operation Center) Direcionamento de chamados para os próximos níveis de atendimento ou áreas solucionadoras Execução de solução ou medida de contorno para pronto atendimento da ocorrência Atendimento de requisições de serviço. Propostas de Melhorias nos processos existentes (PDCA) Operação de serviços de TI e atendimento de incidências de N1 para prestação de serviços, incluindo a plataforma mainframe, sistemas web, servidores e ferramentas de backup e schedulagem. Requisitos e qualificações Superior em ciência da computação, análise de sistemas, processamento de dados, engenharia, área de exatas, análise de sistemas gerenciais, administração de sistemas de informações ou MBA ou especialização nas áreas de TI ou Tecnólogos nas áreas de tecnologia da informação certificação ITIL v3 Foundation Conhecimento (nível operacional): - Zabbix - Solução de monitoramento Conhecimento (nível operacional): - ITSM - Ferramenta de registro de solicitações Conhecimentos nas Ferramentas (nível operacional): Commvault ou EDI/RVS - Transferência bancária arquivos enviados e recebidos.
Coordenador de Processos e Desenvolvimento;https://www.catho.com.br/vagas/coordenador-de-processos-e-desenvolvimento/18326649/?origem_apply=busca-de-vagas&entrada_apply=direto;São Paulo - SP (1);Coletar dados e analisar as necessidades dos negócios, identificando processos, desenhando-os e automatizando-os.  Analisar problemas complexos de negócios e avaliar como o sistema de colaboração, integração e automatização de processos pode ser implementado para resolvê-los.  Realizar levantamento e definição dos requisitos funcionais e de sistemas em conjunto com as áreas de negócio.  Ser o elo de ligação com a gestão de TI, coordenando os trabalhos de mapeamento de processos voltados para as customizações dos sistemas ERP e Corporativo.   Atuar como administrador do sistema informatizado de colaboração, integração e automatização de processos ? Fluig.  Ampliar a utilização das atuais e identificar novas ferramentas que auxiliem a gestão dos processos, o ganho de produtividade e a efetividade dos controles.  Identificar pontos fortes e fraquezas dos processos mapeados e apontar oportunidades e ameaças.  Observar às políticas corporativas e buscar o alinhamento dos processos com os princípios nelas estabelecidos.  Coordenar e supervisionar os trabalhos de desenvolvimento de fluxos automatizados e sistemas.  Definir com o Supervisor de Processos e Qualidade a agenda de trabalhos desenvolvidos e em desenvolvimento na área de Processos.  Atuar como líder de projetos na avaliação, elaboração, aprovação, execução, monitoramento e encerramento de iniciativas multifuncionais e/ou estratégicas, a fim de garantir o seu alinhamento contínuo com os objetivos de negócios  e observando as práticas definidas pelo Escritório de Projetos.  Atuar como interlocutor para facilitar as discussões entre as várias partes interessadas dos projetos em que liderar, garantindo o atendimento do escopo, do cronograma, da qualidade e do orçamento estabelecidos.  Auxiliar a Gerência de Planejamento nos trabalhos voltados para implantação de iniciativas multifuncionais e/ou estratégicas. Ensino superior completo em Tecnologia em Processamento de Dados ou Engenharia de Sistemas
Administrador de Dados;https://www.catho.com.br/vagas/administrador-de-dados/18528282/?origem_apply=busca-de-vagas&entrada_apply=direto;Recife - PE (1);Criar modelo de dados conceitual, lógico e físico. Realizar engenharia reversa de modelo de dados. Criar e executar carga de dados. Criar e executar rotinas de integração de dados. Administrar as estruturas das bases de dados. Desenvolver comandos DDL, DML, DCL e TCL. Apoiar as equipes na localização de dados nas diversas bases de dados existentes. Apoiar desenvolvimento de requisitos. Elaborar, manter e disseminar normas, padrões e dicionários de dados dos repositórios de dados. Apoiar análise e desenvolvimento do modelo de negócio dos sistemas. Apoiar a equipe de Informações e Business Intelligence. Buscamos um profissional que possua: Nível superior completo, preferencialmente nas áreas de Tecnologia da Informação, Engenharia ou Administração, ou possuir nível superior completo em outras áreas diferentes, tendo neste caso que possuir pós-graduação na área de Banco de dados ou Administração de dados. Conhecimento comprovado através de cursos ou experiência comprovada em análise e administração de dados. Conhecimento em modelagem de dados. Conhecimento em ferramenta case de modelagem de dados. Conhecimento no planejamento, organização e controle de dados corporativos. Conhecimento na documentação e gerenciamento de dados corporativos. Conhecimento em administração de objetos de banco de dados em SQL Server. Conhecimento em desenvolvimento de scripts SQL Conhecimento comprovado através de cursos ou experiência comprovada em SQL ANSI, SGDBs SQL Server e PostgreSQL. Será um diferencial caso o profissional apresente conhecimentos em: Análise de negócios. Análise de performance de queries. SQL Server - Integration Services. Ferramenta de versionamento e gerenciamento de código Ferramenta Erwin Integração de dados utilizando Pentaho Data Integration (PDI), Métodos ágeis (XP, Scrum, Kanban etc), uma vez que será o framework que guiará o time de desenvolvimento na entrega dos produtos. ITIL, Information Technology Infraestructure Library (ITIL® Foundation).
Analista de Sistemas Sênior;https://www.catho.com.br/vagas/analista-de-sistemas-senior/18502307/?origem_apply=busca-de-vagas&entrada_apply=direto;Barueri - SP (1);Você conhece o #Méqui? Somos uma das maiores redes de serviço de alimentação rápida do mundo! #parapapapaaaaa Na América Latina e no Caribe, a Arcos Dorados é a responsável por operar os restaurantes do McDonald\\&#39s. Desde 2007, quando nos consolidamos regionalmente, continuamos a apostar nos mesmos compromissos que norteiam o nosso caminho: ? Qualidade da alimentação e transparência ? Geração de empregos formais para jovens ? Apoio às comunidades ? Cadeia de suprimentos sustentável e cuidado ambiental ? Diversidade e Inclusão ? Inovação de experiências para toda a família! Você será responsável por: * Através de metodologia Scrum, entender, desenhar e implementar soluções tecnológicas (especificamente na camada de localização de produto) para a plataforma de PDV, Delivery e Drive para o Brasil * Trabalhar com as equipes de suporte e desenvolvimento * Integrar sistemas específicos e sistemas legados (back- Office) com o restaurante * Pensar em soluções fim a fim quando se tratar de Restaurante, Drive-Thru e Delivery * Operações de varejo (diferencial se houver experiência no segmento de food) * Operações fiscais básicas: S@T, NFC-e, S@T MFE, PAF-NFce * Operações financeiras básicas: TEF, Carteiras Digitais. Gostou da oportunidade? Então, se o seu perfil profissional está alinhado com os pontos abaixo, fique à vontade para se candidatar : * Superior completo em Sistemas da Informação, Análise de Sistemas, Matemática, Engenharia, Ciências da Computação ou Processamento de Dados (Tecnólogo) * Implantação de sistemas, Indicadores, produtos ou projetos de varejo * Experiência com Banco de Dados SQL ou Oracle * Metodologia Agile, Scrum Master ou Product Owner * Desejável vivência em Varejo, preferencialmente com pontos de vendas distribuídos * Desejável experiência com operações de Delivery ou Drive-Thru ou Digital * Projetos de grande complexidade usando Metodologia Agile * Flexibilidade e fácil adaptação a mudanças * Foco no cliente * Altos padrões e controle * Trabalho em Equipe. Promovemos a Inclusão e valorizamos a diversidade em toda a sua multiplicidade. Aqui você pode fazer a diferença sendo você mesmo. ? Venha para o MÉQUI! #MCÉMC
CTO;https://www.catho.com.br/vagas/cto/18263950/?origem_apply=busca-de-vagas&entrada_apply=direto;Campinas - SP (1);Responder pela gestão das áreas de dados, engenharia e arquitetura de produtos, garantindo que as tecnologias possam atender às necessidades comerciais da empresa e a sustentabilidade do negócio a curto, médio e longo prazo Desenvolver o planejamento estratégico voltado a tecnologia, com foco nas demanda de mercados e experiência do cliente Promover pesquisas e implementação de novas tecnologias que possam potencialmente aumentar a vantagem competitiva do negócio Mentorar as demais áreas no uso eficaz da tecnologia e dados Desenvolver, analisar e reportar KPIs para avaliação do desempenho das áreas, identificando cenários críticos, possíveis pontos de atenção e propondo soluções que possam impactar o negócio Implantar política de segurança de dados, reduzindo o risco de violações tecnológicas e proteção informações sensíveis Gerenciar budget e ativos digitais da área, visando a melhor empregabilidade e uso consciente dos recursos Evoluir a infraestrutura do sistema e de dados para garantir funcionalidade, escalabilidade e eficiência Comunicar nossa estratégia de tecnologia para parceiros e investidores Promover um ambiente colaborativo de gestão e transferência de conhecimento entre os times com foco no desenvolvimento de carreira Gerir projetos e processos de acordo com as boas práticas de Agilidade, fortalecendo a cultura de excelência em tecnologia, comunicação eficiente e desenvolvimento profissional do time. Experiência como CTO | CIO ou função de liderança semelhante Forte conhecimento nas áreas de tecnologia e visão em tendências de inovação Perfil analítico com compreensão do planejamento de negócios e capacidade de definir prioridades de forma estratégica Fortes habilidades de liderança e vivência na gestão de equipe técnicas, considerando todos os níveis de senioridade Capacidade de comunicação clara e objetiva Excelentes habilidades interpessoais e vivência na implementação de metodologias de desenvolvimento Ágil Formação Superior em Ciência da Computação, Engenharia ou similares MBA ou pós-graduação em áreas com relevância para o negócio.
Cientista de Dados;https://www.catho.com.br/vagas/cientista-de-dados/18488048/?origem_apply=busca-de-vagas&entrada_apply=direto;Campinas - SP (1);Desenvolver análises diagnósticas e testes de hipótese, utilizando grandes volumes de dados para identificar oportunidades junto às áreas de negócio e atender as necessidades dos stakeholders Coletar, limpar, armazenar, organizar, integrar dados e contribuir na criação de pipelines de dados com nosso time de engenheiros Criar modelos de dados inteligentes utilizando Machine Learning (ML), Inteligência Artificial (AI) e outros métodos de modelagem de dado para auxiliar nossos clientes internos e externos em suas tomadas de decisões de negócios Realizar análises exploratórias, modelagem preditiva, aplicar aprendizado de máquina, realizar simulações e visualização interativa de dados, garantindo a performance dos modelos e a entrega dos resultados esperados Ser evangelista em relação ao uso de dados, ferramentas de análise e modelos estatísticos existentes na empresa. Graduação completa em qualquer área de conhecimento Perfil fortemente analítico e raciocínio lógico Experiência em linguagem de programação voltada para Ciência de Dados (Python, R, SPSS ou SAS - Preferêncialmente Python) Domínio de SQL Conhecimento em análise descritiva e visualização de dados Conhecimento em algoritmos de machine learning e modelagem estatística para regressão, classificação e clusterização de dados.    Você terá destaque se:  Possuir pós graduação (especialização) na área de dados ou formação acadêmica como mestrado/doutorado Conhecer outros algoritmos em ML e AI como NLP, Visão Computacional, Redes Neurais Profundas, Algoritmos Genéticos, Aprendizado por Reforço Experiência com técnicas e algoritmos de Deep Learning com Tensorflow ou Pytorch Conhecimento em ambiente de Cloud Computing como AWS, GCP ou Azure Conhecimento no ciclo de desenvolvimento de software e modelos em produção (CI/CD, MLOps) Conhecimento em ferramentas como Git, Jenkins, Docker Conhecimento em ferramentas de BI (PowerBI, Tableau ou similares).   Soft Skills  Forte desejo de autodesenvolvimento e aprimoramento Abertura para feedback Adorar trabalhar em time Proatividade, sempre se importar e se comportar como o dono dos entregáveis.
Analista de Redes de Computadores / Infraestrutura de Tecnologia de Informação;https://www.catho.com.br/vagas/analista-de-redes-de-computadores-infraestrutura-de-tecnologia-de-informacao/18557771/?origem_apply=busca-de-vagas&entrada_apply=direto;Teresina - PI (2);Requisitos * Ensino Superior Completo em Ciências da Computação, Informática ou áreas afins ou graduação completa em qualquer área de formação com Pós- graduação em Informática/Computação, fornecido por instituição reconhecida pelo MEC, acrescido de experiência profissional (na área) superior a cinco anos ou acrescido de título de mestrado ou doutorado (na área). Ter habilidades com as seguintes tecnologias: * VMWare, Citrix, Hyper-V * Zabbix, Sentry, GrayLog, Haproxy, NGinx, Apache, OpenVPN * Firewall, Proxy, IDP, Antivirus, ..., * Active Directory, DNS, NTP * Autonomous System * Switch Gerenciável, Roteadores, Servidores, Storages, Link&#39 s de Dados * Nobreaks, Geradores * JAVA,JavaScript, Python, SQL, TypeScript, ShellScrip t, PowerShell, NodeJs * VOIP * Protocolos * LGPD Atividades * Desempenhar atividades, de nível superior e especializado, envolvendo o planejamento, projeto e instalação de redes de transmissão de dados que suportem sistemas de processamento de dados. * Definir e documentar as configurações adequadas à infraestrutura necessária para os serviços em desenvolvimento, homologação e em produção, incluindo suas modificações e evoluções. * Analisar a utilização de redes de comunicação em uso ou planejadas e desenvolver estudos para melhorar o seu desempenho. * Planejar topologias de rede, aquisição, instalação e manutenção de software e equipamentos de telecomunicação. * Manter em perfeito funcionamento sistemas de segurança de acesso. * Analisar, configurar, instalar e manter programas e sistemas operacionais, gerenciar contas e discos, acompanhar a evolução de software, analisando o seu impacto nos sistemas, projetos, padrões e procedimentos existentes. * Instalar e manter a comunicação digital, incluindo o acesso à Internet, Intranet, correio eletrônico, comunicação de voz e vídeo, implementando mecanismos que garantam sua correta utilização. * Promover a resolução de problemas da instalação e de suporte às demandas de usuários que envolvam aspectos de configuração e administração dos servidores. * Pesquisar, definir e operacionalizar e sistemas de segurança, com o objetivo de preservar a integridade e o sigilo das informações armazenadas nos computadores. * Efetuar a atualização dos softwares de segurança. * Realizar o monitoramento, auditoria e manutenção da rede de computadores. * Realizar, validar, armazenar e restaurar cópias de segurança das informações contidas nos sistemas. * Administrar as licenças de software em uso. * Orientar os usuários nos itens referentes à segurança de dados e contaminação por &quotmalwares&quot nos seus computadores. * Pesquisar e avaliar novas tecnologias, de forma a aprimorar os recursos tecnológicos utilizados. * Promover o assessoramento na especificação de equipamentos relacionados à rede a serem adquiridos. * Orientar na elaboração de projetos de cabeamentos lógico e elétrico, bem como realizar testes de conectividade em redes locais. * Monitorar os serviços de TI. * Elaborar scripts para automatização de rotinas. * Definir padrões de arquitetura em conjunto com o time de sistemas. * Desenvolver padrões de desenvolvimento e implantação de infraestrutura. * Atuar como agente integrador e em parceria com administradores de dados, engenheiros de software times de operação. * garantir disponibilidade dos sistemas baseados em infraestruturas cloud. * Participar ativamente das implantações de projetos que envolvam ambientes cloud. * Desenvolver e evoluir arquiteturas de soluções. * Migrar Data-Center físicos para nuvem. * Participar ativamente da análise, estudo, seleção e planejamento de software e hardware básico e de apoio (como sistemas operacionais, bancos de dados, teleprocessamento, sistemas de gestão, etc.). * Prestar suporte técnico a usuários e desenvolvedores. * Elaborar documentação técnica relativa aos procedimentos e controles. * Emitir pareceres técnicos. * Atuar no gerenciamento de serviços de Tecnologia da Informação. * Executar outras tarefas da mesma natureza e grau de complexidade. * Auxiliar, quando necessário, em perícias. * Desenvolver outras atividades correlatas a sua área de atuação.
